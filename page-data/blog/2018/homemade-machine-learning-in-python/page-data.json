{"componentChunkName":"component---src-templates-post-tsx-content-file-path-src-posts-2018-homemade-machine-learning-in-python-index-md","path":"/blog/2018/homemade-machine-learning-in-python/","result":{"data":{"mdx":{"id":"e3229814-f6bf-5d54-9b42-509d620089cc","body":"\n![Homemade Machine Learning in Python](assets/01-cover.png)\n\n<center><i>\nThe source of the following machine learning topics map is <a href=\"https://vas3k.ru/blog/machine_learning/\">this wonderful blog post</a>.\n</i></center>\n\nIâ€™ve recently launched [Homemade Machine Learning](https://github.com/trekhleb/homemade-machine-learning) repository that contains examples of popular machine learning algorithms and approaches (like _linear/logistic regressions, K-Means clustering, neural networks_) implemented in **Python** with mathematics behind them being explained. Each algorithm has interactive **Jupyter Notebook** demo that allows you to play with training data, algorithms configurations and immediately see the results, charts and predictions **right in your browser**. In most cases the explanations are based on [this great machine learning course](https://www.coursera.org/learn/machine-learning) by [Andrew Ng](https://medium.com/@andrewng).\n\nThe purpose of the repository was _not_ to implement machine learning algorithms by using 3rd party library â€œone-linersâ€ _but_ rather to practice implementing these algorithms from scratch and get better understanding of the mathematics behind each algorithm. Thatâ€™s why all algorithms implementations are called â€œhomemadeâ€.\n\nThe main Python libraries that are used there are [NumPy](http://www.numpy.org/) and [Pandas](https://pandas.pydata.org/). These two are used for efficient matrix operations and for loading/parsing CSV datasets. When it comes to [Jupyter Notebook](http://jupyter.org/) demos then such libraries as [Matplotlib](https://matplotlib.org/) and [Plotly](https://plot.ly/) are being used for data visualizations.\n\nCurrently, the following topics have been covered:\n\n## Regression: Linear Regression\n\nIn regression problems we do real value predictions. Basically we try to draw a line/plane/n-dimensional plane along the training examples.\n\n_Usage examples: stock price forecast, sales analysis, dependency of any number, etc._\n\n*   ðŸ“— [Linear Regression Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/linear_regression)  â€”  theory and links for further readings\n*   âš™ï¸ [Linear Regression Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/linear_regression/linear_regression.py)\n*   â–¶ï¸ [Demo | Univariate Linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/univariate_linear_regression_demo.ipynb)  â€”  predict `country happiness` score by `economy GDP`\n*   â–¶ï¸ [Demo | Multivariate Linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/multivariate_linear_regression_demo.ipynb)  â€”  predict `country happiness` score by `economy GDP` and `freedom index`\n*   â–¶ï¸ [Demo | Non-linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/non_linear_regression_demo.ipynb)  â€”  use linear regression with _polynomial_ and _sinusoid_ features to predict non-linear dependencies.\n\n## Classification: Logistic Regression\n\nIn classification problems we split input examples by certain characteristic.\n\n_Usage examples: spam-filters, language detection, finding similar documents, handwritten letters recognition, etc._\n\n*   ðŸ“— [Logistic Regression Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/logistic_regression)  â€”  theory and links for further readings\n*   âš™ï¸ [Logistic Regression Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/logistic_regression/logistic_regression.py)\n*   â–¶ï¸ [Demo | Logistic Regression (Linear Boundary)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_linear_boundary_demo.ipynb)  â€”  predict Iris flower `class` based on `petal_length` and `petal_width`\n*   â–¶ï¸ [Demo | Logistic Regression (Non-Linear Boundary)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_non_linear_boundary_demo.ipynb)  â€”  predict microchip `validity` based on `param_1` and `param_2`\n*   â–¶ï¸ [Demo | Multivariate Logistic Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/multivariate_logistic_regression_demo.ipynb)  â€”  recognize handwritten digits from `28x28` pixel images.\n\n## Clustering: K-means Algorithm\n\nIn clustering problems we split the training examples by unknown characteristics. The algorithm itself decides what characteristic to use for splitting.\n\n_Usage examples: market segmentation, social networks analysis, organize computing clusters, astronomical data analysis, image compression, etc._\n\n*   ðŸ“— [K-means Algorithm Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/k_means)  â€”  theory and links for further readings\n*   âš™ï¸ [K-means Algorithm Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/k_means/k_means.py)\n*   â–¶ï¸ [Demo | K-means Algorithm](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/k_means/k_means_demo.ipynb)  â€”  split Iris flowers into clusters based on `petal_length` and `petal_width`\n\n## Neural Networks: Multilayer Perceptron (MLP)\n\nThe neural network itself isnâ€™t an algorithm, but rather a framework for many different machine learning algorithms to work together and process complex data inputs.\n\n_Usage examples: as a substitute of all other algorithms in general, image recognition, voice recognition, image processing (applying specific style), language translation, etc._\n\n*   ðŸ“— [Multilayer Perceptron Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/neural_network)  â€”  theory and links for further readings\n*   âš™ï¸ [Multilayer Perceptron Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/neural_network/multilayer_perceptron.py)\n*   â–¶ï¸ [Demo | Multilayer Perceptron](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/neural_network/multilayer_perceptron_demo.ipynb)  â€”  recognize handwritten digits from `28x28` pixel images.\n\n## Anomaly Detection: Gaussian Distribution\n\nAnomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.\n\n_Usage examples: intrusion detection, fraud detection, system health monitoring, removing anomalous data from the dataset etc._\n\n*   ðŸ“— [The Math Behind Anomaly Detection using Gaussian Distribution](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/anomaly_detection)\n\n> I hope youâ€™ll find [the repository](https://github.com/trekhleb/homemade-machine-learning) useful. Either by playing with demos or by reading the math sections or by simply exploring the source code. Happy coding!\n","fields":{"slug":"/blog/2018/homemade-machine-learning-in-python/"},"internal":{"contentFilePath":"/home/runner/work/trekhleb.github.io/trekhleb.github.io/src/posts/2018/homemade-machine-learning-in-python/index.md"},"frontmatter":{"title":"Homemade Machine Learning in Python","summary":"MatLab/Octave examples of popular machine learning algorithms with code examples and mathematics being explained","date":"21 December, 2018","cover":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAACF0lEQVR42mWSWW/UMBDH9/t/GN4RSCDEA1RQDvWAtqq2abONnWzi+LbnQt6lFMTID9bYvzn+MxtmZiJmRkRmzjnXWr1z3jsiAgCzruO0DEpba2utMSY6mIhsAEBrHULs+8ec88P9/bqupcC0n10L4Uc9ZNu5eZtSTMHux8eUgjEGETd9v7NmsuNFWjsino31brXjj7RuRSTGaMwcXZ+DYuawbJfhe0nGmBUANtY6hFyCwrJiWkx/Wf2YvcI0i0itkFIIU+d01/qDUKM2i1ZKhxA2cjRmEknz/fb0ZbWKD67DERHsz9/p6xNmTn5U3Wm0etrPWusn+HcEOYrBzN4Gu3hCOghKx2emGoOLMfLhW4OJKOdMiMaYXEqDib99PP/w5lNJlQibRwQJs7ku9kYEnfPW2s1RlXlZ9t3Z3dfX2U1IgggAWEpBRCSGaHZnb93ukkWKH5K5ydGklBscQhjHaR07vT2jGvmgQMkhestMzMKQ7XCTzQ4hYdLJ9s4uLNLgUor3vgIgM1JLyoTbL68u37+g7BAJCVmEmOJ8FZeftWSlxlrrUbCmKla/f7wIVokIANaScgxQgUUgL36+EvTG2EOZo/eemZ/hdVHq4Ty1ZeoIglvVPHWCIQeFcZftHWNoLTC30rghz6NKuRCLX4f+9iQ6Zafb/XCBZT/cfc5e/cnxt/0zZwBYrVuMM8YeZ9tWMhZsd/4f/gXsaSSlsrVQiwAAAABJRU5ErkJggg==","aspectRatio":1.4367816091954022,"src":"/static/6a4daeb4f4a615338ca192f7993816ae/eb0de/01-cover.png","srcSet":"/static/6a4daeb4f4a615338ca192f7993816ae/bd3a8/01-cover.png 250w,\n/static/6a4daeb4f4a615338ca192f7993816ae/0757b/01-cover.png 500w,\n/static/6a4daeb4f4a615338ca192f7993816ae/eb0de/01-cover.png 1000w,\n/static/6a4daeb4f4a615338ca192f7993816ae/3c4ef/01-cover.png 1207w","sizes":"(max-width: 1000px) 100vw, 1000px"}}}}}},"pageContext":{"slug":"/blog/2018/homemade-machine-learning-in-python/","frontmatter":{"title":"Homemade Machine Learning in Python","summary":"MatLab/Octave examples of popular machine learning algorithms with code examples and mathematics being explained","cover":"assets/01-cover.png","date":"2018-12-21T00:00:00.000Z"}}},"staticQueryHashes":[],"slicesMap":{}}