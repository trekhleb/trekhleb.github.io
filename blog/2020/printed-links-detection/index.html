<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 5.10.0"/><meta data-react-helmet="true" name="description" content="In this article we will start solving the issue of making the printed links (i.e. in a book or in a magazine) clickable via your smartphone camera"/><meta data-react-helmet="true" name="image" content="https://trekhleb.dev/static/55a94699f1c16ff59258cbb490d497eb/8fe9a/01-cover.png"/><meta data-react-helmet="true" property="og:title" content="Making the Printed Links Clickable Using TensorFlow 2 Object Detection API | Trekhleb"/><meta data-react-helmet="true" property="og:description" content="In this article we will start solving the issue of making the printed links (i.e. in a book or in a magazine) clickable via your smartphone camera"/><meta data-react-helmet="true" property="og:url" content="https://trekhleb.dev/blog/2020/printed-links-detection/"/><meta data-react-helmet="true" property="og:image" content="https://trekhleb.dev/static/55a94699f1c16ff59258cbb490d497eb/8fe9a/01-cover.png"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:creator" content="@Trekhleb"/><meta data-react-helmet="true" name="twitter:title" content="Making the Printed Links Clickable Using TensorFlow 2 Object Detection API | Trekhleb"/><meta data-react-helmet="true" name="twitter:description" content="In this article we will start solving the issue of making the printed links (i.e. in a book or in a magazine) clickable via your smartphone camera"/><meta data-react-helmet="true" name="twitter:image" content="https://trekhleb.dev/static/55a94699f1c16ff59258cbb490d497eb/8fe9a/01-cover.png"/><meta data-react-helmet="true" name="twitter:url" content="https://trekhleb.dev/blog/2020/printed-links-detection/"/><style data-href="/styles.ca827ea6641e6e29980d.css" data-identity="gatsby-global-css">@import url(https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap);.prose blockquote p:first-of-type:before,.prose blockquote p:last-of-type:after,.prose code:after,.prose code:before{content:""!important}.prose blockquote{font-weight:400!important}.prose li code.language-text,.prose p code.language-text,.prose td code.language-text,.prose th code.language-text,.prose tr code.language-text{font-weight:400;padding:2px 5px 1px}.prose code{font-size:13px!important}.prose p>img{margin:auto}.prose h1>a.gatsby-remark-autolink-header-anchor,.prose h2>a.gatsby-remark-autolink-header-anchor,.prose h3>a.gatsby-remark-autolink-header-anchor,.prose h4>a.gatsby-remark-autolink-header-anchor,.prose h5>a.gatsby-remark-autolink-header-anchor{display:inline-block;margin-left:10px;visibility:hidden}.prose h1:hover>a.gatsby-remark-autolink-header-anchor,.prose h2:hover>a.gatsby-remark-autolink-header-anchor,.prose h3:hover>a.gatsby-remark-autolink-header-anchor,.prose h4:hover>a.gatsby-remark-autolink-header-anchor,.prose h5:hover>a.gatsby-remark-autolink-header-anchor{visibility:visible}.shared-tooltip-content a{text-decoration:underline}.shared-tooltip-content p:not(:last-child){margin-bottom:10px}

/* ! tailwindcss v3.3.2 | MIT License | https://tailwindcss.com */*,:after,:before{border:0 solid #e5e7eb;box-sizing:border-box}:after,:before{--tw-content:""}html{-webkit-text-size-adjust:100%;font-feature-settings:normal;font-family:Roboto,ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;font-variation-settings:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4}body{line-height:inherit;margin:0}hr{border-top-width:1px;color:inherit;height:0}abbr:where([title]){-webkit-text-decoration:underline dotted;text-decoration:underline dotted}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{border-collapse:collapse;border-color:inherit;text-indent:0}button,input,optgroup,select,textarea{color:inherit;font-family:inherit;font-size:100%;font-weight:inherit;line-height:inherit;margin:0;padding:0}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button;background-color:transparent;background-image:none}:-moz-focusring{outline:auto}:-moz-ui-invalid{box-shadow:none}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}fieldset{margin:0}fieldset,legend{padding:0}menu,ol,ul{list-style:none;margin:0;padding:0}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{color:#9ca3af;opacity:1}input::placeholder,textarea::placeholder{color:#9ca3af;opacity:1}[role=button],button{cursor:pointer}:disabled{cursor:default}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{height:auto;max-width:100%}[hidden]{display:none}*,:after,:before{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: }::backdrop{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: }.container{width:100%}@media (min-width:640px){.container{max-width:640px}}@media (min-width:768px){.container{max-width:768px}}@media (min-width:1024px){.container{max-width:1024px}}@media (min-width:1280px){.container{max-width:1280px}}@media (min-width:1536px){.container{max-width:1536px}}.prose{color:var(--tw-prose-body);max-width:65ch}.prose :where(p):not(:where([class~=not-prose] *)){margin-bottom:1.25em;margin-top:1.25em}.prose :where([class~=lead]):not(:where([class~=not-prose] *)){color:var(--tw-prose-lead);font-size:1.25em;line-height:1.6;margin-bottom:1.2em;margin-top:1.2em}.prose :where(a):not(:where([class~=not-prose] *)){color:#dc2626;font-weight:500;text-decoration:underline}.prose :where(a):not(:where([class~=not-prose] *)):hover{color:#ef4444}.prose :where(strong):not(:where([class~=not-prose] *)){color:var(--tw-prose-bold);font-weight:600}.prose :where(a strong):not(:where([class~=not-prose] *)){color:inherit}.prose :where(blockquote strong):not(:where([class~=not-prose] *)){color:inherit}.prose :where(thead th strong):not(:where([class~=not-prose] *)){color:inherit}.prose :where(ol):not(:where([class~=not-prose] *)){list-style-type:decimal;margin-bottom:1.25em;margin-top:1.25em;padding-left:1.625em}.prose :where(ol[type=A]):not(:where([class~=not-prose] *)){list-style-type:upper-alpha}.prose :where(ol[type=a]):not(:where([class~=not-prose] *)){list-style-type:lower-alpha}.prose :where(ol[type=A s]):not(:where([class~=not-prose] *)){list-style-type:upper-alpha}.prose :where(ol[type=a s]):not(:where([class~=not-prose] *)){list-style-type:lower-alpha}.prose :where(ol[type=I]):not(:where([class~=not-prose] *)){list-style-type:upper-roman}.prose :where(ol[type=i]):not(:where([class~=not-prose] *)){list-style-type:lower-roman}.prose :where(ol[type=I s]):not(:where([class~=not-prose] *)){list-style-type:upper-roman}.prose :where(ol[type=i s]):not(:where([class~=not-prose] *)){list-style-type:lower-roman}.prose :where(ol[type="1"]):not(:where([class~=not-prose] *)){list-style-type:decimal}.prose :where(ul):not(:where([class~=not-prose] *)){list-style-type:disc;margin-bottom:1.25em;margin-top:1.25em;padding-left:1.625em}.prose :where(ol>li):not(:where([class~=not-prose] *))::marker{color:var(--tw-prose-counters);font-weight:400}.prose :where(ul>li):not(:where([class~=not-prose] *))::marker{color:var(--tw-prose-bullets)}.prose :where(hr):not(:where([class~=not-prose] *)){border-color:var(--tw-prose-hr);border-top-width:1px;margin-bottom:3em;margin-top:3em}.prose :where(blockquote):not(:where([class~=not-prose] *)){border-left-color:var(--tw-prose-quote-borders);border-left-width:.25rem;color:var(--tw-prose-quotes);font-style:italic;font-weight:500;margin-bottom:1.6em;margin-top:1.6em;padding-left:1em;quotes:"\201C""\201D""\2018""\2019"}.prose :where(blockquote p:first-of-type):not(:where([class~=not-prose] *)):before{content:open-quote}.prose :where(blockquote p:last-of-type):not(:where([class~=not-prose] *)):after{content:close-quote}.prose :where(h1):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-size:2.25em;font-weight:800;line-height:1.1111111;margin-bottom:.8888889em;margin-top:0}.prose :where(h1 strong):not(:where([class~=not-prose] *)){color:inherit;font-weight:900}.prose :where(h2):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-size:1.5em;font-weight:700;line-height:1.3333333;margin-bottom:1em;margin-top:2em}.prose :where(h2 strong):not(:where([class~=not-prose] *)){color:inherit;font-weight:800}.prose :where(h3):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-size:1.25em;font-weight:600;line-height:1.6;margin-bottom:.6em;margin-top:1.6em}.prose :where(h3 strong):not(:where([class~=not-prose] *)){color:inherit;font-weight:700}.prose :where(h4):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-weight:600;line-height:1.5;margin-bottom:.5em;margin-top:1.5em}.prose :where(h4 strong):not(:where([class~=not-prose] *)){color:inherit;font-weight:700}.prose :where(img):not(:where([class~=not-prose] *)){margin-bottom:2em;margin-top:2em}.prose :where(figure>*):not(:where([class~=not-prose] *)){margin-bottom:0;margin-top:0}.prose :where(figcaption):not(:where([class~=not-prose] *)){color:var(--tw-prose-captions);font-size:.875em;line-height:1.4285714;margin-top:.8571429em}.prose :where(code):not(:where([class~=not-prose] *)){color:var(--tw-prose-code);font-size:.875em;font-weight:600}.prose :where(code):not(:where([class~=not-prose] *)):before{content:"`"}.prose :where(code):not(:where([class~=not-prose] *)):after{content:"`"}.prose :where(a code):not(:where([class~=not-prose] *)){color:inherit}.prose :where(h1 code):not(:where([class~=not-prose] *)){color:inherit}.prose :where(h2 code):not(:where([class~=not-prose] *)){color:inherit;font-size:.875em}.prose :where(h3 code):not(:where([class~=not-prose] *)){color:inherit;font-size:.9em}.prose :where(h4 code):not(:where([class~=not-prose] *)){color:inherit}.prose :where(blockquote code):not(:where([class~=not-prose] *)){color:inherit}.prose :where(thead th code):not(:where([class~=not-prose] *)){color:inherit}.prose :where(pre):not(:where([class~=not-prose] *)){background-color:var(--tw-prose-pre-bg);border-radius:.375rem;color:var(--tw-prose-pre-code);font-size:.875em;font-weight:400;line-height:1.7142857;margin-bottom:1.7142857em;margin-top:1.7142857em;overflow-x:auto;padding:.8571429em 1.1428571em}.prose :where(pre code):not(:where([class~=not-prose] *)){background-color:transparent;border-radius:0;border-width:0;color:inherit;font-family:inherit;font-size:inherit;font-weight:inherit;line-height:inherit;padding:0}.prose :where(pre code):not(:where([class~=not-prose] *)):before{content:none}.prose :where(pre code):not(:where([class~=not-prose] *)):after{content:none}.prose :where(table):not(:where([class~=not-prose] *)){font-size:.875em;line-height:1.7142857;margin-bottom:2em;margin-top:2em;table-layout:auto;text-align:left;width:100%}.prose :where(thead):not(:where([class~=not-prose] *)){border-bottom-color:var(--tw-prose-th-borders);border-bottom-width:1px}.prose :where(thead th):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-weight:600;padding-bottom:.5714286em;padding-left:.5714286em;padding-right:.5714286em;vertical-align:bottom}.prose :where(tbody tr):not(:where([class~=not-prose] *)){border-bottom-color:var(--tw-prose-td-borders);border-bottom-width:1px}.prose :where(tbody tr:last-child):not(:where([class~=not-prose] *)){border-bottom-width:0}.prose :where(tbody td):not(:where([class~=not-prose] *)){vertical-align:baseline}.prose :where(tfoot):not(:where([class~=not-prose] *)){border-top-color:var(--tw-prose-th-borders);border-top-width:1px}.prose :where(tfoot td):not(:where([class~=not-prose] *)){vertical-align:top}.prose{--tw-prose-body:#374151;--tw-prose-headings:#111827;--tw-prose-lead:#4b5563;--tw-prose-links:#111827;--tw-prose-bold:#111827;--tw-prose-counters:#6b7280;--tw-prose-bullets:#d1d5db;--tw-prose-hr:#e5e7eb;--tw-prose-quotes:#111827;--tw-prose-quote-borders:#e5e7eb;--tw-prose-captions:#6b7280;--tw-prose-code:#111827;--tw-prose-pre-code:#e5e7eb;--tw-prose-pre-bg:#1f2937;--tw-prose-th-borders:#d1d5db;--tw-prose-td-borders:#e5e7eb;--tw-prose-invert-body:#d1d5db;--tw-prose-invert-headings:#fff;--tw-prose-invert-lead:#9ca3af;--tw-prose-invert-links:#fff;--tw-prose-invert-bold:#fff;--tw-prose-invert-counters:#9ca3af;--tw-prose-invert-bullets:#4b5563;--tw-prose-invert-hr:#374151;--tw-prose-invert-quotes:#f3f4f6;--tw-prose-invert-quote-borders:#374151;--tw-prose-invert-captions:#9ca3af;--tw-prose-invert-code:#fff;--tw-prose-invert-pre-code:#d1d5db;--tw-prose-invert-pre-bg:rgba(0,0,0,.5);--tw-prose-invert-th-borders:#4b5563;--tw-prose-invert-td-borders:#374151;font-size:1rem;line-height:1.75}.prose :where(video):not(:where([class~=not-prose] *)){margin-bottom:2em;margin-top:2em}.prose :where(figure):not(:where([class~=not-prose] *)){margin-bottom:2em;margin-top:2em}.prose :where(li):not(:where([class~=not-prose] *)){margin-bottom:.5em;margin-top:.5em}.prose :where(ol>li):not(:where([class~=not-prose] *)){padding-left:.375em}.prose :where(ul>li):not(:where([class~=not-prose] *)){padding-left:.375em}.prose :where(.prose>ul>li p):not(:where([class~=not-prose] *)){margin-bottom:.75em;margin-top:.75em}.prose :where(.prose>ul>li>:first-child):not(:where([class~=not-prose] *)){margin-top:1.25em}.prose :where(.prose>ul>li>:last-child):not(:where([class~=not-prose] *)){margin-bottom:1.25em}.prose :where(.prose>ol>li>:first-child):not(:where([class~=not-prose] *)){margin-top:1.25em}.prose :where(.prose>ol>li>:last-child):not(:where([class~=not-prose] *)){margin-bottom:1.25em}.prose :where(ul ul,ul ol,ol ul,ol ol):not(:where([class~=not-prose] *)){margin-bottom:.75em;margin-top:.75em}.prose :where(hr+*):not(:where([class~=not-prose] *)){margin-top:0}.prose :where(h2+*):not(:where([class~=not-prose] *)){margin-top:0}.prose :where(h3+*):not(:where([class~=not-prose] *)){margin-top:0}.prose :where(h4+*):not(:where([class~=not-prose] *)){margin-top:0}.prose :where(thead th:first-child):not(:where([class~=not-prose] *)){padding-left:0}.prose :where(thead th:last-child):not(:where([class~=not-prose] *)){padding-right:0}.prose :where(tbody td,tfoot td):not(:where([class~=not-prose] *)){padding:.5714286em}.prose :where(tbody td:first-child,tfoot td:first-child):not(:where([class~=not-prose] *)){padding-left:0}.prose :where(tbody td:last-child,tfoot td:last-child):not(:where([class~=not-prose] *)){padding-right:0}.prose :where(.prose>:first-child):not(:where([class~=not-prose] *)){margin-top:0}.prose :where(.prose>:last-child):not(:where([class~=not-prose] *)){margin-bottom:0}.prose-sm{font-size:.875rem;line-height:1.7142857}.prose-sm :where(p):not(:where([class~=not-prose] *)){margin-bottom:1.1428571em;margin-top:1.1428571em}.prose-sm :where([class~=lead]):not(:where([class~=not-prose] *)){font-size:1.2857143em;line-height:1.5555556;margin-bottom:.8888889em;margin-top:.8888889em}.prose-sm :where(blockquote):not(:where([class~=not-prose] *)){margin-bottom:1.3333333em;margin-top:1.3333333em;padding-left:1.1111111em}.prose-sm :where(h1):not(:where([class~=not-prose] *)){font-size:2.1428571em;line-height:1.2;margin-bottom:.8em;margin-top:0}.prose-sm :where(h2):not(:where([class~=not-prose] *)){font-size:1.4285714em;line-height:1.4;margin-bottom:.8em;margin-top:1.6em}.prose-sm :where(h3):not(:where([class~=not-prose] *)){font-size:1.2857143em;line-height:1.5555556;margin-bottom:.4444444em;margin-top:1.5555556em}.prose-sm :where(h4):not(:where([class~=not-prose] *)){line-height:1.4285714;margin-bottom:.5714286em;margin-top:1.4285714em}.prose-sm :where(img):not(:where([class~=not-prose] *)){margin-bottom:1.7142857em;margin-top:1.7142857em}.prose-sm :where(video):not(:where([class~=not-prose] *)){margin-bottom:1.7142857em;margin-top:1.7142857em}.prose-sm :where(figure):not(:where([class~=not-prose] *)){margin-bottom:1.7142857em;margin-top:1.7142857em}.prose-sm :where(figure>*):not(:where([class~=not-prose] *)){margin-bottom:0;margin-top:0}.prose-sm :where(figcaption):not(:where([class~=not-prose] *)){font-size:.8571429em;line-height:1.3333333;margin-top:.6666667em}.prose-sm :where(code):not(:where([class~=not-prose] *)){font-size:.8571429em}.prose-sm :where(h2 code):not(:where([class~=not-prose] *)){font-size:.9em}.prose-sm :where(h3 code):not(:where([class~=not-prose] *)){font-size:.8888889em}.prose-sm :where(pre):not(:where([class~=not-prose] *)){border-radius:.25rem;font-size:.8571429em;line-height:1.6666667;margin-bottom:1.6666667em;margin-top:1.6666667em;padding:.6666667em 1em}.prose-sm :where(ol):not(:where([class~=not-prose] *)){margin-bottom:1.1428571em;margin-top:1.1428571em;padding-left:1.5714286em}.prose-sm :where(ul):not(:where([class~=not-prose] *)){margin-bottom:1.1428571em;margin-top:1.1428571em;padding-left:1.5714286em}.prose-sm :where(li):not(:where([class~=not-prose] *)){margin-bottom:.2857143em;margin-top:.2857143em}.prose-sm :where(ol>li):not(:where([class~=not-prose] *)){padding-left:.4285714em}.prose-sm :where(ul>li):not(:where([class~=not-prose] *)){padding-left:.4285714em}.prose-sm :where(.prose-sm>ul>li p):not(:where([class~=not-prose] *)){margin-bottom:.5714286em;margin-top:.5714286em}.prose-sm :where(.prose-sm>ul>li>:first-child):not(:where([class~=not-prose] *)){margin-top:1.1428571em}.prose-sm :where(.prose-sm>ul>li>:last-child):not(:where([class~=not-prose] *)){margin-bottom:1.1428571em}.prose-sm :where(.prose-sm>ol>li>:first-child):not(:where([class~=not-prose] *)){margin-top:1.1428571em}.prose-sm :where(.prose-sm>ol>li>:last-child):not(:where([class~=not-prose] *)){margin-bottom:1.1428571em}.prose-sm :where(ul ul,ul ol,ol ul,ol ol):not(:where([class~=not-prose] *)){margin-bottom:.5714286em;margin-top:.5714286em}.prose-sm :where(hr):not(:where([class~=not-prose] *)){margin-bottom:2.8571429em;margin-top:2.8571429em}.prose-sm :where(hr+*):not(:where([class~=not-prose] *)){margin-top:0}.prose-sm :where(h2+*):not(:where([class~=not-prose] *)){margin-top:0}.prose-sm :where(h3+*):not(:where([class~=not-prose] *)){margin-top:0}.prose-sm :where(h4+*):not(:where([class~=not-prose] *)){margin-top:0}.prose-sm :where(table):not(:where([class~=not-prose] *)){font-size:.8571429em;line-height:1.5}.prose-sm :where(thead th):not(:where([class~=not-prose] *)){padding-bottom:.6666667em;padding-left:1em;padding-right:1em}.prose-sm :where(thead th:first-child):not(:where([class~=not-prose] *)){padding-left:0}.prose-sm :where(thead th:last-child):not(:where([class~=not-prose] *)){padding-right:0}.prose-sm :where(tbody td,tfoot td):not(:where([class~=not-prose] *)){padding:.6666667em 1em}.prose-sm :where(tbody td:first-child,tfoot td:first-child):not(:where([class~=not-prose] *)){padding-left:0}.prose-sm :where(tbody td:last-child,tfoot td:last-child):not(:where([class~=not-prose] *)){padding-right:0}.prose-sm :where(.prose-sm>:first-child):not(:where([class~=not-prose] *)){margin-top:0}.prose-sm :where(.prose-sm>:last-child):not(:where([class~=not-prose] *)){margin-bottom:0}.prose-red{--tw-prose-links:#dc2626;--tw-prose-invert-links:#ef4444}.visible{visibility:visible}.invisible{visibility:hidden}.static{position:static}.fixed{position:fixed}.absolute{position:absolute}.relative{position:relative}.inset-y-0{bottom:0;top:0}.bottom-0{bottom:0}.left-0{left:0}.right-0{right:0}.z-10{z-index:10}.m-auto{margin:auto}.mx-2{margin-left:.5rem;margin-right:.5rem}.mb-0{margin-bottom:0}.mb-1{margin-bottom:.25rem}.mb-12{margin-bottom:3rem}.mb-2{margin-bottom:.5rem}.mb-24{margin-bottom:6rem}.mb-3{margin-bottom:.75rem}.mb-4{margin-bottom:1rem}.mb-6{margin-bottom:1.5rem}.ml-0{margin-left:0}.ml-1{margin-left:.25rem}.ml-2{margin-left:.5rem}.ml-3{margin-left:.75rem}.ml-4{margin-left:1rem}.ml-5{margin-left:1.25rem}.mr-0{margin-right:0}.mr-1{margin-right:.25rem}.mr-2{margin-right:.5rem}.mr-3{margin-right:.75rem}.mr-4{margin-right:1rem}.mr-5{margin-right:1.25rem}.mr-6{margin-right:1.5rem}.mt-1{margin-top:.25rem}.mt-16{margin-top:4rem}.mt-2{margin-top:.5rem}.mt-24{margin-top:6rem}.mt-3{margin-top:.75rem}.mt-4{margin-top:1rem}.mt-6{margin-top:1.5rem}.block{display:block}.inline-block{display:inline-block}.flex{display:flex}.grid{display:grid}.hidden{display:none}.h-0{height:0}.h-0\.5{height:.125rem}.h-16{height:4rem}.h-4{height:1rem}.h-48{height:12rem}.h-5{height:1.25rem}.h-6{height:1.5rem}.h-64{height:16rem}.h-96{height:24rem}.h-full{height:100%}.w-1{width:.25rem}.w-10{width:2.5rem}.w-14{width:3.5rem}.w-16{width:4rem}.w-2{width:.5rem}.w-36{width:9rem}.w-4{width:1rem}.w-5{width:1.25rem}.w-6{width:1.5rem}.w-64{width:16rem}.w-full{width:100%}.w-screen{width:100vw}.max-w-md{max-width:28rem}.max-w-screen-xl{max-width:1280px}.flex-1{flex:1 1 0%}.shrink{flex-shrink:1}.transform{transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}@keyframes spin{to{transform:rotate(1turn)}}.animate-spin{animation:spin 1s linear infinite}.cursor-not-allowed{cursor:not-allowed}.cursor-pointer{cursor:pointer}.resize{resize:both}.appearance-none{-webkit-appearance:none;-moz-appearance:none;appearance:none}.grid-cols-1{grid-template-columns:repeat(1,minmax(0,1fr))}.flex-row{flex-direction:row}.flex-col{flex-direction:column}.flex-wrap{flex-wrap:wrap}.items-start{align-items:flex-start}.items-center{align-items:center}.items-stretch{align-items:stretch}.justify-start{justify-content:flex-start}.justify-end{justify-content:flex-end}.justify-center{justify-content:center}.justify-between{justify-content:space-between}.justify-items-center{justify-items:center}.gap-1{gap:.25rem}.gap-12{gap:3rem}.self-start{align-self:flex-start}.self-stretch{align-self:stretch}.justify-self-end{justify-self:end}.overflow-hidden{overflow:hidden}.overflow-scroll{overflow:scroll}.whitespace-nowrap{white-space:nowrap}.rounded{border-radius:.25rem}.rounded-full{border-radius:9999px}.rounded-lg{border-radius:.5rem}.rounded-md{border-radius:.375rem}.rounded-sm{border-radius:.125rem}.border{border-width:1px}.border-4{border-width:4px}.border-b-2{border-bottom-width:2px}.border-solid{border-style:solid}.border-dashed{border-style:dashed}.border-dotted{border-style:dotted}.border-black{--tw-border-opacity:1;border-color:rgb(0 0 0/var(--tw-border-opacity))}.border-gray-300{--tw-border-opacity:1;border-color:rgb(209 213 219/var(--tw-border-opacity))}.border-gray-400{--tw-border-opacity:1;border-color:rgb(156 163 175/var(--tw-border-opacity))}.border-red-600{--tw-border-opacity:1;border-color:rgb(220 38 38/var(--tw-border-opacity))}.border-slate-400{--tw-border-opacity:1;border-color:rgb(148 163 184/var(--tw-border-opacity))}.border-white{--tw-border-opacity:1;border-color:rgb(255 255 255/var(--tw-border-opacity))}.bg-black{--tw-bg-opacity:1;background-color:rgb(0 0 0/var(--tw-bg-opacity))}.bg-blue-100{--tw-bg-opacity:1;background-color:rgb(219 234 254/var(--tw-bg-opacity))}.bg-gray-100{--tw-bg-opacity:1;background-color:rgb(243 244 246/var(--tw-bg-opacity))}.bg-gray-200{--tw-bg-opacity:1;background-color:rgb(229 231 235/var(--tw-bg-opacity))}.bg-gray-400{--tw-bg-opacity:1;background-color:rgb(156 163 175/var(--tw-bg-opacity))}.bg-orange-100{--tw-bg-opacity:1;background-color:rgb(255 237 213/var(--tw-bg-opacity))}.bg-orange-500{--tw-bg-opacity:1;background-color:rgb(249 115 22/var(--tw-bg-opacity))}.bg-red-100{--tw-bg-opacity:1;background-color:rgb(254 226 226/var(--tw-bg-opacity))}.bg-rose-200{--tw-bg-opacity:1;background-color:rgb(254 205 211/var(--tw-bg-opacity))}.bg-rose-500{--tw-bg-opacity:1;background-color:rgb(244 63 94/var(--tw-bg-opacity))}.bg-slate-100{--tw-bg-opacity:1;background-color:rgb(241 245 249/var(--tw-bg-opacity))}.bg-slate-200{--tw-bg-opacity:1;background-color:rgb(226 232 240/var(--tw-bg-opacity))}.bg-white{--tw-bg-opacity:1;background-color:rgb(255 255 255/var(--tw-bg-opacity))}.bg-cover{background-size:cover}.p-3{padding:.75rem}.p-6{padding:1.5rem}.p-8{padding:2rem}.px-1{padding-left:.25rem;padding-right:.25rem}.px-2{padding-left:.5rem;padding-right:.5rem}.px-3{padding-left:.75rem;padding-right:.75rem}.px-4{padding-left:1rem;padding-right:1rem}.px-6{padding-left:1.5rem;padding-right:1.5rem}.py-1{padding-bottom:.25rem;padding-top:.25rem}.py-12{padding-bottom:3rem;padding-top:3rem}.py-2{padding-bottom:.5rem;padding-top:.5rem}.py-3{padding-bottom:.75rem;padding-top:.75rem}.py-6{padding-top:1.5rem}.pb-6,.py-6{padding-bottom:1.5rem}.pt-4{padding-top:1rem}.text-center{text-align:center}.font-mono{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace}.text-2xl{font-size:1.5rem;line-height:2rem}.text-3xl{font-size:1.875rem;line-height:2.25rem}.text-sm{font-size:.875rem;line-height:1.25rem}.text-xl{font-size:1.25rem;line-height:1.75rem}.text-xs{font-size:.75rem;line-height:1rem}.font-bold{font-weight:700}.font-extrabold{font-weight:800}.font-light{font-weight:300}.font-medium{font-weight:500}.font-normal{font-weight:400}.uppercase{text-transform:uppercase}.italic{font-style:italic}.leading-4{line-height:1rem}.tracking-wider{letter-spacing:.05em}.tracking-widest{letter-spacing:.1em}.text-black{--tw-text-opacity:1;color:rgb(0 0 0/var(--tw-text-opacity))}.text-blue-600{--tw-text-opacity:1;color:rgb(37 99 235/var(--tw-text-opacity))}.text-gray-400{--tw-text-opacity:1;color:rgb(156 163 175/var(--tw-text-opacity))}.text-gray-500{--tw-text-opacity:1;color:rgb(107 114 128/var(--tw-text-opacity))}.text-gray-700{--tw-text-opacity:1;color:rgb(55 65 81/var(--tw-text-opacity))}.text-red-600{--tw-text-opacity:1;color:rgb(220 38 38/var(--tw-text-opacity))}.text-slate-400{--tw-text-opacity:1;color:rgb(148 163 184/var(--tw-text-opacity))}.text-white{--tw-text-opacity:1;color:rgb(255 255 255/var(--tw-text-opacity))}.underline{text-decoration-line:underline}.no-underline{text-decoration-line:none}.underline-offset-2{text-underline-offset:2px}.opacity-0{opacity:0}.opacity-100{opacity:1}.shadow{--tw-shadow:0 1px 3px 0 rgba(0,0,0,.1),0 1px 2px -1px rgba(0,0,0,.1);--tw-shadow-colored:0 1px 3px 0 var(--tw-shadow-color),0 1px 2px -1px var(--tw-shadow-color)}.shadow,.shadow-card{box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}.shadow-card{--tw-shadow:0 2px 1px -1px rgba(0,0,0,.2),0 1px 1px 0 rgba(0,0,0,.14),0 1px 3px 0 rgba(0,0,0,.12);--tw-shadow-colored:0 2px 1px -1px var(--tw-shadow-color),0 1px 1px 0 var(--tw-shadow-color),0 1px 3px 0 var(--tw-shadow-color)}.shadow-inner{--tw-shadow:inset 0 2px 4px 0 rgba(0,0,0,.05);--tw-shadow-colored:inset 0 2px 4px 0 var(--tw-shadow-color)}.shadow-inner,.shadow-md{box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}.shadow-md{--tw-shadow:0 4px 6px -1px rgba(0,0,0,.1),0 2px 4px -2px rgba(0,0,0,.1);--tw-shadow-colored:0 4px 6px -1px var(--tw-shadow-color),0 2px 4px -2px var(--tw-shadow-color)}.shadow-sm{--tw-shadow:0 1px 2px 0 rgba(0,0,0,.05);--tw-shadow-colored:0 1px 2px 0 var(--tw-shadow-color);box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}.outline{outline-style:solid}.drop-shadow-md{--tw-drop-shadow:drop-shadow(0 4px 3px rgba(0,0,0,.07)) drop-shadow(0 2px 2px rgba(0,0,0,.06))}.drop-shadow-md,.grayscale{filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}.grayscale{--tw-grayscale:grayscale(100%)}.filter{filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}.transition{transition-duration:.15s;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1)}.transition-all{transition-duration:.15s;transition-property:all;transition-timing-function:cubic-bezier(.4,0,.2,1)}.duration-200{transition-duration:.2s}.duration-500{transition-duration:.5s}.ease-in-out{transition-timing-function:cubic-bezier(.4,0,.2,1)}@media (min-width:640px){.sm\:prose{color:var(--tw-prose-body);max-width:65ch}.sm\:prose :where(p):not(:where([class~=not-prose] *)){margin-bottom:1.25em;margin-top:1.25em}.sm\:prose :where([class~=lead]):not(:where([class~=not-prose] *)){color:var(--tw-prose-lead);font-size:1.25em;line-height:1.6;margin-bottom:1.2em;margin-top:1.2em}.sm\:prose :where(a):not(:where([class~=not-prose] *)){color:#dc2626;font-weight:500;text-decoration:underline}.sm\:prose :where(a):not(:where([class~=not-prose] *)):hover{color:#ef4444}.sm\:prose :where(strong):not(:where([class~=not-prose] *)){color:var(--tw-prose-bold);font-weight:600}.sm\:prose :where(a strong):not(:where([class~=not-prose] *)){color:inherit}.sm\:prose :where(blockquote strong):not(:where([class~=not-prose] *)){color:inherit}.sm\:prose :where(thead th strong):not(:where([class~=not-prose] *)){color:inherit}.sm\:prose :where(ol):not(:where([class~=not-prose] *)){list-style-type:decimal;margin-bottom:1.25em;margin-top:1.25em;padding-left:1.625em}.sm\:prose :where(ol[type=A]):not(:where([class~=not-prose] *)){list-style-type:upper-alpha}.sm\:prose :where(ol[type=a]):not(:where([class~=not-prose] *)){list-style-type:lower-alpha}.sm\:prose :where(ol[type=A s]):not(:where([class~=not-prose] *)){list-style-type:upper-alpha}.sm\:prose :where(ol[type=a s]):not(:where([class~=not-prose] *)){list-style-type:lower-alpha}.sm\:prose :where(ol[type=I]):not(:where([class~=not-prose] *)){list-style-type:upper-roman}.sm\:prose :where(ol[type=i]):not(:where([class~=not-prose] *)){list-style-type:lower-roman}.sm\:prose :where(ol[type=I s]):not(:where([class~=not-prose] *)){list-style-type:upper-roman}.sm\:prose :where(ol[type=i s]):not(:where([class~=not-prose] *)){list-style-type:lower-roman}.sm\:prose :where(ol[type="1"]):not(:where([class~=not-prose] *)){list-style-type:decimal}.sm\:prose :where(ul):not(:where([class~=not-prose] *)){list-style-type:disc;margin-bottom:1.25em;margin-top:1.25em;padding-left:1.625em}.sm\:prose :where(ol>li):not(:where([class~=not-prose] *))::marker{color:var(--tw-prose-counters);font-weight:400}.sm\:prose :where(ul>li):not(:where([class~=not-prose] *))::marker{color:var(--tw-prose-bullets)}.sm\:prose :where(hr):not(:where([class~=not-prose] *)){border-color:var(--tw-prose-hr);border-top-width:1px;margin-bottom:3em;margin-top:3em}.sm\:prose :where(blockquote):not(:where([class~=not-prose] *)){border-left-color:var(--tw-prose-quote-borders);border-left-width:.25rem;color:var(--tw-prose-quotes);font-style:italic;font-weight:500;margin-bottom:1.6em;margin-top:1.6em;padding-left:1em;quotes:"\201C""\201D""\2018""\2019"}.sm\:prose :where(blockquote p:first-of-type):not(:where([class~=not-prose] *)):before{content:open-quote}.sm\:prose :where(blockquote p:last-of-type):not(:where([class~=not-prose] *)):after{content:close-quote}.sm\:prose :where(h1):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-size:2.25em;font-weight:800;line-height:1.1111111;margin-bottom:.8888889em;margin-top:0}.sm\:prose :where(h1 strong):not(:where([class~=not-prose] *)){color:inherit;font-weight:900}.sm\:prose :where(h2):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-size:1.5em;font-weight:700;line-height:1.3333333;margin-bottom:1em;margin-top:2em}.sm\:prose :where(h2 strong):not(:where([class~=not-prose] *)){color:inherit;font-weight:800}.sm\:prose :where(h3):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-size:1.25em;font-weight:600;line-height:1.6;margin-bottom:.6em;margin-top:1.6em}.sm\:prose :where(h3 strong):not(:where([class~=not-prose] *)){color:inherit;font-weight:700}.sm\:prose :where(h4):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-weight:600;line-height:1.5;margin-bottom:.5em;margin-top:1.5em}.sm\:prose :where(h4 strong):not(:where([class~=not-prose] *)){color:inherit;font-weight:700}.sm\:prose :where(img):not(:where([class~=not-prose] *)){margin-bottom:2em;margin-top:2em}.sm\:prose :where(figure>*):not(:where([class~=not-prose] *)){margin-bottom:0;margin-top:0}.sm\:prose :where(figcaption):not(:where([class~=not-prose] *)){color:var(--tw-prose-captions);font-size:.875em;line-height:1.4285714;margin-top:.8571429em}.sm\:prose :where(code):not(:where([class~=not-prose] *)){color:var(--tw-prose-code);font-size:.875em;font-weight:600}.sm\:prose :where(code):not(:where([class~=not-prose] *)):before{content:"`"}.sm\:prose :where(code):not(:where([class~=not-prose] *)):after{content:"`"}.sm\:prose :where(a code):not(:where([class~=not-prose] *)){color:inherit}.sm\:prose :where(h1 code):not(:where([class~=not-prose] *)){color:inherit}.sm\:prose :where(h2 code):not(:where([class~=not-prose] *)){color:inherit;font-size:.875em}.sm\:prose :where(h3 code):not(:where([class~=not-prose] *)){color:inherit;font-size:.9em}.sm\:prose :where(h4 code):not(:where([class~=not-prose] *)){color:inherit}.sm\:prose :where(blockquote code):not(:where([class~=not-prose] *)){color:inherit}.sm\:prose :where(thead th code):not(:where([class~=not-prose] *)){color:inherit}.sm\:prose :where(pre):not(:where([class~=not-prose] *)){background-color:var(--tw-prose-pre-bg);border-radius:.375rem;color:var(--tw-prose-pre-code);font-size:.875em;font-weight:400;line-height:1.7142857;margin-bottom:1.7142857em;margin-top:1.7142857em;overflow-x:auto;padding:.8571429em 1.1428571em}.sm\:prose :where(pre code):not(:where([class~=not-prose] *)){background-color:transparent;border-radius:0;border-width:0;color:inherit;font-family:inherit;font-size:inherit;font-weight:inherit;line-height:inherit;padding:0}.sm\:prose :where(pre code):not(:where([class~=not-prose] *)):before{content:none}.sm\:prose :where(pre code):not(:where([class~=not-prose] *)):after{content:none}.sm\:prose :where(table):not(:where([class~=not-prose] *)){font-size:.875em;line-height:1.7142857;margin-bottom:2em;margin-top:2em;table-layout:auto;text-align:left;width:100%}.sm\:prose :where(thead):not(:where([class~=not-prose] *)){border-bottom-color:var(--tw-prose-th-borders);border-bottom-width:1px}.sm\:prose :where(thead th):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-weight:600;padding-bottom:.5714286em;padding-left:.5714286em;padding-right:.5714286em;vertical-align:bottom}.sm\:prose :where(tbody tr):not(:where([class~=not-prose] *)){border-bottom-color:var(--tw-prose-td-borders);border-bottom-width:1px}.sm\:prose :where(tbody tr:last-child):not(:where([class~=not-prose] *)){border-bottom-width:0}.sm\:prose :where(tbody td):not(:where([class~=not-prose] *)){vertical-align:baseline}.sm\:prose :where(tfoot):not(:where([class~=not-prose] *)){border-top-color:var(--tw-prose-th-borders);border-top-width:1px}.sm\:prose :where(tfoot td):not(:where([class~=not-prose] *)){vertical-align:top}.sm\:prose{--tw-prose-body:#374151;--tw-prose-headings:#111827;--tw-prose-lead:#4b5563;--tw-prose-links:#111827;--tw-prose-bold:#111827;--tw-prose-counters:#6b7280;--tw-prose-bullets:#d1d5db;--tw-prose-hr:#e5e7eb;--tw-prose-quotes:#111827;--tw-prose-quote-borders:#e5e7eb;--tw-prose-captions:#6b7280;--tw-prose-code:#111827;--tw-prose-pre-code:#e5e7eb;--tw-prose-pre-bg:#1f2937;--tw-prose-th-borders:#d1d5db;--tw-prose-td-borders:#e5e7eb;--tw-prose-invert-body:#d1d5db;--tw-prose-invert-headings:#fff;--tw-prose-invert-lead:#9ca3af;--tw-prose-invert-links:#fff;--tw-prose-invert-bold:#fff;--tw-prose-invert-counters:#9ca3af;--tw-prose-invert-bullets:#4b5563;--tw-prose-invert-hr:#374151;--tw-prose-invert-quotes:#f3f4f6;--tw-prose-invert-quote-borders:#374151;--tw-prose-invert-captions:#9ca3af;--tw-prose-invert-code:#fff;--tw-prose-invert-pre-code:#d1d5db;--tw-prose-invert-pre-bg:rgba(0,0,0,.5);--tw-prose-invert-th-borders:#4b5563;--tw-prose-invert-td-borders:#374151;font-size:1rem;line-height:1.75}.sm\:prose :where(video):not(:where([class~=not-prose] *)){margin-bottom:2em;margin-top:2em}.sm\:prose :where(figure):not(:where([class~=not-prose] *)){margin-bottom:2em;margin-top:2em}.sm\:prose :where(li):not(:where([class~=not-prose] *)){margin-bottom:.5em;margin-top:.5em}.sm\:prose :where(ol>li):not(:where([class~=not-prose] *)){padding-left:.375em}.sm\:prose :where(ul>li):not(:where([class~=not-prose] *)){padding-left:.375em}.sm\:prose :where(.sm\:prose>ul>li p):not(:where([class~=not-prose] *)){margin-bottom:.75em;margin-top:.75em}.sm\:prose :where(.sm\:prose>ul>li>:first-child):not(:where([class~=not-prose] *)){margin-top:1.25em}.sm\:prose :where(.sm\:prose>ul>li>:last-child):not(:where([class~=not-prose] *)){margin-bottom:1.25em}.sm\:prose :where(.sm\:prose>ol>li>:first-child):not(:where([class~=not-prose] *)){margin-top:1.25em}.sm\:prose :where(.sm\:prose>ol>li>:last-child):not(:where([class~=not-prose] *)){margin-bottom:1.25em}.sm\:prose :where(ul ul,ul ol,ol ul,ol ol):not(:where([class~=not-prose] *)){margin-bottom:.75em;margin-top:.75em}.sm\:prose :where(hr+*):not(:where([class~=not-prose] *)){margin-top:0}.sm\:prose :where(h2+*):not(:where([class~=not-prose] *)){margin-top:0}.sm\:prose :where(h3+*):not(:where([class~=not-prose] *)){margin-top:0}.sm\:prose :where(h4+*):not(:where([class~=not-prose] *)){margin-top:0}.sm\:prose :where(thead th:first-child):not(:where([class~=not-prose] *)){padding-left:0}.sm\:prose :where(thead th:last-child):not(:where([class~=not-prose] *)){padding-right:0}.sm\:prose :where(tbody td,tfoot td):not(:where([class~=not-prose] *)){padding:.5714286em}.sm\:prose :where(tbody td:first-child,tfoot td:first-child):not(:where([class~=not-prose] *)){padding-left:0}.sm\:prose :where(tbody td:last-child,tfoot td:last-child):not(:where([class~=not-prose] *)){padding-right:0}.sm\:prose :where(.sm\:prose>:first-child):not(:where([class~=not-prose] *)){margin-top:0}.sm\:prose :where(.sm\:prose>:last-child):not(:where([class~=not-prose] *)){margin-bottom:0}}.last\:mr-0:last-child{margin-right:0}.hover\:-translate-y-1:hover{--tw-translate-y:-0.25rem}.hover\:-translate-y-1:hover,.hover\:scale-105:hover{transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.hover\:scale-105:hover{--tw-scale-x:1.05;--tw-scale-y:1.05}.hover\:border-gray-400:hover{--tw-border-opacity:1;border-color:rgb(156 163 175/var(--tw-border-opacity))}.hover\:border-white:hover{--tw-border-opacity:1;border-color:rgb(255 255 255/var(--tw-border-opacity))}.hover\:bg-black:hover{--tw-bg-opacity:1;background-color:rgb(0 0 0/var(--tw-bg-opacity))}.hover\:bg-gray-800:hover{--tw-bg-opacity:1;background-color:rgb(31 41 55/var(--tw-bg-opacity))}.hover\:bg-red-500:hover{--tw-bg-opacity:1;background-color:rgb(239 68 68/var(--tw-bg-opacity))}.hover\:bg-white:hover{--tw-bg-opacity:1;background-color:rgb(255 255 255/var(--tw-bg-opacity))}.hover\:text-black:hover{--tw-text-opacity:1;color:rgb(0 0 0/var(--tw-text-opacity))}.hover\:text-gray-500:hover{--tw-text-opacity:1;color:rgb(107 114 128/var(--tw-text-opacity))}.hover\:text-red-600:hover{--tw-text-opacity:1;color:rgb(220 38 38/var(--tw-text-opacity))}.hover\:text-white:hover{--tw-text-opacity:1;color:rgb(255 255 255/var(--tw-text-opacity))}.hover\:underline:hover{text-decoration-line:underline}.group:hover .group-hover\:inline-block{display:inline-block}@media (min-width:640px){.sm\:left-auto{left:auto}.sm\:mb-0{margin-bottom:0}.sm\:mr-6{margin-right:1.5rem}.sm\:flex{display:flex}.sm\:h-20{height:5rem}.sm\:h-auto{height:auto}.sm\:w-2\/5{width:40%}.sm\:w-20{width:5rem}.sm\:w-3\/5{width:60%}.sm\:w-64{width:16rem}.sm\:flex-1{flex:1 1 0%}.sm\:-translate-x-1\/2{--tw-translate-x:-50%;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.sm\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}.sm\:flex-row{flex-direction:row}.sm\:items-start{align-items:flex-start}.sm\:items-center{align-items:center}.sm\:px-12{padding-left:3rem;padding-right:3rem}.sm\:text-left{text-align:left}}@media (min-width:1024px){.lg\:w-1\/4{width:25%}.lg\:w-3\/4{width:75%}.lg\:grid-cols-3{grid-template-columns:repeat(3,minmax(0,1fr))}}.\[\&\>h2\>a\]\:invisible>h2>a{visibility:hidden}.\[\&\>h2\>a\]\:hidden>h2>a{display:none}.\[\&\>h2\>a\]\:h-0>h2>a{height:0}.\[\&\>h2\>a\]\:w-0>h2>a{width:0}.\[\&\>h2\>a\]\:overflow-hidden>h2>a{overflow:hidden}.\[\&\>h2\>a\]\:opacity-0>h2>a{opacity:0}.\[\&\>h2\]\:inline>h2{display:inline}.\[\&\>p\]\:m-0>p{margin:0}.\[\&\>p\]\:inline>p{display:inline}code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;color:#f8f8f2;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;text-align:left;text-shadow:0 1px rgba(0,0,0,.3);white-space:pre;word-break:normal;word-spacing:normal}pre[class*=language-]{border-radius:.3em;margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#272822}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#8292a2}.token.punctuation{color:#f8f8f2}.token.namespace{opacity:.7}.token.constant,.token.deleted,.token.property,.token.symbol,.token.tag{color:#f92672}.token.boolean,.token.number{color:#ae81ff}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#a6e22e}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url,.token.variable{color:#f8f8f2}.token.atrule,.token.attr-value,.token.class-name,.token.function{color:#e6db74}.token.keyword{color:#66d9ef}.token.important,.token.regex{color:#fd971f}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.post--2021--binary-floating-point--bit-button:hover{box-shadow:0 0 5px 1px rgba(0,0,0,.2);transition:box-shadow .2s ease-in-out}.custom-fade-in-opacity{animation-duration:.8s;animation-iteration-count:1;animation-name:customFadeInOpacity;animation-timing-function:ease-out;opacity:1}@keyframes customFadeInOpacity{0%{opacity:0}to{opacity:1}}input:checked~.toggle__dot{transform:translateX(100%)}input:checked~.toggle__line{background-color:#48bb78}.post--2021--water-line--gyro-cube .gyro-cube-container{align-items:center;display:flex;height:400px;justify-content:center;perspective:800px;perspective-origin:50%}.post--2021--water-line--gyro-cube .gyro-cube{height:200px;position:relative;transform-style:preserve-3d;width:200px}.post--2021--water-line--gyro-cube .gyro-cube-side{align-items:center;border:2px solid #fff;color:#fff;display:flex;font-size:100px;font-weight:700;height:100%;justify-content:center;opacity:.8;position:absolute;width:100%}.post--2021--water-line--gyro-cube .gyro-cube-front{background-color:#d50000;transform:translateZ(100px)}.post--2021--water-line--gyro-cube .gyro-cube-back{background-color:#a0f;transform:translateZ(-100px)}.post--2021--water-line--gyro-cube .gyro-cube-left{background-color:#304ffe;transform:translateX(100px) rotateY(90deg)}.post--2021--water-line--gyro-cube .gyro-cube-right{background-color:#0091ea;transform:translateX(-100px) rotateY(90deg)}.post--2021--water-line--gyro-cube .gyro-cube-top{background-color:#00bfa5;transform:translateY(-100px) rotateX(90deg)}.post--2021--water-line--gyro-cube .gyro-cube-bottom{background-color:#64dd17;transform:translateY(100px) rotateX(90deg)}.react-flow__container{height:100%;left:0;position:absolute;top:0;width:100%}.react-flow__pane{cursor:grab;z-index:1}.react-flow__pane.selection{cursor:pointer}.react-flow__pane.dragging{cursor:grabbing}.react-flow__viewport{pointer-events:none;transform-origin:0 0;z-index:2}.react-flow__renderer{z-index:4}.react-flow__selection{z-index:6}.react-flow__nodesselection-rect:focus,.react-flow__nodesselection-rect:focus-visible{outline:none}.react-flow .react-flow__edges{overflow:visible;pointer-events:none}.react-flow__connection-path,.react-flow__edge-path{stroke:#b1b1b7;stroke-width:1;fill:none}.react-flow__edge{cursor:pointer;pointer-events:visibleStroke}.react-flow__edge.animated path{stroke-dasharray:5;animation:dashdraw .5s linear infinite}.react-flow__edge.animated path.react-flow__edge-interaction{stroke-dasharray:none;animation:none}.react-flow__edge.inactive{pointer-events:none}.react-flow__edge.selected,.react-flow__edge:focus,.react-flow__edge:focus-visible{outline:none}.react-flow__edge.selected .react-flow__edge-path,.react-flow__edge:focus .react-flow__edge-path,.react-flow__edge:focus-visible .react-flow__edge-path{stroke:#555}.react-flow__edge-textwrapper{pointer-events:all}.react-flow__edge-textbg{fill:#fff}.react-flow__edge .react-flow__edge-text{pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.react-flow__connection{pointer-events:none}.react-flow__connection .animated{stroke-dasharray:5;animation:dashdraw .5s linear infinite}.react-flow__connectionline{z-index:1001}.react-flow__nodes{pointer-events:none;transform-origin:0 0}.react-flow__node{box-sizing:border-box;cursor:grab;pointer-events:all;position:absolute;transform-origin:0 0;-webkit-user-select:none;-moz-user-select:none;user-select:none}.react-flow__node.dragging{cursor:grabbing}.react-flow__nodesselection{pointer-events:none;transform-origin:left top;z-index:3}.react-flow__nodesselection-rect{cursor:grab;pointer-events:all;position:absolute}.react-flow__handle{background:#1a192b;border:1px solid #fff;border-radius:100%;height:6px;min-height:5px;min-width:5px;pointer-events:none;position:absolute;width:6px}.react-flow__handle.connectionindicator{cursor:crosshair;pointer-events:all}.react-flow__handle-bottom{bottom:-4px;left:50%;top:auto;transform:translate(-50%)}.react-flow__handle-top{left:50%;top:-4px;transform:translate(-50%)}.react-flow__handle-left{left:-4px;top:50%;transform:translateY(-50%)}.react-flow__handle-right{right:-4px;top:50%;transform:translateY(-50%)}.react-flow__edgeupdater{cursor:move;pointer-events:all}.react-flow__panel{margin:15px;position:absolute;z-index:5}.react-flow__panel.top{top:0}.react-flow__panel.bottom{bottom:0}.react-flow__panel.left{left:0}.react-flow__panel.right{right:0}.react-flow__panel.center{left:50%;transform:translateX(-50%)}.react-flow__attribution{background:hsla(0,0%,100%,.5);font-size:10px;margin:0;padding:2px 3px}.react-flow__attribution a{color:#999;text-decoration:none}@keyframes dashdraw{0%{stroke-dashoffset:10}}.react-flow__edgelabel-renderer{height:100%;pointer-events:none;position:absolute;-webkit-user-select:none;-moz-user-select:none;user-select:none;width:100%}.react-flow__edge.updating .react-flow__edge-path{stroke:#777}.react-flow__edge-text{font-size:10px}.react-flow__node.selectable:focus,.react-flow__node.selectable:focus-visible{outline:none}.react-flow__node-default,.react-flow__node-group,.react-flow__node-input,.react-flow__node-output{background-color:#fff;border:1px solid #1a192b;border-radius:3px;color:#222;font-size:12px;padding:10px;text-align:center;width:150px}.react-flow__node-default.selectable:hover,.react-flow__node-group.selectable:hover,.react-flow__node-input.selectable:hover,.react-flow__node-output.selectable:hover{box-shadow:0 1px 4px 1px rgba(0,0,0,.08)}.react-flow__node-default.selectable.selected,.react-flow__node-default.selectable:focus,.react-flow__node-default.selectable:focus-visible,.react-flow__node-group.selectable.selected,.react-flow__node-group.selectable:focus,.react-flow__node-group.selectable:focus-visible,.react-flow__node-input.selectable.selected,.react-flow__node-input.selectable:focus,.react-flow__node-input.selectable:focus-visible,.react-flow__node-output.selectable.selected,.react-flow__node-output.selectable:focus,.react-flow__node-output.selectable:focus-visible{box-shadow:0 0 0 .5px #1a192b}.react-flow__node-group{background-color:hsla(0,0%,94%,.25)}.react-flow__nodesselection-rect,.react-flow__selection{background:rgba(0,89,220,.08);border:1px dotted rgba(0,89,220,.8)}.react-flow__nodesselection-rect:focus,.react-flow__nodesselection-rect:focus-visible,.react-flow__selection:focus,.react-flow__selection:focus-visible{outline:none}.react-flow__controls{box-shadow:0 0 2px 1px rgba(0,0,0,.08)}.react-flow__controls-button{align-items:center;background:#fefefe;border:none;border-bottom:1px solid #eee;box-sizing:content-box;cursor:pointer;display:flex;height:16px;justify-content:center;padding:5px;-webkit-user-select:none;-moz-user-select:none;user-select:none;width:16px}.react-flow__controls-button:hover{background:#f4f4f4}.react-flow__controls-button svg{max-height:12px;max-width:12px;width:100%}.react-flow__controls-button:disabled{pointer-events:none}.react-flow__controls-button:disabled svg{fill-opacity:.4}.react-flow__minimap{background-color:#fff}.react-flow__resize-control{position:absolute}.react-flow__resize-control.left,.react-flow__resize-control.right{cursor:ew-resize}.react-flow__resize-control.bottom,.react-flow__resize-control.top{cursor:ns-resize}.react-flow__resize-control.bottom.right,.react-flow__resize-control.top.left{cursor:nwse-resize}.react-flow__resize-control.bottom.left,.react-flow__resize-control.top.right{cursor:nesw-resize}.react-flow__resize-control.handle{background-color:#3367d9;border:1px solid #fff;border-radius:1px;height:4px;transform:translate(-50%,-50%);width:4px}.react-flow__resize-control.handle.left{left:0;top:50%}.react-flow__resize-control.handle.right{left:100%;top:50%}.react-flow__resize-control.handle.top{left:50%;top:0}.react-flow__resize-control.handle.bottom{left:50%;top:100%}.react-flow__resize-control.handle.bottom.left,.react-flow__resize-control.handle.top.left{left:0}.react-flow__resize-control.handle.bottom.right,.react-flow__resize-control.handle.top.right{left:100%}.react-flow__resize-control.line{border:0 solid #3367d9}.react-flow__resize-control.line.left,.react-flow__resize-control.line.right{height:100%;top:0;transform:translate(-50%);width:1px}.react-flow__resize-control.line.left{border-left-width:1px;left:0}.react-flow__resize-control.line.right{border-right-width:1px;left:100%}.react-flow__resize-control.line.bottom,.react-flow__resize-control.line.top{height:1px;left:0;transform:translateY(-50%);width:100%}.react-flow__resize-control.line.top{border-top-width:1px;top:0}.react-flow__resize-control.line.bottom{border-bottom-width:1px;top:100%}</style><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><title data-react-helmet="true">Making the Printed Links Clickable Using TensorFlow 2 Object Detection API | Trekhleb</title><style type="text/css">
    .gatsby-remark-autolink-header-anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .gatsby-remark-autolink-header-anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .gatsby-remark-autolink-header-anchor svg,
    h2 .gatsby-remark-autolink-header-anchor svg,
    h3 .gatsby-remark-autolink-header-anchor svg,
    h4 .gatsby-remark-autolink-header-anchor svg,
    h5 .gatsby-remark-autolink-header-anchor svg,
    h6 .gatsby-remark-autolink-header-anchor svg {
      visibility: hidden;
    }
    h1:hover .gatsby-remark-autolink-header-anchor svg,
    h2:hover .gatsby-remark-autolink-header-anchor svg,
    h3:hover .gatsby-remark-autolink-header-anchor svg,
    h4:hover .gatsby-remark-autolink-header-anchor svg,
    h5:hover .gatsby-remark-autolink-header-anchor svg,
    h6:hover .gatsby-remark-autolink-header-anchor svg,
    h1 .gatsby-remark-autolink-header-anchor:focus svg,
    h2 .gatsby-remark-autolink-header-anchor:focus svg,
    h3 .gatsby-remark-autolink-header-anchor:focus svg,
    h4 .gatsby-remark-autolink-header-anchor:focus svg,
    h5 .gatsby-remark-autolink-header-anchor:focus svg,
    h6 .gatsby-remark-autolink-header-anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link rel="alternate" type="application/rss+xml" title="Trekhleb.dev RSS Feed" href="/rss.xml"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><main class="flex flex-col items-center"><div class="max-w-screen-xl self-stretch m-auto w-full"><header class="flex flex-row items-center px-6 sm:px-12 py-6"><div class="mr-6"><div><a class="transition duration-200 ease-in-out flex flex-row items-center hover:text-red-600 font-extrabold text-sm tracking-widest uppercase" href="/">Trekhleb</a></div></div><nav><ul class="flex flex-row"><li class="ml-5"><a class="transition duration-200 ease-in-out flex flex-row items-center hover:text-red-600 uppercase text-xs" href="/projects/">Projects</a></li><li class="ml-5"><a class="transition duration-200 ease-in-out flex flex-row items-center hover:text-red-600 uppercase text-xs" href="/blog/">Blog</a></li><li class="ml-5"><a class="transition duration-200 ease-in-out flex flex-row items-center hover:text-red-600 uppercase text-xs" href="/publications/">Publications</a></li></ul></nav></header><article class="px-6 sm:px-12 py-6"><div class="flex flex-col items-center"><article class="w-full prose prose-sm sm:prose overflow-hidden prose-red" style="max-width:860px"><h1 class="text-3xl mb-6 uppercase font-extrabold ">Making the Printed Links Clickable Using TensorFlow 2 Object Detection API</h1><div class="flex flex-row items-center "><div class="flex flex-row items-center mr-6 mb-6 text-gray-500 text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="mr-1" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>01 December, 2020</div></div><span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACOklEQVR42o2SS0sbURSAYxKVFOlGxI1LYxBR0X+g4EYCLnQp6KqPEBGbgl3UFNouUorLgK1WcNFNogW1ijChr0StpSWWJjWpYzJOZjLxNSHzB74yk1aKuOji49zL4X6cc8+x2Ww2rsNut1uxu7ubxcVFdnd32d/fJ5PJIIoi6XSaZDLJ5uYm4XCY8fFx6urqzDc2ampqLrkqbG9vZ2lpiWw2y8HBAYqioGkaqqoiy7IlXV1dxe/343Q6q8KrmAmXy2Wde3p6iEQiSJJkSSqVCrquUzEMLnTd4ugoRzD4iPr6+qqwsbGRlpYWWltbaWpqYmhoiLGxMUvY0dFBLBajXC5zcnKCYRicn59R1i8wjDKlkoqmqYRCIRoaGqrCzs5OSzI6OsrAwAB9fX0MDg5e/uH6+jqlUglZPqaonaFKe+SSMxx+DZLaeUDm8zTPnt7GdeNmVWi25fP5GB4exuv1MjIyQn9//2WF0WgUpVAgn88hywWKiogqJTgWP5FNC6SSG8w8DGC3O6rC5uZment7rWpMurq6cLvdltCMCwuvSP88JC8VkY6L5CWNgqqTk075/kMknthjaiqAw/FHaE60trbWGsZfzLuZa2vzMDv7nF+pt8iigJJ7R1F6j5KLUTiKcZh6g7D1Gv/EJE6n4/op/7s2bncbTx4H2d6a5OPaHb7EAhbfPkyzJ9wjsXGLtWgI/0Tg/4Qej4dA4D5zcy9YWVkhHo+T2E6wvbODIAgsLy/zcn4en++utYe/AdR9wIxZE16JAAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Links Detector Cover"
        title=""
        src="/static/745b6101a4bb0c212288c868617942b8/00d43/27.png"
        srcset="/static/745b6101a4bb0c212288c868617942b8/63868/27.png 250w,
/static/745b6101a4bb0c212288c868617942b8/0b533/27.png 500w,
/static/745b6101a4bb0c212288c868617942b8/00d43/27.png 1000w,
/static/745b6101a4bb0c212288c868617942b8/21b4d/27.png 1280w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<h2 id="-tldr" style="position:relative"> TL;DR<a href="#-tldr" aria-label=" tldr permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p><em>In this article we will start solving the issue of making the printed links (i.e. in a book or in a magazine) clickable via your smartphone camera.</em></p>
<p>We will use <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">TensorFlow 2 Object Detection API</a> to train a custom object detector model to find positions and bounding boxes of the sub-strings like <span><code class="language-text">https://</code></span> in the text image (i.e. in smartphone camera stream).</p>
<p>The text of each link (right continuation of <span><code class="language-text">https://</code></span> bounding box) will be recognized by using <a href="https://tesseract.projectnaptha.com/">Tesseract</a> library. The recognition part will not be covered in this article, but you may find the complete code example of the application in <a href="https://github.com/trekhleb/links-detector">links-detector repository</a>.</p>
<blockquote>
<p> <a href="https://trekhleb.dev/links-detector/">Launch Links Detector demo</a> from your smartphone to see the final result.</p>
</blockquote>
<blockquote>
<p> <a href="https://github.com/trekhleb/links-detector">Open links-detector repository</a> on GitHub to see the complete source code of the application.</p>
</blockquote>
<p>Here is how the final solution will look like:</p>
<img src="/posts-assets/4e839b39a53cf12e04da75a283aadc60/02-demo.gif" alt="Links Detector Demo"/>
<blockquote>
<p> Currently the application is in <em>experimental</em> <em>Alpha</em> stage and has <a href="https://github.com/trekhleb/links-detector/issues?q=is%3Aopen+is%3Aissue+label%3Aenhancement">many issues and limitations</a>. So don&#x27;t raise your expectations level too high until these issues are resolved . Also, the purpose of this article is more about learning how to work with TensorFlow 2 Object Detection API rather than coming up with a production-ready model.</p>
</blockquote>
<blockquote>
<p>In case if Python code blocks in this article will lack proper formatting on this platform feel free to <a href="https://github.com/trekhleb/links-detector/blob/master/articles/printed_links_detection/printed_links_detection.md">to read the article on GitHub</a></p>
</blockquote>
<h2 id="-the-problem" style="position:relative"> The Problem<a href="#%EF%B8%8F-the-problem" aria-label=" the problem permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>I work as a software engineer and in my own time, I learn Machine Learning as a hobby. But this is not the problem yet.</p>
<p>I bought a printed book about Machine Learning recently and while I was reading through the first several chapters I&#x27;ve encountered many printed links in the text that looked like <span><code class="language-text">https://tensorflow.org/</code></span> or <span><code class="language-text">https://some-url.com/which/may/be/even/longer?and_with_params=true</code></span>.</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 43.2%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAIDBP/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHSglKx/8QAFhAAAwAAAAAAAAAAAAAAAAAAACAh/9oACAEBAAEFAir/AP/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABkQAAMBAQEAAAAAAAAAAAAAAAABQREQMf/aAAgBAQABPyFa7w92kIP0/9oADAMBAAIAAwAAABBAz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQACAgMAAAAAAAAAAAAAAAEAERCBIUGx/9oACAEBAAE/EEFmlx4du4jB8Rxv/9k='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Printed Links"
        title=""
        src="/static/0c4381cbec209c0614c9a8e89dc64425/a2510/0.jpg"
        srcset="/static/0c4381cbec209c0614c9a8e89dc64425/0479a/0.jpg 250w,
/static/0c4381cbec209c0614c9a8e89dc64425/41099/0.jpg 500w,
/static/0c4381cbec209c0614c9a8e89dc64425/a2510/0.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>I saw all these links, but I couldn&#x27;t click on them since they were printed (thanks, cap!). To visit these links I needed to start typing them character by character in the browser&#x27;s address bar, which was pretty annoying and error-prone.</p>
<h2 id="-possible-solution" style="position:relative"> Possible Solution<a href="#-possible-solution" aria-label=" possible solution permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>So, I was thinking, what if, similarly to QR-code detection, we will try to &quot;teach&quot; the smartphone to <em>(1)</em> <em>detect</em> and <em>(2)</em> <em>recognize</em> printed links for us and to make them <em>clickable</em>? This way you would do just one click instead of multiple keystrokes. The operational complexity of &quot;clicking&quot; the printed links goes from <span><code class="language-text">O(N)</code></span> to <span><code class="language-text">O(1)</code></span>.</p>
<p>This is how the final workflow will look like:</p>
<img src="/posts-assets/2dc300f4cc152c8b14200c25eba77a02/1.gif" alt="Links Detector Demo"/>
<h2 id="-solution-requirements" style="position:relative"> Solution Requirements<a href="#-solution-requirements" aria-label=" solution requirements permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>As I&#x27;ve mentioned earlier I&#x27;m just studying Machine Learning as a hobby. Thus, the purpose of this article is more about <em>learning</em> how to work with TensorFlow 2 Object Detection API rather than coming up with a production-ready application.</p>
<p>With that being said, I simplified the solution requirements to the following:</p>
<ol>
<li>The detection and recognition processes should have a <strong>close-to-real-time</strong> performance (i.e. <span><code class="language-text">0.5-1</code></span> frames per second) on a device like iPhone X. It means that the whole <em>detection + recognition</em> process should take up to <span><code class="language-text">2</code></span> seconds (pretty bearable as for the amateur project).</li>
<li>Only <strong>English</strong> links should be supported.</li>
<li>Only <strong>dark text</strong> (i.e. black or dark-grey) on <strong>light background</strong> (i.e. white or light-grey) should be supported.</li>
<li>Only <span><code class="language-text">https://</code></span> links should be supported for now (it is ok if our model will not recognize the <span><code class="language-text">http://</code></span>, <span><code class="language-text">ftp://</code></span>, <span><code class="language-text">tcp://</code></span> or other types of links).</li>
</ol>
<h2 id="-solution-breakdown" style="position:relative"> Solution Breakdown<a href="#-solution-breakdown" aria-label=" solution breakdown permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<h3 id="high-level-breakdown" style="position:relative">High-level breakdown<a href="#high-level-breakdown" aria-label="high level breakdown permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>Let&#x27;s see how we could approach the problem on a high level.</p>
<h4 id="option-1-detection-model-on-the-back-end" style="position:relative">Option 1: Detection model on the back-end<a href="#option-1-detection-model-on-the-back-end" aria-label="option 1 detection model on the back end permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h4>
<p><strong>The flow:</strong></p>
<ol>
<li>Get camera stream (frame by frame) on the client-side.</li>
<li>Send each frame one by one over the network to the back-end.</li>
<li>Do link detection and recognition on the back-end and send the response back to the client.</li>
<li>Client draws the detection boxes with the clickable links.</li>
</ol>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 76.4%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAgABBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe4zg4x//8QAGRAAAgMBAAAAAAAAAAAAAAAAABEBECFC/9oACAEBAAEFAuqWog//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAVEAEBAAAAAAAAAAAAAAAAAAAgMf/aAAgBAQAGPwKr/8QAGxAAAwACAwAAAAAAAAAAAAAAAAERMUFRYXH/2gAIAQEAAT8hjXZoqMjpHwVH6I5k/9oADAMBAAIAAwAAABCzD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABoQAQEBAQEBAQAAAAAAAAAAAAERACExUUH/2gAIAQEAAT8QAVaVnJaQ44QCNH93dZ8T3WBh6ITmCQEPpv/Z'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Model on the back-end"
        title=""
        src="/static/b1008fc4187f646645a88963ab5d842e/a2510/2.jpg"
        srcset="/static/b1008fc4187f646645a88963ab5d842e/0479a/2.jpg 250w,
/static/b1008fc4187f646645a88963ab5d842e/41099/2.jpg 500w,
/static/b1008fc4187f646645a88963ab5d842e/a2510/2.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p><strong>Pros:</strong></p>
<ul>
<li> The detection performance is not limited by the client&#x27;s device. We may speed the detection up by scaling the service horizontally (adding more instances) and vertically (adding more cores/GPUs).</li>
<li> The model might be bigger since there is no need to upload it to the client-side. Downloading the <span><code class="language-text">~10Mb</code></span> model on the client-side may be ok, but loading the <span><code class="language-text">~100Mb</code></span> model might be a big issue for the client&#x27;s network and application UX (user experience) otherwise.</li>
<li> It is possible to control who is using the model. Model is guarded behind the API, so we would have complete control over its callers/clients.</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li> System complexity growth. The application tech stack grew from just <span><code class="language-text">JavaScript</code></span> to, let&#x27;s say, <span><code class="language-text">JavaScript + Python</code></span>. We need to take care of the autoscaling.</li>
<li> Offline mode for the app is not possible since it needs an internet connection to work.</li>
<li> Too many HTTP requests between the client and the server may become a bottleneck at some point. Imagine if we would want to improve the performance of the detection, let&#x27;s say, from <span><code class="language-text">1</code></span> to <span><code class="language-text">10+</code></span> frames per second. This means that each client will send <span><code class="language-text">10+</code></span> requests per second. For <span><code class="language-text">10</code></span> simultaneous clients it is already <span><code class="language-text">100+</code></span> requests per second. The <span><code class="language-text">HTTP/2</code></span> bidirectional streaming and <span><code class="language-text">gRPC</code></span> might be useful in this case, but we&#x27;re going back to the increased system complexity here.</li>
<li> System becomes more expensive. Almost all points from the Pros section need to be paid for.</li>
</ul>
<h4 id="option-2-detection-model-on-the-front-end" style="position:relative">Option 2: Detection model on the front-end<a href="#option-2-detection-model-on-the-front-end" aria-label="option 2 detection model on the front end permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h4>
<p><strong>The flow:</strong></p>
<ol>
<li>Get camera stream (frame by frame) on the client-side.</li>
<li>Do link detection and recognition on the client-side (without sending anything to the back-end).</li>
<li>Client draws the detection boxes with the clickable links.</li>
</ol>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 104.4%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAVABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAECAwX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAAB7ldc41FRULA//8QAGhAAAgIDAAAAAAAAAAAAAAAAARAAEQISIv/aAAgBAQABBQLKC9kD0qX/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAY/Ah//xAAZEAEBAQADAAAAAAAAAAAAAAARARAAIUH/2gAIAQEAAT8hZ1z2JtHGbZXP/9oADAMBAAIAAwAAABCoCHz/xAAVEQEBAAAAAAAAAAAAAAAAAAAQAf/aAAgBAwEBPxAh/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAGRABAQADAQAAAAAAAAAAAAAAAREQIUEA/9oACAEBAAE/EETvV55GNg7lSIKk7DLpKLj/2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Model on the front-end"
        title=""
        src="/static/9d35d51a8edae4727238f9dc487ab5e1/a2510/3.jpg"
        srcset="/static/9d35d51a8edae4727238f9dc487ab5e1/0479a/3.jpg 250w,
/static/9d35d51a8edae4727238f9dc487ab5e1/41099/3.jpg 500w,
/static/9d35d51a8edae4727238f9dc487ab5e1/a2510/3.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p><strong>Pros:</strong></p>
<ul>
<li> System is less complex. We don&#x27;t need to set up the servers, build the API, and introduce an additional Python stack to the system.</li>
<li> Offline mode is possible. The app doesn&#x27;t need an internet connection to work since the model is fully loaded to the device. So the Progressive Web Application (<a href="https://web.dev/progressive-web-apps/">PWA</a>) might be built to support that.</li>
<li> System is &quot;kind of&quot; scaling automatically. The more clients you have, the more cores and GPUs they bring. This is not a proper scaling solution though (more about that in a Cons section below).</li>
<li> System is cheaper. We only need a server for static assets (<span><code class="language-text">HTML</code></span>, <span><code class="language-text">JS</code></span>, <span><code class="language-text">CSS</code></span>, model files, etc.). This may be done for free, let&#x27;s say, on GitHub.</li>
<li> No issue with the growing number of HTTP requests per second to the server-side.</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li> Only horizontal scaling is possible (each client will have its own CPU/GPU). Vertical scaling is not possible since we can&#x27;t influence the client&#x27;s device performance. As a result, we can&#x27;t guarantee fast detection for low performant devices.</li>
<li> It is not possible to guard the model usage and control the callers/clients of the model. Everyone could download the model and re-use it.</li>
<li> Battery consumption of the client&#x27;s device might become an issue. For the model to work it needs computational resources. So clients might not be happy with their iPhone getting warmer and warmer while the app is working.</li>
</ul>
<h4 id="high-level-conclusion" style="position:relative">High-level conclusion<a href="#high-level-conclusion" aria-label="high level conclusion permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h4>
<p>Since the purpose of the project was more about learning and not coming up with a production-ready solution <em>I decided to go with the second option of serving the model from the client side</em>. This made the whole project much cheaper (actually with GitHub it was free to host it), and I could focus more on Machine Learning than on the autoscaling back-end infrastructure.</p>
<h3 id="lower-level-breakdown" style="position:relative">Lower level breakdown<a href="#lower-level-breakdown" aria-label="lower level breakdown permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>Ok, so we&#x27;ve decided to go with the serverless solution. Now we have an image from the camera stream as an input that looks something like this:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBP/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHrYsaYCBQf/8QAGRAAAgMBAAAAAAAAAAAAAAAAABEBECAh/9oACAEBAAEFAq7lyM//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAY/Ah//xAAcEAACAgIDAAAAAAAAAAAAAAAAARFREDEhYYH/2gAIAQEAAT8hl2S7Z6N5XC2zuJWf/9oADAMBAAIAAwAAABCE133/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAeEAEBAQACAQUAAAAAAAAAAAABEQAhQZExUXGB0f/aAAgBAQABPxBqxS++atxO/g4Wksu5Pk156+9YJ5Mg+vJv4N//2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Printed Links Input"
        title=""
        src="/static/ad6a433499d46bf50b63d69734154c37/a2510/4.jpg"
        srcset="/static/ad6a433499d46bf50b63d69734154c37/0479a/4.jpg 250w,
/static/ad6a433499d46bf50b63d69734154c37/41099/4.jpg 500w,
/static/ad6a433499d46bf50b63d69734154c37/a2510/4.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>We need to solve two sub-tasks for this image:</p>
<ol>
<li>Links <strong>detection</strong> (finding the position and bounding boxes of the links)</li>
<li>Links <strong>recognition</strong> (recognizing the text of the links)</li>
</ol>
<h4 id="option-1-tesseract-based-solution" style="position:relative">Option 1: Tesseract based solution<a href="#option-1-tesseract-based-solution" aria-label="option 1 tesseract based solution permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h4>
<p>The first and the most obvious approach would be to solve the <em>Optical Character Recognition</em> (<a href="https://en.wikipedia.org/wiki/Optical_character_recognition">OCR</a>) task by recognizing the whole text of the image by using, let&#x27;s say, <a href="https://github.com/naptha/tesseract.js">Tesseract.js</a> library. It returns the bounding boxes of the paragraphs, text lines, and text blocks along with the recognized text.</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 99.6%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBP/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHqRstoGYFA/8QAGRAAAgMBAAAAAAAAAAAAAAAAABEBECAh/9oACAEBAAEFAq7lyM//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAY/Ah//xAAbEAACAwADAAAAAAAAAAAAAAAAARExURAhgf/aAAgBAQABPyGXrJes9l8qUrZ3WS0//9oADAMBAAIAAwAAABCEF33/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAdEAEBAQACAgMAAAAAAAAAAAABEQAhMUGRUXHw/9oACAEBAAE/EG7IX5zVuAjn0cLSWXxuR80w92P3kCe7da9+wb//2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Recognized text with bounding boxes"
        title=""
        src="/static/a2b20844e61c8aff72a78bd9777f23ce/a2510/5.jpg"
        srcset="/static/a2b20844e61c8aff72a78bd9777f23ce/0479a/5.jpg 250w,
/static/a2b20844e61c8aff72a78bd9777f23ce/41099/5.jpg 500w,
/static/a2b20844e61c8aff72a78bd9777f23ce/a2510/5.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>We may try then to extract the links from the recognized text lines or text blocks with a regular expression like <a href="https://stackoverflow.com/questions/3809401/what-is-a-good-regular-expression-to-match-a-url">this one</a> (example is on TypeScript):</p>
<span><div class="gatsby-highlight" data-language="typescript"><pre class="language-typescript"><code class="language-typescript"><span class="token keyword">const</span> <span class="token constant">URL_REG_EXP</span> <span class="token operator">=</span> <span class="token regex"><span class="token regex-delimiter">/</span><span class="token regex-source language-regex">https?:\/\/(www\.)?[-a-zA-Z0-9@:%._+~#=]{2,256}\.[a-z]{2,4}\b([-a-zA-Z0-9@:%_+.~#?&amp;/=]*)</span><span class="token regex-delimiter">/</span><span class="token regex-flags">gi</span></span><span class="token punctuation">;</span>

<span class="token keyword">const</span> extractLinkFromText <span class="token operator">=</span> <span class="token punctuation">(</span>text<span class="token operator">:</span> <span class="token builtin">string</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">string</span> <span class="token operator">|</span> <span class="token keyword">null</span> <span class="token operator">=></span> <span class="token punctuation">{</span>
  <span class="token keyword">const</span> urls<span class="token operator">:</span> <span class="token builtin">string</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">|</span> <span class="token keyword">null</span> <span class="token operator">=</span> text<span class="token punctuation">.</span><span class="token function">match</span><span class="token punctuation">(</span><span class="token constant">URL_REG_EXP</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>urls <span class="token operator">||</span> <span class="token operator">!</span>urls<span class="token punctuation">.</span>length<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">return</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
  <span class="token keyword">return</span> urls<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span></code></pre></div></span>
<p> Seems like the issue is solved in a pretty straightforward and simple way:</p>
<ul>
<li>We know the bounding boxes of the links</li>
<li>We also know the text of the links to make them clickable</li>
</ul>
<p> The thing is that the <em>recognition + detection</em> time may vary from <span><code class="language-text">2</code></span> to <span><code class="language-text">20+</code></span> seconds depending on the size of the text, on the amount of &quot;something that looks like a text&quot; on the image, on the image quality and on other factors. So it will be really hard to achieve those <span><code class="language-text">0.5-1</code></span> frames per second to make the user experience at least <em>close</em> to real-time.</p>
<p> Also if we would think about it, we&#x27;re asking the library to recognize the <strong>whole</strong> text from the image for us even though it might contain only one or two links in it (i.e. only ~10% of the text might be useful for us), or it may even not contain the links at all. In this case, it sounds like a waste of computational resources.</p>
<h4 id="option-2-tesseract--tensorflow-based-solution" style="position:relative">Option 2: Tesseract + TensorFlow based solution<a href="#option-2-tesseract--tensorflow-based-solution" aria-label="option 2 tesseract  tensorflow based solution permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h4>
<p>We could make Tesseract work faster if we used some <em>additional &quot;adviser&quot; algorithm</em> prior to the links text recognition. This &quot;adviser&quot; algorithm should detect, but not recognize, <em>the leftmost position</em> of each link on the image if there are any. This will allow us to speed up the recognition part by following these rules:</p>
<ol>
<li>If the image does not contain any link we should not call Tesseract detection/recognition at all.</li>
<li>If the image does have the links then we need to ask Tesseract to recognize only those parts of the image that contains the links. We&#x27;re not interested in spending the time for recognition of the irrelevant text that does not contain the links.</li>
</ol>
<p>The &quot;adviser&quot; algorithm that will take place before the Tesseract should work with a constant time regardless of the image quality, or the presence/absence of the text on the image. It also should be pretty fast and detect the leftmost positions of the links for less than <span><code class="language-text">1s</code></span> so that we could satisfy the &quot;close-to-real-time&quot; requirement (i.e. on iPhone X).</p>
<blockquote>
<p> So what if we will use another object detection model to help us find all occurrences of the <span><code class="language-text">https://</code></span> substrings (every secure link has this prefix, doesn&#x27;t it) in the image? Then, having these <span><code class="language-text">https://</code></span> bounding boxes in the text we may extract the right-side continuation of them and send them to the Tesseract for text recognition.</p>
</blockquote>
<p>Take a look at the picture below:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 55.99999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHYschDD//EABkQAAEFAAAAAAAAAAAAAAAAAAEAERIgIv/aAAgBAQABBQLUi6FP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFRABAQAAAAAAAAAAAAAAAAAAIEH/2gAIAQEABj8Cq//EABsQAAIBBQAAAAAAAAAAAAAAAAABERAhMXHw/9oACAEBAAE/IXpScIxuRX//2gAMAwEAAgADAAAAEFzP/8QAFREBAQAAAAAAAAAAAAAAAAAAEDH/2gAIAQMBAT8Qh//EABYRAQEBAAAAAAAAAAAAAAAAAAEQEf/aAAgBAgEBPxBdn//EABwQAQEAAgIDAAAAAAAAAAAAAAERACFRgRAxQf/aAAgBAQABPxBUnTZLj00j2xKtrfuIVvPOHrx//9k='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Tesseract and TensorFlow based solution"
        title=""
        src="/static/6ef7e472afd39bfe0d1b7508449d6144/a2510/6.jpg"
        srcset="/static/6ef7e472afd39bfe0d1b7508449d6144/0479a/6.jpg 250w,
/static/6ef7e472afd39bfe0d1b7508449d6144/41099/6.jpg 500w,
/static/6ef7e472afd39bfe0d1b7508449d6144/a2510/6.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>You may notice that Tesseract needs to do <strong>much less</strong> work in case if it would have some hints about where are the links might be located (see the number of blue boxes on both pictures).</p>
<p>So the question now is which object detection model we should choose and how to re-train it to support the detection of the custom <span><code class="language-text">https://</code></span> objects.</p>
<blockquote>
<p>Finally! We&#x27;ve got closer to the TensorFlow part of the article </p>
</blockquote>
<h2 id="-selecting-the-object-detection-model" style="position:relative"> Selecting the Object Detection Model<a href="#-selecting-the-object-detection-model" aria-label=" selecting the object detection model permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>Training a new object detection model is not a reasonable option in our context because of the following reasons:</p>
<ul>
<li> The training process might take days/weeks and bucks.</li>
<li> We most probably won&#x27;t be able to collect hundreds of thousands of <em>labeled</em> images of the books that have links in them (we might try to generate them though, but more about that later).</li>
</ul>
<p>So instead of creating a new model, we should better teach an existing object detection model to do the custom object detection for us (to do the <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a>). In our case, the &quot;custom objects&quot; would be the images with <span><code class="language-text">https://</code></span> text drawn in them. This approach has the following benefits:</p>
<ul>
<li> The dataset might be much smaller. We don&#x27;t need to collect hundreds of thousands of the labeled images. Instead, we may do <span><code class="language-text">~100</code></span> pictures and label them manually. This is because the model is already pre-trained on the general dataset like <a href="https://cocodataset.org/#home">COCO dataset</a> and already learned how to extract general image features.</li>
<li> The training process will be much faster (minutes/hours on GPU instead of days/weeks). Again, this is because of a smaller dataset (smaller batches) and because of fewer trainable parameters.</li>
</ul>
<p>We may choose the existing model from <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">TensorFlow 2 Detection Model Zoo</a> which provides a collection of detection models pre-trained on the <a href="https://cocodataset.org/#home">COCO 2017 dataset</a>. Now it contains <span><code class="language-text">~40</code></span> model variations to choose from.</p>
<p>To re-train and fine-tune the model on the custom dataset we will use a <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">TensorFlow 2 Object Detection API</a>. The TensorFlow Object Detection API is an open-source framework built on top of <a href="https://www.tensorflow.org/">TensorFlow</a> that makes it easy to construct, train, and deploy object detection models.</p>
<p>If you follow the <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">Model Zoo</a> link you will find the <em>detection speed</em> and <em>accuracy</em> for each model.</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 96.80000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAECAwX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAAB9uzUFTz2JQP/xAAZEAABBQAAAAAAAAAAAAAAAAAAARARIDH/2gAIAQEAAQUCIZNr/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAFBABAAAAAAAAAAAAAAAAAAAAMP/aAAgBAQAGPwIf/8QAGBABAQEBAQAAAAAAAAAAAAAAAQBBEDH/2gAIAQEAAT8h2Q+kcGNtmNv/2gAMAwEAAgADAAAAEDwPQP/EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAEDAQE/ECE//8QAFREBAQAAAAAAAAAAAAAAAAAAARD/2gAIAQIBAT8QYz//xAAdEAACAgIDAQAAAAAAAAAAAAAAARExIbFBUZGB/9oACAEBAAE/EJbs5THEobxknDuzsyW82KuCticfRbzZuZ//2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Model Zoo"
        title=""
        src="/static/f01df6492b87597aa9333c853eaa333b/a2510/7.jpg"
        srcset="/static/f01df6492b87597aa9333c853eaa333b/0479a/7.jpg 250w,
/static/f01df6492b87597aa9333c853eaa333b/41099/7.jpg 500w,
/static/f01df6492b87597aa9333c853eaa333b/a2510/7.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p><em>Image source: <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">TensorFlow Model Zoo</a> repository</em></p>
<p>Of course, we would want to find the right balance between the detection <strong>speed</strong> and <strong>accuracy</strong> while picking the model. But what might be even more important in our case is the <strong>size</strong> of the model since it will be loaded to the client-side.</p>
<p>The size of the archived model might vary drastically from <span><code class="language-text">~20Mb</code></span> to <span><code class="language-text">~1Gb</code></span>. Here are several examples:</p>
<ul>
<li><span><code class="language-text">1386 (Mb)</code></span> <span><code class="language-text">centernet_hg104_1024x1024_kpts_coco17_tpu-32</code></span></li>
<li><span><code class="language-text"> 330 (Mb)</code></span> <span><code class="language-text">centernet_resnet101_v1_fpn_512x512_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 195 (Mb)</code></span> <span><code class="language-text">centernet_resnet50_v1_fpn_512x512_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 198 (Mb)</code></span> <span><code class="language-text">centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 227 (Mb)</code></span> <span><code class="language-text">centernet_resnet50_v2_512x512_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 230 (Mb)</code></span> <span><code class="language-text">centernet_resnet50_v2_512x512_kpts_coco17_tpu-8</code></span></li>
<li><span><code class="language-text">  29 (Mb)</code></span> <span><code class="language-text">efficientdet_d0_coco17_tpu-32</code></span></li>
<li><span><code class="language-text">  49 (Mb)</code></span> <span><code class="language-text">efficientdet_d1_coco17_tpu-32</code></span></li>
<li><span><code class="language-text">  60 (Mb)</code></span> <span><code class="language-text">efficientdet_d2_coco17_tpu-32</code></span></li>
<li><span><code class="language-text">  89 (Mb)</code></span> <span><code class="language-text">efficientdet_d3_coco17_tpu-32</code></span></li>
<li><span><code class="language-text"> 151 (Mb)</code></span> <span><code class="language-text">efficientdet_d4_coco17_tpu-32</code></span></li>
<li><span><code class="language-text"> 244 (Mb)</code></span> <span><code class="language-text">efficientdet_d5_coco17_tpu-32</code></span></li>
<li><span><code class="language-text"> 376 (Mb)</code></span> <span><code class="language-text">efficientdet_d6_coco17_tpu-32</code></span></li>
<li><span><code class="language-text"> 376 (Mb)</code></span> <span><code class="language-text">efficientdet_d7_coco17_tpu-32</code></span></li>
<li><span><code class="language-text"> 665 (Mb)</code></span> <span><code class="language-text">extremenet</code></span></li>
<li><span><code class="language-text"> 427 (Mb)</code></span> <span><code class="language-text">faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 424 (Mb)</code></span> <span><code class="language-text">faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 337 (Mb)</code></span> <span><code class="language-text">faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 337 (Mb)</code></span> <span><code class="language-text">faster_rcnn_resnet101_v1_640x640_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 343 (Mb)</code></span> <span><code class="language-text">faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8</code></span></li>
<li><span><code class="language-text"> 449 (Mb)</code></span> <span><code class="language-text">faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 449 (Mb)</code></span> <span><code class="language-text">faster_rcnn_resnet152_v1_640x640_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 454 (Mb)</code></span> <span><code class="language-text">faster_rcnn_resnet152_v1_800x1333_coco17_gpu-8</code></span></li>
<li><span><code class="language-text"> 202 (Mb)</code></span> <span><code class="language-text">faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 202 (Mb)</code></span> <span><code class="language-text">faster_rcnn_resnet50_v1_640x640_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 207 (Mb)</code></span> <span><code class="language-text">faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8</code></span></li>
<li><span><code class="language-text"> 462 (Mb)</code></span> <span><code class="language-text">mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8</code></span></li>
<li><span><code class="language-text">  86 (Mb)</code></span> <span><code class="language-text">ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8</code></span></li>
<li><span><code class="language-text">  44 (Mb)</code></span> <span><code class="language-text">ssd_mobilenet_v2_320x320_coco17_tpu-8</code></span></li>
<li><span><code class="language-text">  20 (Mb)</code></span> <span><code class="language-text">ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8</code></span></li>
<li><span><code class="language-text">  20 (Mb)</code></span> <span><code class="language-text">ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 369 (Mb)</code></span> <span><code class="language-text">ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 369 (Mb)</code></span> <span><code class="language-text">ssd_resnet101_v1_fpn_640x640_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 481 (Mb)</code></span> <span><code class="language-text">ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 480 (Mb)</code></span> <span><code class="language-text">ssd_resnet152_v1_fpn_640x640_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 233 (Mb)</code></span> <span><code class="language-text">ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8</code></span></li>
<li><span><code class="language-text"> 233 (Mb)</code></span> <span><code class="language-text">ssd_resnet50_v1_fpn_640x640_coco17_tpu-8</code></span></li>
</ul>
<p>The <strong><span><code class="language-text">ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8</code></span></strong> model might be a good fit in our case:</p>
<ul>
<li> It is relatively lightweight: <span><code class="language-text">20Mb</code></span> archived.</li>
<li> It is pretty fast: <span><code class="language-text">39ms</code></span> for the detection.</li>
<li> It uses the MobileNet v2 network as a feature extractor which is optimized for usage on mobile devices to reduce energy consumption.</li>
<li> It does the object detection for the whole image and for all objects in it <strong>in one go</strong> regardless of the image content (no <a href="https://en.wikipedia.org/wiki/Region_Based_Convolutional_Neural_Networks">regions proposal</a> step is involved which makes the detection faster).</li>
<li> It is not the most accurate model though (everything is a tradeoff ).</li>
</ul>
<p>The model name encodes some several important characteristics that you may read more about if you want:</p>
<ul>
<li>The expected image input size is <span><code class="language-text">640x640px</code></span>.</li>
<li>The model implements <a href="https://arxiv.org/abs/1512.02325">Single Shot MultiBox Detector</a> (SSD) and <a href="https://arxiv.org/abs/1612.03144">Feature Pyramid Network</a> (FPN).</li>
<li><a href="https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html">MobileNet v2</a> convolutional neural network (<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">CNN</a>) is used as a feature extractor.</li>
<li>The model was trained on <a href="https://cocodataset.org/#home">COCO dataset</a></li>
</ul>
<h2 id="-installing-object-detection-api" style="position:relative"> Installing Object Detection API<a href="#-installing-object-detection-api" aria-label=" installing object detection api permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>In this article, we&#x27;re going to install the Tensorflow 2 Object Detection API <em>as a Python package</em>. It is convenient in case if you&#x27;re experimenting in <a href="https://colab.research.google.com/">Google Colab</a> (recommended) or in <a href="https://jupyter.org/try">Jupyter</a>. For both cases no local installation is needed, you may experiment right in your browser.</p>
<p>You may also follow the <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md">official documentation</a> if you would prefer to install Object Detection API via Docker.</p>
<blockquote>
<p>If you stuck with something during the API installation or during the dataset preparation try to read through the <a href="https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/index.html">TensorFlow 2 Object Detection API tutorial</a> which adds a lot of useful details to this process.</p>
</blockquote>
<p>First, let&#x27;s clone the <a href="https://github.com/tensorflow/models">API repository</a>:</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">git</span> clone <span class="token parameter variable">--depth</span> <span class="token number">1</span> https://github.com/tensorflow/models</code></pre></div></span>
<p><em>output </em></p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Cloning into 'models'...
remote: Enumerating objects: 2301, done.
remote: Counting objects: 100% (2301/2301), done.
remote: Compressing objects: 100% (2000/2000), done.
remote: Total 2301 (delta 561), reused 922 (delta 278), pack-reused 0
Receiving objects: 100% (2301/2301), 30.60 MiB | 13.90 MiB/s, done.
Resolving deltas: 100% (561/561), done.</code></pre></div></span>
<p>Now, let&#x27;s compile the <a href="https://github.com/tensorflow/models/tree/master/research/object_detection/protos">API proto files</a> into Python files by using <a href="https://grpc.io/docs/protoc-installation/">protoc</a> tool:</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">cd</span> ./models/research
protoc object_detection/protos/*.proto <span class="token parameter variable">--python_out</span><span class="token operator">=</span>.</code></pre></div></span>
<p>Finally, let&#x27;s install the TF2 version of <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/packages/tf2/setup.py">setup.py</a> via <span><code class="language-text">pip</code></span>:</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">cp</span> ./object_detection/packages/tf2/setup.py <span class="token builtin class-name">.</span>
pip <span class="token function">install</span> <span class="token builtin class-name">.</span> <span class="token parameter variable">--quiet</span></code></pre></div></span>
<blockquote>
<p>It is possible that the last step will fail because of some dependency errors. In this case, you might want to run <span><code class="language-text">pip install . --quiet</code></span> one more time.</p>
</blockquote>
<p>We may test that installation went successfully by running the following tests:</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">python object_detection/builders/model_builder_tf2_test.py</code></pre></div></span>
<p>You should see the logs that end with something similar to this:</p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor
----------------------------------------------------------------------
Ran 20 tests in 45.072s

OK (skipped=1)</code></pre></div></span>
<p>The TensorFlow Object Detection API is installed! You may now use the scripts that API provides for doing the model <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_tf2_colab.ipynb">inference</a>, <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md">training</a> or <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb">fine-tuning</a>.</p>
<h2 id="-downloading-the-pre-trained-model" style="position:relative"> Downloading the Pre-Trained Model<a href="#%EF%B8%8F-downloading-the-pre-trained-model" aria-label=" downloading the pre trained model permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>Let&#x27;s download our selected <span><code class="language-text">ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8</code></span> model from the TensorFlow Model Zoo and check how it does the general object detection (detection of the objects of classes from COCO dataset like &quot;cat&quot;, &quot;dog&quot;, &quot;car&quot;, etc.).</p>
<p>We will use the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file">get_file()</a> TensorFlow helper to download the archived model from the URL and unpack it.</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> pathlib

MODEL_NAME <span class="token operator">=</span> <span class="token string">'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'</span>
TF_MODELS_BASE_PATH <span class="token operator">=</span> <span class="token string">'http://download.tensorflow.org/models/object_detection/tf2/20200711/'</span>
CACHE_FOLDER <span class="token operator">=</span> <span class="token string">'./cache'</span>

<span class="token keyword">def</span> <span class="token function">download_tf_model</span><span class="token punctuation">(</span>model_name<span class="token punctuation">,</span> cache_folder<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model_url <span class="token operator">=</span> TF_MODELS_BASE_PATH <span class="token operator">+</span> model_name <span class="token operator">+</span> <span class="token string">'.tar.gz'</span>
    model_dir <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>get_file<span class="token punctuation">(</span>
        fname<span class="token operator">=</span>model_name<span class="token punctuation">,</span>
        origin<span class="token operator">=</span>model_url<span class="token punctuation">,</span>
        untar<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        cache_dir<span class="token operator">=</span>pathlib<span class="token punctuation">.</span>Path<span class="token punctuation">(</span>cache_folder<span class="token punctuation">)</span><span class="token punctuation">.</span>absolute<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> model_dir

<span class="token comment"># Start the model download.</span>
model_dir <span class="token operator">=</span> download_tf_model<span class="token punctuation">(</span>MODEL_NAME<span class="token punctuation">,</span> CACHE_FOLDER<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span></code></pre></div></span>
<p><em>output </em></p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">/content/cache/datasets/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8</code></pre></div></span>
<p>Here is how the folder structure looks so far:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 972px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 80%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAQABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAgAF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB22EKo//EABcQAAMBAAAAAAAAAAAAAAAAAAEQIQL/2gAIAQEAAQUCMeq//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAHBAAAQQDAQAAAAAAAAAAAAAAAQAQESExYZHx/9oACAEBAAE/IZHWCgSfGspDc8b/2gAMAwEAAgADAAAAELPP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHhABAAICAQUAAAAAAAAAAAAAAQARITFREEFhgZH/2gAIAQEAAT8QVlXkp5mgfq6UAKptO3iNAsnjSDZefc//2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Cache Folder"
        title=""
        src="/static/ba6e6aef4124664efef1f1af4f1f9c95/95c6e/8.jpg"
        srcset="/static/ba6e6aef4124664efef1f1af4f1f9c95/0479a/8.jpg 250w,
/static/ba6e6aef4124664efef1f1af4f1f9c95/41099/8.jpg 500w,
/static/ba6e6aef4124664efef1f1af4f1f9c95/95c6e/8.jpg 972w"
        sizes="(max-width: 972px) 100vw, 972px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>The <span><code class="language-text">checkpoint</code></span> folder contains the snapshot of the pre-trained model.</p>
<p>The <span><code class="language-text">pipeline.config</code></span> file contains the detection settings of the model. We&#x27;ll come back to this file later when we will need to fine-tune the model.</p>
<h2 id="-trying-the-model-doing-the-inference" style="position:relative"> Trying the Model (Doing the Inference)<a href="#%EF%B8%8F-trying-the-model-doing-the-inference" aria-label=" trying the model doing the inference permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>For now, the model can detect the object of <a href="https://cocodataset.org/#explore">90 COCO dataset classes</a> like a <span><code class="language-text">car</code></span>, <span><code class="language-text">bird</code></span>, <span><code class="language-text">hot dog</code></span> etc.</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 22.799999999999997%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAFABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAIF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB06Cwf//EABkQAAMAAwAAAAAAAAAAAAAAAAABAhESE//aAAgBAQABBQKo1FGXyP/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABgQAAIDAAAAAAAAAAAAAAAAAAARASGB/9oACAEBAAY/AmzCpP/EABgQAQEBAQEAAAAAAAAAAAAAAAERADFB/9oACAEBAAE/IZoS3AAr60HQ3//aAAwDAQACAAMAAAAQ8A//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAACAwADAAAAAAAAAAAAAAABEQAhQTFR4f/aAAgBAQABPxALyVZwWV7FLZGp2cIBus9z/9k='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="COCO classes"
        title=""
        src="/static/43edaafc7d30b56f3421efff4cac6d42/a2510/9.jpg"
        srcset="/static/43edaafc7d30b56f3421efff4cac6d42/0479a/9.jpg 250w,
/static/43edaafc7d30b56f3421efff4cac6d42/41099/9.jpg 500w,
/static/43edaafc7d30b56f3421efff4cac6d42/a2510/9.jpg 1000w,
/static/43edaafc7d30b56f3421efff4cac6d42/c58a3/9.jpg 1500w,
/static/43edaafc7d30b56f3421efff4cac6d42/d14d4/9.jpg 1562w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p><em>Image source: <a href="https://cocodataset.org/#explore">COCO dataset</a> website</em></p>
<p>Let&#x27;s see how the model performs on some general images that contain the objects of these classes.</p>
<h3 id="loading-coco-labels" style="position:relative">Loading COCO labels<a href="#loading-coco-labels" aria-label="loading coco labels permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>Object Detection API already has a complete set of COCO labels (classes) defined for us.</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> os

<span class="token comment"># Import Object Detection API helpers.</span>
<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>utils <span class="token keyword">import</span> label_map_util

<span class="token comment"># Loads the COCO labels data (class names and indices relations).</span>
<span class="token keyword">def</span> <span class="token function">load_coco_labels</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Object Detection API already has a complete set of COCO classes defined for us.</span>
    label_map_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>
        <span class="token string">'models/research/object_detection/data'</span><span class="token punctuation">,</span>
        <span class="token string">'mscoco_complete_label_map.pbtxt'</span>
    <span class="token punctuation">)</span>
    label_map <span class="token operator">=</span> label_map_util<span class="token punctuation">.</span>load_labelmap<span class="token punctuation">(</span>label_map_path<span class="token punctuation">)</span>

    <span class="token comment"># Class ID to Class Name mapping.</span>
    categories <span class="token operator">=</span> label_map_util<span class="token punctuation">.</span>convert_label_map_to_categories<span class="token punctuation">(</span>
        label_map<span class="token punctuation">,</span>
        max_num_classes<span class="token operator">=</span>label_map_util<span class="token punctuation">.</span>get_max_label_map_index<span class="token punctuation">(</span>label_map<span class="token punctuation">)</span><span class="token punctuation">,</span>
        use_display_name<span class="token operator">=</span><span class="token boolean">True</span>
    <span class="token punctuation">)</span>
    category_index <span class="token operator">=</span> label_map_util<span class="token punctuation">.</span>create_category_index<span class="token punctuation">(</span>categories<span class="token punctuation">)</span>

    <span class="token comment"># Class Name to Class ID mapping.</span>
    label_map_dict <span class="token operator">=</span> label_map_util<span class="token punctuation">.</span>get_label_map_dict<span class="token punctuation">(</span>label_map<span class="token punctuation">,</span> use_display_name<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> category_index<span class="token punctuation">,</span> label_map_dict

<span class="token comment"># Load COCO labels.</span>
coco_category_index<span class="token punctuation">,</span> coco_label_map_dict <span class="token operator">=</span> load_coco_labels<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'coco_category_index:'</span><span class="token punctuation">,</span> coco_category_index<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'coco_label_map_dict:'</span><span class="token punctuation">,</span> coco_label_map_dict<span class="token punctuation">)</span></code></pre></div></span>
<p><em>output </em></p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">coco_category_index:
{
    1: {'id': 1, 'name': 'person'},
    2: {'id': 2, 'name': 'bicycle'},
    ...
    90: {'id': 90, 'name': 'toothbrush'},
}

coco_label_map_dict:
{
    'background': 0,
    'person': 1,
    'bicycle': 2,
    'car': 3,
    ...
    'toothbrush': 90,
}</code></pre></div></span>
<h3 id="build-a-detection-function" style="position:relative">Build a detection function<a href="#build-a-detection-function" aria-label="build a detection function permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>We need to create a detection function that will use the pre-trained model we&#x27;ve downloaded to do the object detection.</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

<span class="token comment"># Import Object Detection API helpers.</span>
<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>utils <span class="token keyword">import</span> config_util
<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>builders <span class="token keyword">import</span> model_builder

<span class="token comment"># Generates the detection function for specific model and specific model's checkpoint</span>
<span class="token keyword">def</span> <span class="token function">detection_fn_from_checkpoint</span><span class="token punctuation">(</span>config_path<span class="token punctuation">,</span> checkpoint_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Build the model.</span>
    pipeline_config <span class="token operator">=</span> config_util<span class="token punctuation">.</span>get_configs_from_pipeline_file<span class="token punctuation">(</span>config_path<span class="token punctuation">)</span>
    model_config <span class="token operator">=</span> pipeline_config<span class="token punctuation">[</span><span class="token string">'model'</span><span class="token punctuation">]</span>
    model <span class="token operator">=</span> model_builder<span class="token punctuation">.</span>build<span class="token punctuation">(</span>
        model_config<span class="token operator">=</span>model_config<span class="token punctuation">,</span>
        is_training<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># Restore checkpoints.</span>
    ckpt <span class="token operator">=</span> tf<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v2<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Checkpoint<span class="token punctuation">(</span>model<span class="token operator">=</span>model<span class="token punctuation">)</span>
    ckpt<span class="token punctuation">.</span>restore<span class="token punctuation">(</span>checkpoint_path<span class="token punctuation">)</span><span class="token punctuation">.</span>expect_partial<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># This is a function that will do the detection.</span>
    <span class="token decorator annotation punctuation">@tf<span class="token punctuation">.</span>function</span>
    <span class="token keyword">def</span> <span class="token function">detect_fn</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image<span class="token punctuation">,</span> shapes <span class="token operator">=</span> model<span class="token punctuation">.</span>preprocess<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        prediction_dict <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>image<span class="token punctuation">,</span> shapes<span class="token punctuation">)</span>
        detections <span class="token operator">=</span> model<span class="token punctuation">.</span>postprocess<span class="token punctuation">(</span>prediction_dict<span class="token punctuation">,</span> shapes<span class="token punctuation">)</span>

        <span class="token keyword">return</span> detections<span class="token punctuation">,</span> prediction_dict<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>shapes<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> detect_fn

inference_detect_fn <span class="token operator">=</span> detection_fn_from_checkpoint<span class="token punctuation">(</span>
    config_path<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'cache'</span><span class="token punctuation">,</span> <span class="token string">'datasets'</span><span class="token punctuation">,</span> MODEL_NAME<span class="token punctuation">,</span> <span class="token string">'pipeline.config'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    checkpoint_path<span class="token operator">=</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'cache'</span><span class="token punctuation">,</span> <span class="token string">'datasets'</span><span class="token punctuation">,</span> MODEL_NAME<span class="token punctuation">,</span> <span class="token string">'checkpoint'</span><span class="token punctuation">,</span> <span class="token string">'ckpt-0'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span></code></pre></div></span>
<p>This <span><code class="language-text">inference_detect_fn</code></span> function will accept an image and will return the detected objects&#x27; info.</p>
<h3 id="loading-the-images-for-inference" style="position:relative">Loading the images for inference<a href="#loading-the-images-for-inference" aria-label="loading the images for inference permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>Let&#x27;s try to detect the object on this image:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAMEAv/EABcBAQEBAQAAAAAAAAAAAAAAAAECAAP/2gAMAwEAAhADEAAAAZ14qHaDOjMUaBHX/8QAHBAAAgICAwAAAAAAAAAAAAAAAQIAEhExExQi/9oACAEBAAEFAgJyMs7DxVbNPZ2NWLPQT//EABgRAAIDAAAAAAAAAAAAAAAAAAABEBEx/9oACAEDAQE/AShbH//EABURAQEAAAAAAAAAAAAAAAAAABIg/9oACAECAQE/ATH/xAAdEAEAAQMFAAAAAAAAAAAAAAABABARQQIhMUJR/9oACAEBAAY/AndJY1sxDyX65qjxT//EAB0QAQADAAEFAAAAAAAAAAAAAAEAESExEFFhcdH/2gAIAQEAAT8hFLeIFzDiHFQr+JSM744EwcnJRTXSHNhwnun/2gAMAwEAAgADAAAAEJQXQP/EABYRAQEBAAAAAAAAAAAAAAAAABEAEP/aAAgBAwEBPxB0F//EABgRAQADAQAAAAAAAAAAAAAAAAABETFR/9oACAECAQE/ECp6nFv/xAAdEAEAAwADAAMAAAAAAAAAAAABABExIUFxUYGx/9oACAEBAAE/EC6meEhvYWy95/nkSLLd7l2PebeZxjKOJ9bcsnSpxkN8135mLjjhFex4z//Z'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="General Object Inference"
        title=""
        src="/static/9e7ca505789722a51d11eeede2b2d3c3/c08c5/10.jpg"
        srcset="/static/9e7ca505789722a51d11eeede2b2d3c3/0479a/10.jpg 250w,
/static/9e7ca505789722a51d11eeede2b2d3c3/41099/10.jpg 500w,
/static/9e7ca505789722a51d11eeede2b2d3c3/c08c5/10.jpg 640w"
        sizes="(max-width: 640px) 100vw, 640px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p><em>Image source: <a href="https://www.instagram.com/oleksii_trekhleb/?hl=en">oleksii_trekhleb</a> Instagram</em></p>
<p>To do that let&#x27;s save the image to the <span><code class="language-text">inference/test/</code></span> folder of our project. If you&#x27;re using Google Colab you may create this folder and upload the image manually.</p>
<p>Here is how the folder structure looks so far:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 602px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 61.6%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe3uUoP/xAAZEAACAwEAAAAAAAAAAAAAAAAQEQECITH/2gAIAQEAAQUC5ZwFqH//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAbEAABBAMAAAAAAAAAAAAAAAABABARIVFhcf/aAAgBAQABPyEz0W5jKxNKGG//2gAMAwEAAgADAAAAEAPP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHBABAAMAAgMAAAAAAAAAAAAAAQARIRAxUWGB/9oACAEBAAE/EE+3HZ46iRdfmwbBSvU0kCsMoyBomjj/2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Folder structure"
        title=""
        src="/static/17fdcc432317dd5e59a939360936b0b0/e49d1/11.jpg"
        srcset="/static/17fdcc432317dd5e59a939360936b0b0/0479a/11.jpg 250w,
/static/17fdcc432317dd5e59a939360936b0b0/41099/11.jpg 500w,
/static/17fdcc432317dd5e59a939360936b0b0/e49d1/11.jpg 602w"
        sizes="(max-width: 602px) 100vw, 602px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib inline

<span class="token comment"># Creating a TensorFlow dataset of just one image.</span>
inference_ds <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image_dataset_from_directory<span class="token punctuation">(</span>
  directory<span class="token operator">=</span><span class="token string">'inference'</span><span class="token punctuation">,</span>
  image_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">640</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
  shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
  label_mode<span class="token operator">=</span><span class="token boolean">None</span>
<span class="token punctuation">)</span>
<span class="token comment"># Numpy version of the dataset.</span>
inference_ds_numpy <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>inference_ds<span class="token punctuation">.</span>as_numpy_iterator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># You may preview the images in dataset like this.</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span> image <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>inference_ds_numpy<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">"uint8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div></span>
<h3 id="running-the-detection-on-test-data" style="position:relative">Running the detection on test data<a href="#running-the-detection-on-test-data" aria-label="running the detection on test data permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>Now we&#x27;re ready to run the detection. The <span><code class="language-text">inference_ds_numpy[0]</code></span> array stores the pixel data for the first image in <span><code class="language-text">Numpy</code></span> format.</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">detections<span class="token punctuation">,</span> predictions_dict<span class="token punctuation">,</span> shapes <span class="token operator">=</span> inference_detect_fn<span class="token punctuation">(</span>
    inference_ds_numpy<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span></code></pre></div></span>
<p>Let&#x27;s see the shapes of the output:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">boxes <span class="token operator">=</span> detections<span class="token punctuation">[</span><span class="token string">'detection_boxes'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
scores <span class="token operator">=</span> detections<span class="token punctuation">[</span><span class="token string">'detection_scores'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
classes <span class="token operator">=</span> detections<span class="token punctuation">[</span><span class="token string">'detection_classes'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
num_detections <span class="token operator">=</span> detections<span class="token punctuation">[</span><span class="token string">'num_detections'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'boxes.shape: '</span><span class="token punctuation">,</span> boxes<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'scores.shape: '</span><span class="token punctuation">,</span> scores<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'classes.shape: '</span><span class="token punctuation">,</span> classes<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'num_detections:'</span><span class="token punctuation">,</span> num_detections<span class="token punctuation">)</span></code></pre></div></span>
<p><em>output </em></p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">boxes.shape:  (1, 100, 4)
scores.shape:  (1, 100)
classes.shape:  (1, 100)
num_detections: 100.0</code></pre></div></span>
<p>The model has made a <span><code class="language-text">100</code></span> detections for us. It doesn&#x27;t mean that it found <span><code class="language-text">100</code></span> objects on the image though. It means that the model has <span><code class="language-text">100</code></span> slots, and it can detect <span><code class="language-text">100</code></span> objects at max on a single image. Each detection has a score that represents the confidence of the model about it. The bounding boxes for each detection are stored in the <span><code class="language-text">boxes</code></span> array. The scores or confidences of the model about each detection are stored in the <span><code class="language-text">scores</code></span> array. Finally, the <span><code class="language-text">classes</code></span> array stores the labels (classes) for each detection.</p>
<p>Let&#x27;s check the first 5 detections:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'First 5 boxes:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>boxes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'First 5 scores:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>scores<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'First 5 classes:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>classes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

class_names <span class="token operator">=</span> <span class="token punctuation">[</span>coco_category_index<span class="token punctuation">[</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> classes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'First 5 class names:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>class_names<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div></span>
<p><em>output </em></p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">First 5 boxes:
[[0.17576033 0.84654826 0.25642633 0.88327974]
 [0.5187813  0.12410264 0.6344235  0.34545377]
 [0.5220358  0.5181462  0.6329132  0.7669856 ]
 [0.50933677 0.7045719  0.5619138  0.7446198 ]
 [0.44761637 0.51942706 0.61237675 0.75963426]]

First 5 scores:
[0.6950246 0.6343004 0.591157  0.5827219 0.5415643]

First 5 classes:
[9. 8. 8. 0. 8.]

First 5 class names:
['traffic light', 'boat', 'boat', 'person', 'boat']</code></pre></div></span>
<p>The model sees the <span><code class="language-text">traffic light</code></span>, three <span><code class="language-text">boats</code></span>, and a <span><code class="language-text">person</code></span> on the image. We may confirm that indeed these objects are seen on the image.</p>
<p>From the <span><code class="language-text">scores</code></span> array may see that the model is most confident (close to 70% of probability) in the <span><code class="language-text">traffic light</code></span> object.</p>
<p>Each entry of <span><code class="language-text">boxes</code></span> array is <span><code class="language-text">[y1, x1, y2, x2]</code></span>, where <span><code class="language-text">(x1, y1)</code></span> and <span><code class="language-text">(x2, y2)</code></span> are the top-left and bottom-right corners of the bounding box.</p>
<p>Let&#x27;s visualize the detection boxes:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># Importing Object Detection API helpers.</span>
<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>utils <span class="token keyword">import</span> visualization_utils

<span class="token comment"># Visualizes the bounding boxes on top of the image.</span>
<span class="token keyword">def</span> <span class="token function">visualize_detections</span><span class="token punctuation">(</span>image_np<span class="token punctuation">,</span> detections<span class="token punctuation">,</span> category_index<span class="token punctuation">)</span><span class="token punctuation">:</span>
    label_id_offset <span class="token operator">=</span> <span class="token number">1</span>
    image_np_with_detections <span class="token operator">=</span> image_np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

    visualization_utils<span class="token punctuation">.</span>visualize_boxes_and_labels_on_image_array<span class="token punctuation">(</span>
        image_np_with_detections<span class="token punctuation">,</span>
        detections<span class="token punctuation">[</span><span class="token string">'detection_boxes'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span>detections<span class="token punctuation">[</span><span class="token string">'detection_classes'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> label_id_offset<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        detections<span class="token punctuation">[</span><span class="token string">'detection_scores'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        category_index<span class="token punctuation">,</span>
        use_normalized_coordinates<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        max_boxes_to_draw<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
        min_score_thresh<span class="token operator">=</span><span class="token number">.4</span><span class="token punctuation">,</span>
        agnostic_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image_np_with_detections<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Visualizing the detections.</span>
visualize_detections<span class="token punctuation">(</span>
    image_np<span class="token operator">=</span>tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>inference_ds_numpy<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>uint32<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    detections<span class="token operator">=</span>detections<span class="token punctuation">,</span>
    category_index<span class="token operator">=</span>coco_category_index<span class="token punctuation">,</span>
<span class="token punctuation">)</span></code></pre></div></span>
<p>Here is the output:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 709px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 99.2%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAIDAAAAAAAAAAAAAAAAAAECAwQF/8QAFgEBAQEAAAAAAAAAAAAAAAAAAQID/9oADAMBAAIQAxAAAAGU3klrl6eISwnT/8QAHBAAAQQDAQAAAAAAAAAAAAAAAgABEhMRFCEz/9oACAEBAAEFAi9LCBbBohKyPX68GzDL0iv/xAAWEQADAAAAAAAAAAAAAAAAAAAAEBH/2gAIAQMBAT8BI//EABURAQEAAAAAAAAAAAAAAAAAABEg/9oACAECAQE/ASP/xAAdEAACAQQDAAAAAAAAAAAAAAAAAQIRITFBECJR/9oACAEBAAY/Ap9mrlFNmh+VE1ZLPDMs2f/EAB0QAQACAgIDAAAAAAAAAAAAAAEAESFBMVFhkeH/2gAIAQEAAT8hz2ZxmAhSjhJ4/SYGlnccANpKI1G7tyxK3V1qX/U//9oADAMBAAIAAwAAABA8APz/xAAWEQEBAQAAAAAAAAAAAAAAAAAQATH/2gAIAQMBAT8QE0//xAAZEQEAAgMAAAAAAAAAAAAAAAAAARExUWH/2gAIAQIBAT8Q5VO04W//xAAeEAEAAwACAgMAAAAAAAAAAAABABEhMUFRYXGR0f/aAAgBAQABPxAo0IgBC3xXWS6fGlvfEGC7q3f7FOVIo6X8wQoTZZ9dsfYbZxkey1V33D9paLlK9VHUw//Z'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Inference result"
        title=""
        src="/static/9312de3c7465a05f9ddd12eca3d9d385/bd958/12.jpg"
        srcset="/static/9312de3c7465a05f9ddd12eca3d9d385/0479a/12.jpg 250w,
/static/9312de3c7465a05f9ddd12eca3d9d385/41099/12.jpg 500w,
/static/9312de3c7465a05f9ddd12eca3d9d385/bd958/12.jpg 709w"
        sizes="(max-width: 709px) 100vw, 709px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>If we will do the detection for the text image here is what we will see:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 709px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 99.2%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBP/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHujMikDqkNB//EABwQAAICAgMAAAAAAAAAAAAAAAABAhIDERAhMv/aAAgBAQABBQKTdts7JeuHjW6FD//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8BH//EABcQAAMBAAAAAAAAAAAAAAAAAAABMRD/2gAIAQEABj8CevXSsrP/xAAcEAACAgIDAAAAAAAAAAAAAAAAAREhEHExYZH/2gAIAQEAAT8hobfJ2M3fpJ7y8MOmzGiCAf/aAAwDAQACAAMAAAAQLBDD/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAHhABAAICAgMBAAAAAAAAAAAAAQARIUFhcaGx0cH/2gAIAQEAAT8QIAi22Nr72LvAaMauY7lDTjiN3nzK4yjhNvUUxj5Pkbv3Pk//2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Inference result for text image"
        title=""
        src="/static/372fe51fcd25300ff07e0bba1d94b846/bd958/13.jpg"
        srcset="/static/372fe51fcd25300ff07e0bba1d94b846/0479a/13.jpg 250w,
/static/372fe51fcd25300ff07e0bba1d94b846/41099/13.jpg 500w,
/static/372fe51fcd25300ff07e0bba1d94b846/bd958/13.jpg 709w"
        sizes="(max-width: 709px) 100vw, 709px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>The model couldn&#x27;t detect anything on this image. This is what we&#x27;re going to change, we want to teach the model to &quot;see&quot; the <span><code class="language-text">https://</code></span> prefixes on this image.</p>
<h2 id="-preparing-the-custom-dataset" style="position:relative"> Preparing the Custom Dataset<a href="#-preparing-the-custom-dataset" aria-label=" preparing the custom dataset permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>To &quot;teach&quot; the <span><code class="language-text">ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8</code></span> model to detect the custom objects which are <em>not</em> a part of a COCO dataset we need to do the fine-tune training on a new custom dataset.</p>
<p>The datasets for object detection consist of two parts:</p>
<ol>
<li>The image itself (i.e. the image of the book page)</li>
<li>The boundary boxes that show where exactly on the image the custom objects are located.</li>
</ol>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 52.400000000000006%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3VoB/8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQABBQJf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAERIFFh/9oACAEBAAE/IXpPRU//2gAMAwEAAgADAAAAEEDP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGhAAAwEBAQEAAAAAAAAAAAAAAAERMVFxIf/aAAgBAQABPxCk3TlyH1JoarU/Ba/RJcIuH//Z'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Bounding Boxes"
        title=""
        src="/static/be25b47e961629a02f8ed3a656535b42/a2510/14.jpg"
        srcset="/static/be25b47e961629a02f8ed3a656535b42/0479a/14.jpg 250w,
/static/be25b47e961629a02f8ed3a656535b42/41099/14.jpg 500w,
/static/be25b47e961629a02f8ed3a656535b42/a2510/14.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>In the example above each box has <span><code class="language-text">left-top</code></span> and <span><code class="language-text">right-bottom</code></span> coordinates in <em>absolute</em> values (in pixels). However, there are also different formats of writing the location of the bounding boxes exists. For example, we may locate the bounding box by setting the coordinate of its <span><code class="language-text">center point</code></span> and its <span><code class="language-text">width</code></span> and <span><code class="language-text">height</code></span>. We might also use <em>relative</em> values (percentage of the width and height of the image) for setting up the coordinates. But you&#x27;ve got the idea, the network needs to know what the image is and where on the image the objects are located.</p>
<p>Now, how can we get the custom dataset for training? We have three options here:</p>
<ol>
<li><em>Re-use</em> the existing dataset.</li>
<li><em>Generate</em> a new dataset of fake book images.</li>
<li><em>Create</em> the dataset manually by taking or downloading the pictures of real book pages which contain <span><code class="language-text">https://</code></span> links and labeling all bounding boxes.</li>
</ol>
<h3 id="option-1-re-using-the-existing-dataset" style="position:relative">Option 1: Re-using the existing dataset<a href="#option-1-re-using-the-existing-dataset" aria-label="option 1 re using the existing dataset permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>There are plenty of the datasets that are shared to be re-used by researches. We could start from the following resources to find a proper dataset:</p>
<ul>
<li><a href="https://datasetsearch.research.google.com/">Google Dataset Search</a></li>
<li><a href="https://www.kaggle.com/datasets">Kaggle Datasets</a></li>
<li><a href="https://github.com/awesomedata/awesome-public-datasets">awesome-public-datasets</a> repository</li>
<li>etc.</li>
</ul>
<p> If you could find the needed dataset and its license allows you to re-use it, it is probably the fastest way to get straight to the model training.</p>
<p> I couldn&#x27;t find the dataset with labeled <span><code class="language-text">https://</code></span> prefixes though.</p>
<p>So we need to skip this option.</p>
<h3 id="option-2-generating-the-synthetic-dataset" style="position:relative">Option 2: Generating the synthetic dataset<a href="#option-2-generating-the-synthetic-dataset" aria-label="option 2 generating the synthetic dataset permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>There are tools that exist (i.e. <a href="https://keras-ocr.readthedocs.io/en/latest/examples/end_to_end_training.html#generating-synthetic-data">keras_ocr</a>) that might help us to generate random text, include the link in it, and draw it on images with some background and distortions.</p>
<p> The cool part about this approach is that we have the freedom to generate training examples for different <em>fonts</em>, <em>ligatures</em>, <em>text colors</em>, <em>background colors</em>. This is very useful if we want to avoid the <a href="https://en.wikipedia.org/wiki/Overfitting">model overfitting</a> during the training (so that the model could generalize well to unseen real-world examples instead of failing once the background shade is changed for a bit).</p>
<p> It is also possible to generate a variety of link types like <span><code class="language-text">http://</code></span>, <span><code class="language-text">http://</code></span>, <span><code class="language-text">ftp://</code></span>, <span><code class="language-text">tcp://</code></span> etc. Otherwise, it might be hard to find enough real-world examples of this kind of links for training.</p>
<p> Another benefit of this approach is that we could generate as many training examples as we want. We&#x27;re not limited to the number of pages of the printed book we&#x27;ve found for the dataset. Increasing the number of training examples may also increase the accuracy of the model.</p>
<p> It is possible though to misuse the generator and to generate the training images that will be quite different from real-world examples. Let&#x27;s say we may use the wrong and unrealistic distortions for the page (i.e. using waves bend instead of the arc one). In this case, the model will not generalize well to real-world examples.</p>
<blockquote>
<p>I see this approach as a really promising one. It may help to overcome many model issues (more on that below). I didn&#x27;t try it yet though. But it might be a good candidate for another article.</p>
</blockquote>
<h3 id="option-3-creating-the-dataset-manually" style="position:relative">Option 3: Creating the dataset manually<a href="#option-3-creating-the-dataset-manually" aria-label="option 3 creating the dataset manually permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>The most straightforward way though is to get the book (or books) and to make the pictures of the pages with the links and to label all of them manually.</p>
<p>The good news is that the dataset might be pretty small (hundreds of images might be enough) because we&#x27;re not going to train the model <em>from scratch</em> but instead, we&#x27;re going to do a <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> (also see the <a href="https://paperswithcode.com/task/few-shot-learning">few-shot learning</a>.)</p>
<p> In this case, the training dataset will be really close to real-world data. You will literally take the printed book, take a picture of it with realistic fonts, bends, shades, perspectives, and colors.</p>
<p> Even though it doesn&#x27;t require a lot of images it may still be time-consuming.</p>
<p> It is hard to come up with a diverse database where training examples would have different fonts, background colors, and different types of links (we need to find many diverse books and magazines to accomplish that).</p>
<p>Since the article has a learning purpose and since we&#x27;re not trying to win an object detection competition let&#x27;s go with this option for now and try to create a dataset by ourselves.</p>
<h3 id="preprocessing-the-data" style="position:relative">Preprocessing the data<a href="#preprocessing-the-data" aria-label="preprocessing the data permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>So, I&#x27;ve ended up shooting <span><code class="language-text">125</code></span> images of the book pages that contain one or more <span><code class="language-text">https://</code></span> links on them.</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 60.4%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAevlyFD/xAAXEAADAQAAAAAAAAAAAAAAAAAAESFB/9oACAEBAAEFAjNQor//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAZEAADAQEBAAAAAAAAAAAAAAAAATECIUH/2gAIAQEABj8CXNek1B80VlcH1n//xAAbEAEAAgMBAQAAAAAAAAAAAAABAFERMUFx0f/aAAgBAQABPyEDEBDOjE9iGlD2bKnY/QT/2gAMAwEAAgADAAAAEBMP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHhAAAQQCAwEAAAAAAAAAAAAAAQARITFBcVGBkcH/2gAIAQEAAT8QMiByxv4ugc83W0D3gMGBSI2NtOibWGe13tHJmnNCAgL/2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Raw Dataset"
        title=""
        src="/static/5ef08870a8d0193042c9da2c8aa8eb0c/a2510/15.jpg"
        srcset="/static/5ef08870a8d0193042c9da2c8aa8eb0c/0479a/15.jpg 250w,
/static/5ef08870a8d0193042c9da2c8aa8eb0c/41099/15.jpg 500w,
/static/5ef08870a8d0193042c9da2c8aa8eb0c/a2510/15.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>I put all these images in the <span><code class="language-text">dataset/printed_links/raw</code></span> folder.</p>
<p>Next, I&#x27;m going to preprocess the images by doing the following:</p>
<ul>
<li><strong>Resize</strong> each image to the width of <span><code class="language-text">1024px</code></span> (they are too big originally and have a width of <span><code class="language-text">3024px</code></span>)</li>
<li><strong>Crop</strong> each image to make them squared (this is optional, and we could just resize the image by simply squeezing it, but I want the model to be trained on realistic proportions of <span><code class="language-text">https:</code></span> boxes).</li>
<li><strong>Rotate</strong> image if needed by applying the <a href="https://en.wikipedia.org/wiki/Exif">exif</a> metadata.</li>
<li><strong>Greyscale</strong> the image (we don&#x27;t need the model to take the colors into consideration).</li>
<li><strong>Increase brightness</strong></li>
<li><strong>Increase contrast</strong></li>
<li><strong>Increase sharpness</strong></li>
</ul>
<p>Remember, that once we&#x27;ve decided to apply these transformations and adjustments to the dataset we need to do the same in the future for each image that we will send to the model for detection.</p>
<p>Here is how we could apply these adjustments to the image using Python:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> math
<span class="token keyword">import</span> shutil

<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token punctuation">,</span> ImageOps<span class="token punctuation">,</span> ImageEnhance

<span class="token comment"># Resize an image.</span>
<span class="token keyword">def</span> <span class="token function">preprocess_resize</span><span class="token punctuation">(</span>target_width<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>image<span class="token punctuation">:</span> Image<span class="token punctuation">.</span>Image<span class="token punctuation">,</span> log<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Image<span class="token punctuation">.</span>Image<span class="token punctuation">:</span>
        <span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">)</span> <span class="token operator">=</span> image<span class="token punctuation">.</span>size
        ratio <span class="token operator">=</span> width <span class="token operator">/</span> height

        <span class="token keyword">if</span> width <span class="token operator">></span> target_width<span class="token punctuation">:</span>
            target_height <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>target_width <span class="token operator">/</span> ratio<span class="token punctuation">)</span>
            log<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Resizing: To size </span><span class="token interpolation"><span class="token punctuation">{</span>target_width<span class="token punctuation">}</span></span><span class="token string">x</span><span class="token interpolation"><span class="token punctuation">{</span>target_height<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            image <span class="token operator">=</span> image<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span>target_width<span class="token punctuation">,</span> target_height<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            log<span class="token punctuation">(</span><span class="token string">'Resizing: Image already resized, skipping...'</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> image
    <span class="token keyword">return</span> preprocess

<span class="token comment"># Crop an image.</span>
<span class="token keyword">def</span> <span class="token function">preprocess_crop_square</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>image<span class="token punctuation">:</span> Image<span class="token punctuation">.</span>Image<span class="token punctuation">,</span> log<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Image<span class="token punctuation">.</span>Image<span class="token punctuation">:</span>
        <span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">)</span> <span class="token operator">=</span> image<span class="token punctuation">.</span>size

        left <span class="token operator">=</span> <span class="token number">0</span>
        top <span class="token operator">=</span> <span class="token number">0</span>
        right <span class="token operator">=</span> width
        bottom <span class="token operator">=</span> height

        crop_size <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">)</span>

        <span class="token keyword">if</span> width <span class="token operator">>=</span> height<span class="token punctuation">:</span>
            <span class="token comment"># Horizontal image.</span>
            log<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Squre cropping: Horizontal </span><span class="token interpolation"><span class="token punctuation">{</span>crop_size<span class="token punctuation">}</span></span><span class="token string">x</span><span class="token interpolation"><span class="token punctuation">{</span>crop_size<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            left <span class="token operator">=</span> width <span class="token operator">//</span> <span class="token number">2</span> <span class="token operator">-</span> crop_size <span class="token operator">//</span> <span class="token number">2</span>
            right <span class="token operator">=</span> left <span class="token operator">+</span> crop_size
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># Vetyical image.</span>
            log<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Squre cropping: Vertical </span><span class="token interpolation"><span class="token punctuation">{</span>crop_size<span class="token punctuation">}</span></span><span class="token string">x</span><span class="token interpolation"><span class="token punctuation">{</span>crop_size<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            top <span class="token operator">=</span> height <span class="token operator">//</span> <span class="token number">2</span> <span class="token operator">-</span> crop_size <span class="token operator">//</span> <span class="token number">2</span>
            bottom <span class="token operator">=</span> top <span class="token operator">+</span> crop_size

        image <span class="token operator">=</span> image<span class="token punctuation">.</span>crop<span class="token punctuation">(</span><span class="token punctuation">(</span>left<span class="token punctuation">,</span> top<span class="token punctuation">,</span> right<span class="token punctuation">,</span> bottom<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> image
    <span class="token keyword">return</span> preprocess

<span class="token comment"># Apply exif transpose to an image.</span>
<span class="token keyword">def</span> <span class="token function">preprocess_exif_transpose</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># @see: https://pillow.readthedocs.io/en/stable/reference/ImageOps.html</span>
    <span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>image<span class="token punctuation">:</span> Image<span class="token punctuation">.</span>Image<span class="token punctuation">,</span> log<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Image<span class="token punctuation">.</span>Image<span class="token punctuation">:</span>
        log<span class="token punctuation">(</span><span class="token string">'EXif transpose'</span><span class="token punctuation">)</span>
        image <span class="token operator">=</span> ImageOps<span class="token punctuation">.</span>exif_transpose<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        <span class="token keyword">return</span> image
    <span class="token keyword">return</span> preprocess

<span class="token comment"># Apply color transformations to the image.</span>
<span class="token keyword">def</span> <span class="token function">preprocess_color</span><span class="token punctuation">(</span>brightness<span class="token punctuation">,</span> contrast<span class="token punctuation">,</span> color<span class="token punctuation">,</span> sharpness<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># @see: https://pillow.readthedocs.io/en/3.0.x/reference/ImageEnhance.html</span>
    <span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>image<span class="token punctuation">:</span> Image<span class="token punctuation">.</span>Image<span class="token punctuation">,</span> log<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Image<span class="token punctuation">.</span>Image<span class="token punctuation">:</span>
        log<span class="token punctuation">(</span><span class="token string">'Coloring'</span><span class="token punctuation">)</span>

        enhancer <span class="token operator">=</span> ImageEnhance<span class="token punctuation">.</span>Color<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        image <span class="token operator">=</span> enhancer<span class="token punctuation">.</span>enhance<span class="token punctuation">(</span>color<span class="token punctuation">)</span>

        enhancer <span class="token operator">=</span> ImageEnhance<span class="token punctuation">.</span>Brightness<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        image <span class="token operator">=</span> enhancer<span class="token punctuation">.</span>enhance<span class="token punctuation">(</span>brightness<span class="token punctuation">)</span>

        enhancer <span class="token operator">=</span> ImageEnhance<span class="token punctuation">.</span>Contrast<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        image <span class="token operator">=</span> enhancer<span class="token punctuation">.</span>enhance<span class="token punctuation">(</span>contrast<span class="token punctuation">)</span>

        enhancer <span class="token operator">=</span> ImageEnhance<span class="token punctuation">.</span>Sharpness<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        image <span class="token operator">=</span> enhancer<span class="token punctuation">.</span>enhance<span class="token punctuation">(</span>sharpness<span class="token punctuation">)</span>

        <span class="token keyword">return</span> image
    <span class="token keyword">return</span> preprocess

<span class="token comment"># Image pre-processing pipeline.</span>
<span class="token keyword">def</span> <span class="token function">preprocess_pipeline</span><span class="token punctuation">(</span>src_dir<span class="token punctuation">,</span> dest_dir<span class="token punctuation">,</span> preprocessors<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> files_num_limit<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> override<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Create destination folder if not exists.</span>
    Path<span class="token punctuation">(</span>dest_dir<span class="token punctuation">)</span><span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>parents<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># Get the list of files to be copied.</span>
    src_file_names <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>src_dir<span class="token punctuation">)</span>
    files_total <span class="token operator">=</span> files_num_limit <span class="token keyword">if</span> files_num_limit <span class="token operator">></span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token builtin">len</span><span class="token punctuation">(</span>src_file_names<span class="token punctuation">)</span>
    files_processed <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token comment"># Logger function.</span>
    <span class="token keyword">def</span> <span class="token function">preprocessor_log</span><span class="token punctuation">(</span>message<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'  '</span> <span class="token operator">+</span> message<span class="token punctuation">)</span>

    <span class="token comment"># Iterate through files.</span>
    <span class="token keyword">for</span> src_file_index<span class="token punctuation">,</span> src_file_name <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>src_file_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> files_num_limit <span class="token operator">></span> <span class="token number">0</span> <span class="token keyword">and</span> src_file_index <span class="token operator">>=</span> files_num_limit<span class="token punctuation">:</span>
            <span class="token keyword">break</span>

        <span class="token comment"># Copy file.</span>
        src_file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>src_dir<span class="token punctuation">,</span> src_file_name<span class="token punctuation">)</span>
        dest_file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dest_dir<span class="token punctuation">,</span> src_file_name<span class="token punctuation">)</span>

        progress <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> <span class="token punctuation">(</span>src_file_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> files_total<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Image </span><span class="token interpolation"><span class="token punctuation">{</span>src_file_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>files_total<span class="token punctuation">}</span></span><span class="token string"> | </span><span class="token interpolation"><span class="token punctuation">{</span>progress<span class="token punctuation">}</span></span><span class="token string">% |  </span><span class="token interpolation"><span class="token punctuation">{</span>src_file_path<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>src_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
            preprocessor_log<span class="token punctuation">(</span><span class="token string">'Source is not a file, skipping...\n'</span><span class="token punctuation">)</span>
            <span class="token keyword">continue</span>

        <span class="token keyword">if</span> <span class="token keyword">not</span> override <span class="token keyword">and</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>dest_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
            preprocessor_log<span class="token punctuation">(</span><span class="token string">'File already exists, skipping...\n'</span><span class="token punctuation">)</span>
            <span class="token keyword">continue</span>

        shutil<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>src_file_path<span class="token punctuation">,</span> dest_file_path<span class="token punctuation">)</span>
        files_processed <span class="token operator">+=</span> <span class="token number">1</span>

        <span class="token comment"># Preprocess file.</span>
        image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>dest_file_path<span class="token punctuation">)</span>

        <span class="token keyword">for</span> preprocessor <span class="token keyword">in</span> preprocessors<span class="token punctuation">:</span>
            image <span class="token operator">=</span> preprocessor<span class="token punctuation">(</span>image<span class="token punctuation">,</span> preprocessor_log<span class="token punctuation">)</span>

        image<span class="token punctuation">.</span>save<span class="token punctuation">(</span>dest_file_path<span class="token punctuation">,</span> quality<span class="token operator">=</span><span class="token number">95</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>files_processed<span class="token punctuation">}</span></span><span class="token string"> out of </span><span class="token interpolation"><span class="token punctuation">{</span>files_total<span class="token punctuation">}</span></span><span class="token string"> files have been processed'</span></span><span class="token punctuation">)</span>

<span class="token comment"># Launching the image preprocessing pipeline.</span>
preprocess_pipeline<span class="token punctuation">(</span>
    src_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/raw'</span><span class="token punctuation">,</span>
    dest_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/processed'</span><span class="token punctuation">,</span>
    override<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token comment"># files_num_limit=1,</span>
    preprocessors<span class="token operator">=</span><span class="token punctuation">[</span>
        preprocess_exif_transpose<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        preprocess_resize<span class="token punctuation">(</span>target_width<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        preprocess_crop_square<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        preprocess_color<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> contrast<span class="token operator">=</span><span class="token number">1.3</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> sharpness<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span></code></pre></div></span>
<p>As a result, all processed images were saved to the <span><code class="language-text">dataset/printed_links/processed</code></span> folder.</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 52%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3LKAf//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEAAQUCX//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABYQAAMAAAAAAAAAAAAAAAAAAAEQIP/aAAgBAQABPyGCv//aAAwDAQACAAMAAAAQoM//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAeEAABBAIDAQAAAAAAAAAAAAABABExUSFBYXGBwf/aAAgBAQABPxBsRq+UQKvaADl7tABo19QT6gMntf/Z'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Dataset Processed"
        title=""
        src="/static/d573633530a534c4c87aeb4d0bc0f2d6/a2510/16.jpg"
        srcset="/static/d573633530a534c4c87aeb4d0bc0f2d6/0479a/16.jpg 250w,
/static/d573633530a534c4c87aeb4d0bc0f2d6/41099/16.jpg 500w,
/static/d573633530a534c4c87aeb4d0bc0f2d6/a2510/16.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>You may preview the images like this:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">preview_images</span><span class="token punctuation">(</span>images_dir<span class="token punctuation">,</span> images_num<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    image_names <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>images_dir<span class="token punctuation">)</span>
    image_names <span class="token operator">=</span> image_names<span class="token punctuation">[</span><span class="token punctuation">:</span>images_num<span class="token punctuation">]</span>

    num_cells <span class="token operator">=</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>images_num<span class="token punctuation">)</span><span class="token punctuation">)</span>
    figure <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span>figsize<span class="token punctuation">)</span>

    <span class="token keyword">for</span> image_index<span class="token punctuation">,</span> image_name <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>image_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>images_dir<span class="token punctuation">,</span> image_name<span class="token punctuation">)</span>
        image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>

        figure<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span>num_cells<span class="token punctuation">,</span> num_cells<span class="token punctuation">,</span> image_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

preview_images<span class="token punctuation">(</span><span class="token string">'dataset/printed_links/processed'</span><span class="token punctuation">,</span> images_num<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></div></span>
<h3 id="labeling-the-dataset" style="position:relative">Labeling the dataset<a href="#labeling-the-dataset" aria-label="labeling the dataset permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>To do the labeling (to mark the locations of the objects that we&#x27;re interested in, namely the <span><code class="language-text">https://</code></span> prefixes) we may use the <a href="https://github.com/tzutalin/labelImg">LabelImg</a> graphical image annotation tool.</p>
<blockquote>
<p>For this step you might want to install the LabelImg tool on your local machine (not in Colab). You may find the detailed installation instructions in <a href="https://github.com/tzutalin/labelImg">LabelImg README</a>.</p>
</blockquote>
<p>Once you have LabelImg tool installed you may launch it for the <span><code class="language-text">dataset/printed_links/processed</code></span> folder from the root of your project like this:</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">labelImg dataset/printed_links/processed</code></pre></div></span>
<p>Then you&#x27;ll need to label all the images from the <span><code class="language-text">dataset/printed_links/processed</code></span> folder and save annotations as XML files to <span><code class="language-text">dataset/printed_links/labels/xml/</code></span> folder.</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 49.199999999999996%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAIBAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHXdYGKg//EABcQAQADAAAAAAAAAAAAAAAAABAAIUH/2gAIAQEAAQUCKmH/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAWEAADAAAAAAAAAAAAAAAAAAAQIDH/2gAIAQEABj8CFT//xAAbEAACAgMBAAAAAAAAAAAAAAAAAREhEDGh8P/aAAgBAQABPyFOkTW+HmBYSf/aAAwDAQACAAMAAAAQg8//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAcEAEAAQQDAAAAAAAAAAAAAAABABEhMUFxkdH/2gAIAQEAAT8QxDzL6EnaDR4zfuLFGFn/2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Labeling"
        title=""
        src="/static/84c3f7d93cf84fce45d6093732c6ef01/a2510/17.jpg"
        srcset="/static/84c3f7d93cf84fce45d6093732c6ef01/0479a/17.jpg 250w,
/static/84c3f7d93cf84fce45d6093732c6ef01/41099/17.jpg 500w,
/static/84c3f7d93cf84fce45d6093732c6ef01/a2510/17.jpg 1000w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<img src="/posts-assets/1a60a56a4a04291057f8b04ae1d6aed2/18.gif" alt="Labeling Process"/>
<p>After the labeling we should have an XML file with bounding boxes data for each image:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 622px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 86.4%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAARABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABYBAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAAB5hbnIAID/8QAFhAAAwAAAAAAAAAAAAAAAAAAABEw/9oACAEBAAEFAhQ//8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAFBABAAAAAAAAAAAAAAAAAAAAMP/aAAgBAQAGPwIf/8QAGRABAQEBAQEAAAAAAAAAAAAAAQARURAh/9oACAEBAAE/ITbXGxh+yvbYnz//2gAMAwEAAgADAAAAEI8Xff/EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8QH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8QH//EAB0QAAICAQUAAAAAAAAAAAAAAAABETEhEFFhgZH/2gAIAQEAAT8QRlEMactXRwMZDLIlvSW7LFNP/9k='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Labels folder structure"
        title=""
        src="/static/bfa1a524d91a647ee2ecfcd419d1be74/5e4ef/19.jpg"
        srcset="/static/bfa1a524d91a647ee2ecfcd419d1be74/0479a/19.jpg 250w,
/static/bfa1a524d91a647ee2ecfcd419d1be74/41099/19.jpg 500w,
/static/bfa1a524d91a647ee2ecfcd419d1be74/5e4ef/19.jpg 622w"
        sizes="(max-width: 622px) 100vw, 622px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<h3 id="splitting-the-dataset-into-train-test-and-validation-subsets" style="position:relative">Splitting the dataset into train, test, and validation subsets<a href="#splitting-the-dataset-into-train-test-and-validation-subsets" aria-label="splitting the dataset into train test and validation subsets permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>To identify the model&#x27;s <a href="https://en.wikipedia.org/wiki/Overfitting">overfitting or underfitting</a> issue we need to split the dataset into <span><code class="language-text">train</code></span> and <span><code class="language-text">test</code></span> dataset. Let&#x27;s say <span><code class="language-text">80%</code></span> of our images will be used to train the model and <span><code class="language-text">20%</code></span> of the images will be used to check how well the model generalizes to the images that it didn&#x27;t see before.</p>
<blockquote>
<p>In this section we&#x27;ll do the files splitting by copying them into different folders (<span><code class="language-text">test</code></span> and <span><code class="language-text">train</code></span> folders). However, this might not be the most optimal way. Instead, the splitting of the dataset may be done on <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset">tf.data.Dataset</a> level.</p>
</blockquote>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> re
<span class="token keyword">import</span> random

<span class="token keyword">def</span> <span class="token function">partition_dataset</span><span class="token punctuation">(</span>
    images_dir<span class="token punctuation">,</span>
    xml_labels_dir<span class="token punctuation">,</span>
    train_dir<span class="token punctuation">,</span>
    test_dir<span class="token punctuation">,</span>
    val_dir<span class="token punctuation">,</span>
    train_ratio<span class="token punctuation">,</span>
    test_ratio<span class="token punctuation">,</span>
    val_ratio<span class="token punctuation">,</span>
    copy_xml
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>train_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>train_dir<span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>test_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>test_dir<span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>val_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>val_dir<span class="token punctuation">)</span>

    images <span class="token operator">=</span> <span class="token punctuation">[</span>f <span class="token keyword">for</span> f <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>images_dir<span class="token punctuation">)</span>
              <span class="token keyword">if</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span><span class="token string">r'([a-zA-Z0-9\s_\\.\-\(\):])+(.jpg|.jpeg|.png)$'</span><span class="token punctuation">,</span> f<span class="token punctuation">,</span> re<span class="token punctuation">.</span>IGNORECASE<span class="token punctuation">)</span><span class="token punctuation">]</span>

    num_images <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>images<span class="token punctuation">)</span>

    num_train_images <span class="token operator">=</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>train_ratio <span class="token operator">*</span> num_images<span class="token punctuation">)</span>
    num_test_images <span class="token operator">=</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>test_ratio <span class="token operator">*</span> num_images<span class="token punctuation">)</span>
    num_val_images <span class="token operator">=</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>val_ratio <span class="token operator">*</span> num_images<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Intended split'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'  train: </span><span class="token interpolation"><span class="token punctuation">{</span>num_train_images<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_images<span class="token punctuation">}</span></span><span class="token string"> images'</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'  test: </span><span class="token interpolation"><span class="token punctuation">{</span>num_test_images<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_images<span class="token punctuation">}</span></span><span class="token string"> images'</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'  val: </span><span class="token interpolation"><span class="token punctuation">{</span>num_val_images<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_images<span class="token punctuation">}</span></span><span class="token string"> images'</span></span><span class="token punctuation">)</span>

    actual_num_train_images <span class="token operator">=</span> <span class="token number">0</span>
    actual_num_test_images <span class="token operator">=</span> <span class="token number">0</span>
    actual_num_val_images <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">def</span> <span class="token function">copy_random_images</span><span class="token punctuation">(</span>num_images<span class="token punctuation">,</span> dest_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        copied_num <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token keyword">if</span> <span class="token keyword">not</span> num_images<span class="token punctuation">:</span>
            <span class="token keyword">return</span> copied_num

        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_images<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">len</span><span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">break</span>

            idx <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            filename <span class="token operator">=</span> images<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
            shutil<span class="token punctuation">.</span>copyfile<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>images_dir<span class="token punctuation">,</span> filename<span class="token punctuation">)</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dest_dir<span class="token punctuation">,</span> filename<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token keyword">if</span> copy_xml<span class="token punctuation">:</span>
                xml_filename <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>splitext<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">'.xml'</span>
                shutil<span class="token punctuation">.</span>copyfile<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>xml_labels_dir<span class="token punctuation">,</span> xml_filename<span class="token punctuation">)</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dest_dir<span class="token punctuation">,</span> xml_filename<span class="token punctuation">)</span><span class="token punctuation">)</span>

            images<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>images<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span>
            copied_num <span class="token operator">+=</span> <span class="token number">1</span>

        <span class="token keyword">return</span> copied_num

    actual_num_train_images <span class="token operator">=</span> copy_random_images<span class="token punctuation">(</span>num_train_images<span class="token punctuation">,</span> train_dir<span class="token punctuation">)</span>
    actual_num_test_images <span class="token operator">=</span> copy_random_images<span class="token punctuation">(</span>num_test_images<span class="token punctuation">,</span> test_dir<span class="token punctuation">)</span>
    actual_num_val_images <span class="token operator">=</span> copy_random_images<span class="token punctuation">(</span>num_val_images<span class="token punctuation">,</span> val_dir<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">'Actual split'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'  train: </span><span class="token interpolation"><span class="token punctuation">{</span>actual_num_train_images<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_images<span class="token punctuation">}</span></span><span class="token string"> images'</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'  test: </span><span class="token interpolation"><span class="token punctuation">{</span>actual_num_test_images<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_images<span class="token punctuation">}</span></span><span class="token string"> images'</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'  val: </span><span class="token interpolation"><span class="token punctuation">{</span>actual_num_val_images<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_images<span class="token punctuation">}</span></span><span class="token string"> images'</span></span><span class="token punctuation">)</span>

partition_dataset<span class="token punctuation">(</span>
    images_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/processed'</span><span class="token punctuation">,</span>
    train_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/partitioned/train'</span><span class="token punctuation">,</span>
    test_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/partitioned/test'</span><span class="token punctuation">,</span>
    val_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/partitioned/val'</span><span class="token punctuation">,</span>
    xml_labels_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/labels/xml'</span><span class="token punctuation">,</span>
    train_ratio<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span>
    test_ratio<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>
    val_ratio<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
    copy_xml<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span></code></pre></div></span>
<p>After splitting your dataset folder structure should look similar to this:</p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">dataset/
 printed_links
     labels
        xml
     partitioned
        test
        train
            IMG_9140.JPG
            IMG_9140.xml
            IMG_9141.JPG
            IMG_9141.xml
           ...
     processed
     raw</code></pre></div></span>
<h3 id="exporting-the-dataset" style="position:relative">Exporting the dataset<a href="#exporting-the-dataset" aria-label="exporting the dataset permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>The last manipulation we should do with the data is to convert our datasets into <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">TFRecord</a> format. The <span><code class="language-text">TFRecord</code></span> format is a format that TensorFlow is using for storing a sequence of binary records.</p>
<p>First, let&#x27;s create two folders: one is for the labels in <span><code class="language-text">CSV</code></span> format, and the other one is for the final dataset in <span><code class="language-text">TFRecord</code></span> format.</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> dataset/printed_links/labels/csv
<span class="token function">mkdir</span> <span class="token parameter variable">-p</span> dataset/printed_links/tfrecords</code></pre></div></span>
<p>Now we need to create a <span><code class="language-text">dataset/printed_links/labels/label_map.pbtxt</code></span> proto file that will describe the classes of the objects in our dataset. In our case, we only have <em>one class</em> which we may call <span><code class="language-text">http</code></span>. Here is the content of this file:</p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">item {
  id: 1
  name: 'http'
}</code></pre></div></span>
<p>Now we&#x27;re ready to generate the TFRecord datasets out of images in <span><code class="language-text">jpg</code></span> format and labels in <span><code class="language-text">xml</code></span> format:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> io
<span class="token keyword">import</span> math
<span class="token keyword">import</span> glob
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> xml<span class="token punctuation">.</span>etree<span class="token punctuation">.</span>ElementTree <span class="token keyword">as</span> ET
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> collections <span class="token keyword">import</span> namedtuple
<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>utils <span class="token keyword">import</span> dataset_util<span class="token punctuation">,</span> label_map_util

tf1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1

<span class="token comment"># Convers labels from XML format to CSV.</span>
<span class="token keyword">def</span> <span class="token function">xml_to_csv</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    xml_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> xml_file <span class="token keyword">in</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>path <span class="token operator">+</span> <span class="token string">'/*.xml'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        tree <span class="token operator">=</span> ET<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>xml_file<span class="token punctuation">)</span>
        root <span class="token operator">=</span> tree<span class="token punctuation">.</span>getroot<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> member <span class="token keyword">in</span> root<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">'object'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            value <span class="token operator">=</span> <span class="token punctuation">(</span>root<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'filename'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">,</span>
                <span class="token builtin">int</span><span class="token punctuation">(</span>root<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'size'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token builtin">int</span><span class="token punctuation">(</span>root<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'size'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span>
                member<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>text<span class="token punctuation">,</span>
                <span class="token builtin">int</span><span class="token punctuation">(</span>member<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token builtin">int</span><span class="token punctuation">(</span>member<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token builtin">int</span><span class="token punctuation">(</span>member<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token builtin">int</span><span class="token punctuation">(</span>member<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
            xml_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>
    column_name <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'filename'</span><span class="token punctuation">,</span> <span class="token string">'width'</span><span class="token punctuation">,</span> <span class="token string">'height'</span><span class="token punctuation">,</span> <span class="token string">'class'</span><span class="token punctuation">,</span> <span class="token string">'xmin'</span><span class="token punctuation">,</span> <span class="token string">'ymin'</span><span class="token punctuation">,</span> <span class="token string">'xmax'</span><span class="token punctuation">,</span> <span class="token string">'ymax'</span><span class="token punctuation">]</span>
    xml_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>xml_list<span class="token punctuation">,</span> columns<span class="token operator">=</span>column_name<span class="token punctuation">)</span>
    <span class="token keyword">return</span> xml_df


<span class="token keyword">def</span> <span class="token function">class_text_to_int</span><span class="token punctuation">(</span>row_label<span class="token punctuation">,</span> label_map_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> label_map_dict<span class="token punctuation">[</span>row_label<span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">split</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> group<span class="token punctuation">)</span><span class="token punctuation">:</span>
    data <span class="token operator">=</span> namedtuple<span class="token punctuation">(</span><span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'filename'</span><span class="token punctuation">,</span> <span class="token string">'object'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    gb <span class="token operator">=</span> df<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span>group<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>data<span class="token punctuation">(</span>filename<span class="token punctuation">,</span> gb<span class="token punctuation">.</span>get_group<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> filename<span class="token punctuation">,</span> x <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>gb<span class="token punctuation">.</span>groups<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> gb<span class="token punctuation">.</span>groups<span class="token punctuation">)</span><span class="token punctuation">]</span>


<span class="token comment"># Creates a TFRecord.</span>
<span class="token keyword">def</span> <span class="token function">create_tf_example</span><span class="token punctuation">(</span>group<span class="token punctuation">,</span> path<span class="token punctuation">,</span> label_map_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> tf1<span class="token punctuation">.</span>gfile<span class="token punctuation">.</span>GFile<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>group<span class="token punctuation">.</span>filename<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fid<span class="token punctuation">:</span>
        encoded_jpg <span class="token operator">=</span> fid<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>

    encoded_jpg_io <span class="token operator">=</span> io<span class="token punctuation">.</span>BytesIO<span class="token punctuation">(</span>encoded_jpg<span class="token punctuation">)</span>
    image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>encoded_jpg_io<span class="token punctuation">)</span>
    width<span class="token punctuation">,</span> height <span class="token operator">=</span> image<span class="token punctuation">.</span>size

    filename <span class="token operator">=</span> group<span class="token punctuation">.</span>filename<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">'utf8'</span><span class="token punctuation">)</span>
    image_format <span class="token operator">=</span> <span class="token string">b'jpg'</span>
    xmins <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    xmaxs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    ymins <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    ymaxs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    classes_text <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    classes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> index<span class="token punctuation">,</span> row <span class="token keyword">in</span> group<span class="token punctuation">.</span><span class="token builtin">object</span><span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        xmins<span class="token punctuation">.</span>append<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">'xmin'</span><span class="token punctuation">]</span> <span class="token operator">/</span> width<span class="token punctuation">)</span>
        xmaxs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">'xmax'</span><span class="token punctuation">]</span> <span class="token operator">/</span> width<span class="token punctuation">)</span>
        ymins<span class="token punctuation">.</span>append<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">'ymin'</span><span class="token punctuation">]</span> <span class="token operator">/</span> height<span class="token punctuation">)</span>
        ymaxs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">'ymax'</span><span class="token punctuation">]</span> <span class="token operator">/</span> height<span class="token punctuation">)</span>
        classes_text<span class="token punctuation">.</span>append<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">'class'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">'utf8'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        classes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>class_text_to_int<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">'class'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label_map_dict<span class="token punctuation">)</span><span class="token punctuation">)</span>

    tf_example <span class="token operator">=</span> tf1<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Example<span class="token punctuation">(</span>features<span class="token operator">=</span>tf1<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Features<span class="token punctuation">(</span>feature<span class="token operator">=</span><span class="token punctuation">{</span>
        <span class="token string">'image/height'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>int64_feature<span class="token punctuation">(</span>height<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/width'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>int64_feature<span class="token punctuation">(</span>width<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/filename'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>bytes_feature<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/source_id'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>bytes_feature<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/encoded'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>bytes_feature<span class="token punctuation">(</span>encoded_jpg<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/format'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>bytes_feature<span class="token punctuation">(</span>image_format<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/object/bbox/xmin'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>float_list_feature<span class="token punctuation">(</span>xmins<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/object/bbox/xmax'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>float_list_feature<span class="token punctuation">(</span>xmaxs<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/object/bbox/ymin'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>float_list_feature<span class="token punctuation">(</span>ymins<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/object/bbox/ymax'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>float_list_feature<span class="token punctuation">(</span>ymaxs<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/object/class/text'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>bytes_list_feature<span class="token punctuation">(</span>classes_text<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'image/object/class/label'</span><span class="token punctuation">:</span> dataset_util<span class="token punctuation">.</span>int64_list_feature<span class="token punctuation">(</span>classes<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> tf_example


<span class="token keyword">def</span> <span class="token function">dataset_to_tfrecord</span><span class="token punctuation">(</span>
    images_dir<span class="token punctuation">,</span>
    xmls_dir<span class="token punctuation">,</span>
    label_map_path<span class="token punctuation">,</span>
    output_path<span class="token punctuation">,</span>
    csv_path<span class="token operator">=</span><span class="token boolean">None</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    label_map <span class="token operator">=</span> label_map_util<span class="token punctuation">.</span>load_labelmap<span class="token punctuation">(</span>label_map_path<span class="token punctuation">)</span>
    label_map_dict <span class="token operator">=</span> label_map_util<span class="token punctuation">.</span>get_label_map_dict<span class="token punctuation">(</span>label_map<span class="token punctuation">)</span>

    tfrecord_writer <span class="token operator">=</span> tf1<span class="token punctuation">.</span>python_io<span class="token punctuation">.</span>TFRecordWriter<span class="token punctuation">(</span>output_path<span class="token punctuation">)</span>
    images_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>images_dir<span class="token punctuation">)</span>
    csv_examples <span class="token operator">=</span> xml_to_csv<span class="token punctuation">(</span>xmls_dir<span class="token punctuation">)</span>
    grouped_examples <span class="token operator">=</span> split<span class="token punctuation">(</span>csv_examples<span class="token punctuation">,</span> <span class="token string">'filename'</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> group <span class="token keyword">in</span> grouped_examples<span class="token punctuation">:</span>
        tf_example <span class="token operator">=</span> create_tf_example<span class="token punctuation">(</span>group<span class="token punctuation">,</span> images_path<span class="token punctuation">,</span> label_map_dict<span class="token punctuation">)</span>
        tfrecord_writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>tf_example<span class="token punctuation">.</span>SerializeToString<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    tfrecord_writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Successfully created the TFRecord file: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>output_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> csv_path <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        csv_examples<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>csv_path<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Successfully created the CSV file: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>csv_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Generate a TFRecord for train dataset.</span>
dataset_to_tfrecord<span class="token punctuation">(</span>
    images_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/partitioned/train'</span><span class="token punctuation">,</span>
    xmls_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/partitioned/train'</span><span class="token punctuation">,</span>
    label_map_path<span class="token operator">=</span><span class="token string">'dataset/printed_links/labels/label_map.pbtxt'</span><span class="token punctuation">,</span>
    output_path<span class="token operator">=</span><span class="token string">'dataset/printed_links/tfrecords/train.record'</span><span class="token punctuation">,</span>
    csv_path<span class="token operator">=</span><span class="token string">'dataset/printed_links/labels/csv/train.csv'</span>
<span class="token punctuation">)</span>

<span class="token comment"># Generate a TFRecord for test dataset.</span>
dataset_to_tfrecord<span class="token punctuation">(</span>
    images_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/partitioned/test'</span><span class="token punctuation">,</span>
    xmls_dir<span class="token operator">=</span><span class="token string">'dataset/printed_links/partitioned/test'</span><span class="token punctuation">,</span>
    label_map_path<span class="token operator">=</span><span class="token string">'dataset/printed_links/labels/label_map.pbtxt'</span><span class="token punctuation">,</span>
    output_path<span class="token operator">=</span><span class="token string">'dataset/printed_links/tfrecords/test.record'</span><span class="token punctuation">,</span>
    csv_path<span class="token operator">=</span><span class="token string">'dataset/printed_links/labels/csv/test.csv'</span>
<span class="token punctuation">)</span></code></pre></div></span>
<p>As a result we should now have two files: <span><code class="language-text">test.record</code></span> and <span><code class="language-text">train.record</code></span> in <span><code class="language-text">dataset/printed_links/tfrecords/</code></span> folder:</p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">dataset/
 printed_links
     labels
        csv
        label_map.pbtxt
        xml
     partitioned
        test
        train
        val
     processed
     raw
     tfrecords
         test.record
         train.record</code></pre></div></span>
<p>These two files <span><code class="language-text">test.record</code></span> and <span><code class="language-text">train.record</code></span> are our final datasets that we will use to fine-tune the <span><code class="language-text">ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8</code></span> model.</p>
<h2 id="-exploring-the-tfrecord-datasets" style="position:relative"> Exploring the TFRecord Datasets<a href="#-exploring-the-tfrecord-datasets" aria-label=" exploring the tfrecord datasets permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>In this section, we will see how we may use the TensorFlow 2 Object Detection API to explore the datasets in <span><code class="language-text">TFRecord</code></span> format.</p>
<p><strong>Checking the number of items in a dataset</strong></p>
<p>To count the number of items in the dataset we may do the following:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

<span class="token comment"># Count the number of examples in the dataset.</span>
<span class="token keyword">def</span> <span class="token function">count_tfrecords</span><span class="token punctuation">(</span>tfrecords_filename<span class="token punctuation">)</span><span class="token punctuation">:</span>
    raw_dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TFRecordDataset<span class="token punctuation">(</span>tfrecords_filename<span class="token punctuation">)</span>
    <span class="token comment"># Keep in mind that the list() operation might be</span>
    <span class="token comment"># a performance bottleneck for large datasets.</span>
    <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>raw_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>

TRAIN_RECORDS_NUM <span class="token operator">=</span> count_tfrecords<span class="token punctuation">(</span><span class="token string">'dataset/printed_links/tfrecords/train.record'</span><span class="token punctuation">)</span>
TEST_RECORDS_NUM <span class="token operator">=</span> count_tfrecords<span class="token punctuation">(</span><span class="token string">'dataset/printed_links/tfrecords/test.record'</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'TRAIN_RECORDS_NUM: '</span><span class="token punctuation">,</span> TRAIN_RECORDS_NUM<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'TEST_RECORDS_NUM:  '</span><span class="token punctuation">,</span> TEST_RECORDS_NUM<span class="token punctuation">)</span></code></pre></div></span>
<p><em>output </em></p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">TRAIN_RECORDS_NUM:  100
TEST_RECORDS_NUM:   25</code></pre></div></span>
<p>So we will train the model on <span><code class="language-text">100</code></span> examples, and we will check the model accuracy on <span><code class="language-text">25</code></span> test images.</p>
<p><strong>Previewing the dataset images with bounding boxes</strong></p>
<p>To preview images with detection boxes we may do the following:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> google<span class="token punctuation">.</span>protobuf <span class="token keyword">import</span> text_format
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># Import Object Detection API.</span>
<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>utils <span class="token keyword">import</span> visualization_utils
<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>protos <span class="token keyword">import</span> string_int_label_map_pb2
<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>data_decoders<span class="token punctuation">.</span>tf_example_decoder <span class="token keyword">import</span> TfExampleDecoder

<span class="token operator">%</span>matplotlib inline

<span class="token comment"># Visualize the TFRecord dataset.</span>
<span class="token keyword">def</span> <span class="token function">visualize_tfrecords</span><span class="token punctuation">(</span>tfrecords_filename<span class="token punctuation">,</span> label_map<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> print_num<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    decoder <span class="token operator">=</span> TfExampleDecoder<span class="token punctuation">(</span>
        label_map_proto_file<span class="token operator">=</span>label_map<span class="token punctuation">,</span>
        use_display_name<span class="token operator">=</span><span class="token boolean">False</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">if</span> label_map <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        label_map_proto <span class="token operator">=</span> string_int_label_map_pb2<span class="token punctuation">.</span>StringIntLabelMap<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">with</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>gfile<span class="token punctuation">.</span>GFile<span class="token punctuation">(</span>label_map<span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            text_format<span class="token punctuation">.</span>Merge<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label_map_proto<span class="token punctuation">)</span>
            class_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

            <span class="token keyword">for</span> entry <span class="token keyword">in</span> label_map_proto<span class="token punctuation">.</span>item<span class="token punctuation">:</span>
                class_dict<span class="token punctuation">[</span>entry<span class="token punctuation">.</span><span class="token builtin">id</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'name'</span><span class="token punctuation">:</span> entry<span class="token punctuation">.</span>name<span class="token punctuation">}</span>

    raw_dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TFRecordDataset<span class="token punctuation">(</span>tfrecords_filename<span class="token punctuation">)</span>

    <span class="token keyword">for</span> raw_record <span class="token keyword">in</span> raw_dataset<span class="token punctuation">.</span>take<span class="token punctuation">(</span>print_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        example <span class="token operator">=</span> decoder<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>raw_record<span class="token punctuation">)</span>

        image <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        boxes <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">'groundtruth_boxes'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        confidences <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">'groundtruth_image_confidences'</span><span class="token punctuation">]</span>
        filename <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">'filename'</span><span class="token punctuation">]</span>
        area <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">'groundtruth_area'</span><span class="token punctuation">]</span>
        classes <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">'groundtruth_classes'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        image_classes <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">'groundtruth_image_classes'</span><span class="token punctuation">]</span>
        weights <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">'groundtruth_weights'</span><span class="token punctuation">]</span>

        scores <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>boxes<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        visualization_utils<span class="token punctuation">.</span>visualize_boxes_and_labels_on_image_array<span class="token punctuation">(</span>
            image<span class="token punctuation">,</span>
            boxes<span class="token punctuation">,</span>
            classes<span class="token punctuation">,</span>
            scores<span class="token punctuation">,</span>
            class_dict<span class="token punctuation">,</span>
            max_boxes_to_draw<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
            use_normalized_coordinates<span class="token operator">=</span><span class="token boolean">True</span>
        <span class="token punctuation">)</span>

        plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Visualizing the training TFRecord dataset.</span>
visualize_tfrecords<span class="token punctuation">(</span>
    tfrecords_filename<span class="token operator">=</span><span class="token string">'dataset/printed_links/tfrecords/train.record'</span><span class="token punctuation">,</span>
    label_map<span class="token operator">=</span><span class="token string">'dataset/printed_links/labels/label_map.pbtxt'</span><span class="token punctuation">,</span>
    print_num<span class="token operator">=</span><span class="token number">3</span>
<span class="token punctuation">)</span></code></pre></div></span>
<p>As a result, we should see several images with bounding boxes drawn on top of each image.</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 962px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 98%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAH33PREDIUH/8QAGBAAAwEBAAAAAAAAAAAAAAAAAAIRECH/2gAIAQEAAQUCxSwomrw//8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAFxAAAwEAAAAAAAAAAAAAAAAAARBxIP/aAAgBAQAGPwJGs3H/xAAdEAACAgEFAAAAAAAAAAAAAAAAAREhcRAxUZGx/9oACAEBAAE/IdPQUpbmI0rIRPQ0VNLk/9oADAMBAAIAAwAAABBjwDz/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAbEAEBAQEAAwEAAAAAAAAAAAABEQAhMUFRkf/aAAgBAQABPxACHDQ+ZU9oG4/iHV1S1+ax0kFvMIGLwHDzQt7v/9k='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="TFRecord Preview"
        title=""
        src="/static/ae63de06652048e7989d778b786dfec0/82d6d/20.jpg"
        srcset="/static/ae63de06652048e7989d778b786dfec0/0479a/20.jpg 250w,
/static/ae63de06652048e7989d778b786dfec0/41099/20.jpg 500w,
/static/ae63de06652048e7989d778b786dfec0/82d6d/20.jpg 962w"
        sizes="(max-width: 962px) 100vw, 962px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<h2 id="-setting-up-tensorboard" style="position:relative"> Setting Up TensorBoard<a href="#-setting-up-tensorboard" aria-label=" setting up tensorboard permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>Before starting the training process we need to launch a <a href="https://www.tensorflow.org/tensorboard">TensorBoard</a>.</p>
<p>TensorBoard will allow us to monitor the training process and see if the model is actually learning something or should we better stop the training and adjust training parameters. It will also help us to analyze what objects and at what location the model is detecting.</p>
<img src="/posts-assets/d5ee9f7aee1b94550125340243d5ccf5/21.gif" alt="TensorBoard"/>
<p><em>Image source: <a href="https://www.tensorflow.org/tensorboard">TensorBoard homepage</a></em></p>
<p>The cool part about TensorBoard is that we may run it directly in Google Colab. However, if you&#x27;re running the notebook in your local installation of Jupyter you may also <a href="https://github.com/tensorflow/tensorboard/blob/master/README.md">install it as Python package</a> and launch it from the terminal.</p>
<p>First, let&#x27;s create a <span><code class="language-text">./logs</code></span> folder where all training logs will be written:</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> logs</code></pre></div></span>
<p>Next, we may load the TensorBoard extension on Google Colab:</p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">%load_ext tensorboard</code></pre></div></span>
<p>And finally we may launch a TensorBoard to monitor the <span><code class="language-text">./logs</code></span> folder:</p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">%tensorboard --logdir ./logs</code></pre></div></span>
<p>As a result, you should see the empty TensorBoard panel:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 54.400000000000006%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDAgX/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAeyqPNyUD//EABgQAAMBAQAAAAAAAAAAAAAAAAABEgIQ/9oACAEBAAEFAnkkgff/xAAWEQADAAAAAAAAAAAAAAAAAAAAARH/2gAIAQMBAT8BrKz/xAAWEQADAAAAAAAAAAAAAAAAAAAAARL/2gAIAQIBAT8BlEo//8QAGhAAAgIDAAAAAAAAAAAAAAAAAJEBMQIgMv/aAAgBAQAGPwK5Z1LLyen/xAAZEAEAAwEBAAAAAAAAAAAAAAABABARIUH/2gAIAQEAAT8hPdmC0k8wOV//2gAMAwEAAgADAAAAEOz/AP/EABURAQEAAAAAAAAAAAAAAAAAAABh/9oACAEDAQE/ELLP/8QAFREBAQAAAAAAAAAAAAAAAAAAAGH/2gAIAQIBAT8Qgg//xAAdEAACAgEFAAAAAAAAAAAAAAABEQAhEEFRccHR/9oACAEBAAE/EAqFnRFDXf8AIBElrbwRYt84/9k='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Empty TensorBoard Panel"
        title=""
        src="/static/95e5581c409416c73ade13bd383b8274/a2510/22.jpg"
        srcset="/static/95e5581c409416c73ade13bd383b8274/0479a/22.jpg 250w,
/static/95e5581c409416c73ade13bd383b8274/41099/22.jpg 500w,
/static/95e5581c409416c73ade13bd383b8274/a2510/22.jpg 1000w,
/static/95e5581c409416c73ade13bd383b8274/c58a3/22.jpg 1500w,
/static/95e5581c409416c73ade13bd383b8274/5ed7a/22.jpg 1832w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>After the model training is be started you may get back to this panel and see the training process progress.</p>
<h2 id="-model-training" style="position:relative"> Model Training<a href="#%EF%B8%8F-model-training" aria-label=" model training permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<h3 id="configuring-the-detection-pipeline" style="position:relative">Configuring the Detection Pipeline<a href="#configuring-the-detection-pipeline" aria-label="configuring the detection pipeline permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>Now it&#x27;s time to get back to the <span><code class="language-text">cache/datasets/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config</code></span> file that we&#x27;ve mentioned earlier. This file defines the parameters of <span><code class="language-text">ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8</code></span> model training.</p>
<p>We need to copy the <span><code class="language-text">pipeline.config</code></span> file to the root of the project and adjust a couple of things in it:</p>
<ol>
<li>We should change the <strong>number of classes</strong> from <span><code class="language-text">90</code></span> (the COCO classes) to just <span><code class="language-text">1</code></span> (the <span><code class="language-text">http</code></span> class).</li>
<li>We should reduce the <strong>batch size</strong> to <span><code class="language-text">8</code></span> to avoid the errors that are connected to the insufficient memory.</li>
<li>We need to point the model to its <strong>checkpoints</strong> since we don&#x27;t want to train the model from scratch.</li>
<li>We need to change the <span><code class="language-text">fine_tune_checkpoint_type</code></span> to <span><code class="language-text">detection</code></span>.</li>
<li>We need to point the model to a proper <strong>labels map</strong>.</li>
<li>Lastly, we need to pint the model to the <strong>train and test datasets</strong>.</li>
</ol>
<p>All these changes may be done manually directly in <span><code class="language-text">pipeline.config</code></span> file. But we may also do them through code:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> shutil <span class="token keyword">import</span> copyfile
<span class="token keyword">from</span> google<span class="token punctuation">.</span>protobuf <span class="token keyword">import</span> text_format
<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>protos <span class="token keyword">import</span> pipeline_pb2

<span class="token comment"># Adjust pipeline config modification here if needed.</span>
<span class="token keyword">def</span> <span class="token function">modify_config</span><span class="token punctuation">(</span>pipeline<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Model config.</span>
    pipeline<span class="token punctuation">.</span>model<span class="token punctuation">.</span>ssd<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> <span class="token number">1</span>

    <span class="token comment"># Train config.</span>
    pipeline<span class="token punctuation">.</span>train_config<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> <span class="token number">8</span>

    pipeline<span class="token punctuation">.</span>train_config<span class="token punctuation">.</span>fine_tune_checkpoint <span class="token operator">=</span> <span class="token string">'cache/datasets/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0'</span>
    pipeline<span class="token punctuation">.</span>train_config<span class="token punctuation">.</span>fine_tune_checkpoint_type <span class="token operator">=</span> <span class="token string">'detection'</span>

    <span class="token comment"># Train input reader config.</span>
    pipeline<span class="token punctuation">.</span>train_input_reader<span class="token punctuation">.</span>label_map_path <span class="token operator">=</span> <span class="token string">'dataset/printed_links/labels/label_map.pbtxt'</span>
    pipeline<span class="token punctuation">.</span>train_input_reader<span class="token punctuation">.</span>tf_record_input_reader<span class="token punctuation">.</span>input_path<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'dataset/printed_links/tfrecords/train.record'</span>

    <span class="token comment"># Eval input reader config.</span>
    pipeline<span class="token punctuation">.</span>eval_input_reader<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>label_map_path <span class="token operator">=</span> <span class="token string">'dataset/printed_links/labels/label_map.pbtxt'</span>
    pipeline<span class="token punctuation">.</span>eval_input_reader<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tf_record_input_reader<span class="token punctuation">.</span>input_path<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'dataset/printed_links/tfrecords/test.record'</span>

    <span class="token keyword">return</span> pipeline

<span class="token keyword">def</span> <span class="token function">clone_pipeline_config</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    copyfile<span class="token punctuation">(</span>
        <span class="token string">'cache/datasets/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config'</span><span class="token punctuation">,</span>
        <span class="token string">'pipeline.config'</span>
    <span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">setup_pipeline</span><span class="token punctuation">(</span>pipeline_config_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    clone_pipeline_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
    pipeline <span class="token operator">=</span> read_pipeline_config<span class="token punctuation">(</span>pipeline_config_path<span class="token punctuation">)</span>
    pipeline <span class="token operator">=</span> modify_config<span class="token punctuation">(</span>pipeline<span class="token punctuation">)</span>
    write_pipeline_config<span class="token punctuation">(</span>pipeline_config_path<span class="token punctuation">,</span> pipeline<span class="token punctuation">)</span>
    <span class="token keyword">return</span> pipeline

<span class="token keyword">def</span> <span class="token function">read_pipeline_config</span><span class="token punctuation">(</span>pipeline_config_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    pipeline <span class="token operator">=</span> pipeline_pb2<span class="token punctuation">.</span>TrainEvalPipelineConfig<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>gfile<span class="token punctuation">.</span>GFile<span class="token punctuation">(</span>pipeline_config_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        proto_str <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
        text_format<span class="token punctuation">.</span>Merge<span class="token punctuation">(</span>proto_str<span class="token punctuation">,</span> pipeline<span class="token punctuation">)</span>
    <span class="token keyword">return</span> pipeline

<span class="token keyword">def</span> <span class="token function">write_pipeline_config</span><span class="token punctuation">(</span>pipeline_config_path<span class="token punctuation">,</span> pipeline<span class="token punctuation">)</span><span class="token punctuation">:</span>
    config_text <span class="token operator">=</span> text_format<span class="token punctuation">.</span>MessageToString<span class="token punctuation">(</span>pipeline<span class="token punctuation">)</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>gfile<span class="token punctuation">.</span>GFile<span class="token punctuation">(</span>pipeline_config_path<span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>config_text<span class="token punctuation">)</span>

<span class="token comment"># Adjusting the pipeline configuration.</span>
pipeline <span class="token operator">=</span> setup_pipeline<span class="token punctuation">(</span><span class="token string">'pipeline.config'</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>pipeline<span class="token punctuation">)</span></code></pre></div></span>
<p>Here is the content of the <span><code class="language-text">pipeline.config</code></span> file:</p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">model {
  ssd {
    num_classes: 1
    image_resizer {
      fixed_shape_resizer {
        height: 640
        width: 640
      }
    }
    feature_extractor {
      type: "ssd_mobilenet_v2_fpn_keras"
      depth_multiplier: 1.0
      min_depth: 16
      conv_hyperparams {
        regularizer {
          l2_regularizer {
            weight: 3.9999998989515007e-05
          }
        }
        initializer {
          random_normal_initializer {
            mean: 0.0
            stddev: 0.009999999776482582
          }
        }
        activation: RELU_6
        batch_norm {
          decay: 0.996999979019165
          scale: true
          epsilon: 0.0010000000474974513
        }
      }
      use_depthwise: true
      override_base_feature_extractor_hyperparams: true
      fpn {
        min_level: 3
        max_level: 7
        additional_layer_depth: 128
      }
    }
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    box_predictor {
      weight_shared_convolutional_box_predictor {
        conv_hyperparams {
          regularizer {
            l2_regularizer {
              weight: 3.9999998989515007e-05
            }
          }
          initializer {
            random_normal_initializer {
              mean: 0.0
              stddev: 0.009999999776482582
            }
          }
          activation: RELU_6
          batch_norm {
            decay: 0.996999979019165
            scale: true
            epsilon: 0.0010000000474974513
          }
        }
        depth: 128
        num_layers_before_predictor: 4
        kernel_size: 3
        class_prediction_bias_init: -4.599999904632568
        share_prediction_tower: true
        use_depthwise: true
      }
    }
    anchor_generator {
      multiscale_anchor_generator {
        min_level: 3
        max_level: 7
        anchor_scale: 4.0
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        scales_per_octave: 2
      }
    }
    post_processing {
      batch_non_max_suppression {
        score_threshold: 9.99999993922529e-09
        iou_threshold: 0.6000000238418579
        max_detections_per_class: 100
        max_total_detections: 100
        use_static_shapes: false
      }
      score_converter: SIGMOID
    }
    normalize_loss_by_num_matches: true
    loss {
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_loss {
        weighted_sigmoid_focal {
          gamma: 2.0
          alpha: 0.25
        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    encode_background_as_zeros: true
    normalize_loc_loss_by_codesize: true
    inplace_batchnorm_update: true
    freeze_batchnorm: false
  }
}
train_config {
  batch_size: 8
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.0
      min_aspect_ratio: 0.75
      max_aspect_ratio: 3.0
      min_area: 0.75
      max_area: 1.0
      overlap_thresh: 0.0
    }
  }
  sync_replicas: true
  optimizer {
    momentum_optimizer {
      learning_rate {
        cosine_decay_learning_rate {
          learning_rate_base: 0.07999999821186066
          total_steps: 50000
          warmup_learning_rate: 0.026666000485420227
          warmup_steps: 1000
        }
      }
      momentum_optimizer_value: 0.8999999761581421
    }
    use_moving_average: false
  }
  fine_tune_checkpoint: "cache/datasets/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0"
  num_steps: 50000
  startup_delay_steps: 0.0
  replicas_to_aggregate: 8
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
  fine_tune_checkpoint_type: "detection"
  fine_tune_checkpoint_version: V2
}
train_input_reader {
  label_map_path: "dataset/printed_links/labels/label_map.pbtxt"
  tf_record_input_reader {
    input_path: "dataset/printed_links/tfrecords/train.record"
  }
}
eval_config {
  metrics_set: "coco_detection_metrics"
  use_moving_averages: false
}
eval_input_reader {
  label_map_path: "dataset/printed_links/labels/label_map.pbtxt"
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: "dataset/printed_links/tfrecords/test.record"
  }
}</code></pre></div></span>
<h3 id="launching-the-training-process" style="position:relative">Launching the training process<a href="#launching-the-training-process" aria-label="launching the training process permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>We&#x27;re ready now to launch a training process using the TensorFlow 2 Object Detection API. The API contains a <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py">model_main_tf2.py</a> script that will run training for us. Feel free to explore the flags that this Python script supports in the source-code (i.e. <span><code class="language-text">num_train_steps</code></span>, <span><code class="language-text">model_dir</code></span> and others) to see their meanings.</p>
<p>We will be training the model for <span><code class="language-text">1000</code></span> iterations (epochs). Feel free to train it for a smaller or larger number of iterations depending on the learning progress (see the TensorBoard charts).</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">%%bash

<span class="token assign-left variable">NUM_TRAIN_STEPS</span><span class="token operator">=</span><span class="token number">1000</span>
<span class="token assign-left variable">CHECKPOINT_EVERY_N</span><span class="token operator">=</span><span class="token number">1000</span>

<span class="token assign-left variable">PIPELINE_CONFIG_PATH</span><span class="token operator">=</span>pipeline.config
<span class="token assign-left variable">MODEL_DIR</span><span class="token operator">=</span>./logs
<span class="token assign-left variable">SAMPLE_1_OF_N_EVAL_EXAMPLES</span><span class="token operator">=</span><span class="token number">1</span>

python ./models/research/object_detection/model_main_tf2.py <span class="token punctuation">\</span>
  <span class="token parameter variable">--model_dir</span><span class="token operator">=</span><span class="token variable">$MODEL_DIR</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--num_train_steps</span><span class="token operator">=</span><span class="token variable">$NUM_TRAIN_STEPS</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--sample_1_of_n_eval_examples</span><span class="token operator">=</span><span class="token variable">$SAMPLE_1_OF_N_EVAL_EXAMPLES</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--pipeline_config_path</span><span class="token operator">=</span><span class="token variable">$PIPELINE_CONFIG_PATH</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--checkpoint_every_n</span><span class="token operator">=</span><span class="token variable">$CHECKPOINT_EVERY_N</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--alsologtostderr</span></code></pre></div></span>
<p>While the model is training (it may take around<span><code class="language-text">~10 minutes</code></span> for <span><code class="language-text">1000</code></span> iterations in <a href="https://colab.research.google.com/notebooks/gpu.ipynb">GoogleColab GPU</a> runtime) you should be able to observe the training progress in TensorBoard. The <span><code class="language-text">localization</code></span> and <span><code class="language-text">classification</code></span> losses should decrease which means that the model is doing a good job in localizing and classifying new custom objects.</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 46.800000000000004%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAgABBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHtLVBlH//EABcQAAMBAAAAAAAAAAAAAAAAAAABEiD/2gAIAQEAAQUClEolY//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/Aar/xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAgEBPwGI/8QAFxAAAwEAAAAAAAAAAAAAAAAAAAExIP/aAAgBAQAGPwKERFj/xAAZEAACAwEAAAAAAAAAAAAAAAAAARBR8ZH/2gAIAQEAAT8hVHhiGIKf/9oADAMBAAIAAwAAABCkP//EABYRAQEBAAAAAAAAAAAAAAAAAAARUf/aAAgBAwEBPxCla//EABYRAAMAAAAAAAAAAAAAAAAAAAARUf/aAAgBAgEBPxBIJD//xAAcEAACAQUBAAAAAAAAAAAAAAAAAREQITFxofH/2gAIAQEAAT8Qi3l0Extcp4QyFT//2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Training Process"
        title=""
        src="/static/f0ee38bedbfe135b3b118411cdb68c50/a2510/23.jpg"
        srcset="/static/f0ee38bedbfe135b3b118411cdb68c50/0479a/23.jpg 250w,
/static/f0ee38bedbfe135b3b118411cdb68c50/41099/23.jpg 500w,
/static/f0ee38bedbfe135b3b118411cdb68c50/a2510/23.jpg 1000w,
/static/f0ee38bedbfe135b3b118411cdb68c50/c58a3/23.jpg 1500w,
/static/f0ee38bedbfe135b3b118411cdb68c50/3acf0/23.jpg 2000w,
/static/f0ee38bedbfe135b3b118411cdb68c50/8b3ab/23.jpg 2390w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>Also during the training, the new model checkpoints (parameters that the model has learned during the training) will be saved to the <span><code class="language-text">logs</code></span> folder.</p>
<p>The <span><code class="language-text">logs</code></span> folder structure now looks like this:</p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">logs
 checkpoint
 ckpt-1.data-00000-of-00001
 ckpt-1.index
 train
     events.out.tfevents.1606560330.b314c371fa10.1747.1628.v2</code></pre></div></span>
<h3 id="evaluating-the-model-optional" style="position:relative">Evaluating the Model (Optional)<a href="#evaluating-the-model-optional" aria-label="evaluating the model optional permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h3>
<p>The evaluation process uses the trained model checkpoints and evaluates how well the model performs in detecting objects in the test dataset. The results of this evaluation are summarised in the form of some <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/evaluation_protocols.md">metrics</a>, which can be examined over time. You may read more about how to evaluate these metrics <a href="https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#evaluating-the-model-optional">here</a>.</p>
<p>We will skip the metrics evaluation step in this article. But we may still use the evaluation step to see the model&#x27;s detections in TensorBoard:</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">%%bash

<span class="token assign-left variable">PIPELINE_CONFIG_PATH</span><span class="token operator">=</span>pipeline.config
<span class="token assign-left variable">MODEL_DIR</span><span class="token operator">=</span>logs

python ./models/research/object_detection/model_main_tf2.py <span class="token punctuation">\</span>
  <span class="token parameter variable">--model_dir</span><span class="token operator">=</span><span class="token variable">$MODEL_DIR</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--pipeline_config_path</span><span class="token operator">=</span><span class="token variable">$PIPELINE_CONFIG_PATH</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--checkpoint_dir</span><span class="token operator">=</span><span class="token variable">$MODEL_DIR</span> <span class="token punctuation">\</span></code></pre></div></span>
<p>After launching the script you should be able to see several side-by-side images with detections boxes:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1000px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 42%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHZklsD/8QAFxABAQEBAAAAAAAAAAAAAAAAAgASAf/aAAgBAQABBQLJuE2Df//EABYRAAMAAAAAAAAAAAAAAAAAAAABEf/aAAgBAwEBPwGsrP/EABYRAAMAAAAAAAAAAAAAAAAAAAABEf/aAAgBAgEBPwGIiP/EABYQAAMAAAAAAAAAAAAAAAAAAAABMf/aAAgBAQAGPwKIiIj/xAAZEAABBQAAAAAAAAAAAAAAAAAAASHB0fH/2gAIAQEAAT8hYgFFRhH/2gAMAwEAAgADAAAAEHAP/8QAFREBAQAAAAAAAAAAAAAAAAAAAGH/2gAIAQMBAT8Qoo//xAAVEQEBAAAAAAAAAAAAAAAAAAAAYf/aAAgBAgEBPxCST//EABkQAAMAAwAAAAAAAAAAAAAAAAABESFh8f/aAAgBAQABPxCzNErzFocAf//Z'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Model Evaluation"
        title=""
        src="/static/4e770b2825aa52724dd190abec9b4384/a2510/24.jpg"
        srcset="/static/4e770b2825aa52724dd190abec9b4384/0479a/24.jpg 250w,
/static/4e770b2825aa52724dd190abec9b4384/41099/24.jpg 500w,
/static/4e770b2825aa52724dd190abec9b4384/a2510/24.jpg 1000w,
/static/4e770b2825aa52724dd190abec9b4384/c58a3/24.jpg 1500w,
/static/4e770b2825aa52724dd190abec9b4384/3acf0/24.jpg 2000w,
/static/4e770b2825aa52724dd190abec9b4384/56873/24.jpg 2332w"
        sizes="(max-width: 1000px) 100vw, 1000px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<h2 id="-exporting-the-model" style="position:relative"> Exporting the Model<a href="#-exporting-the-model" aria-label=" exporting the model permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>Once the training process is complete we should save the trained model for further usage. To export the model we will use the <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/exporter_main_v2.py">exporter_main_v2.py</a> script from Object Detection API. It prepares an object detection TensorFlow graph for inference using model configuration and a trained checkpoint. The script outputs associated checkpoint files, a SavedModel, and a copy of the model config:</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">%%bash

python ./models/research/object_detection/exporter_main_v2.py <span class="token punctuation">\</span>
    <span class="token parameter variable">--input_type</span><span class="token operator">=</span>image_tensor <span class="token punctuation">\</span>
    <span class="token parameter variable">--pipeline_config_path</span><span class="token operator">=</span>pipeline.config <span class="token punctuation">\</span>
    <span class="token parameter variable">--trained_checkpoint_dir</span><span class="token operator">=</span>logs <span class="token punctuation">\</span>
    <span class="token parameter variable">--output_directory</span><span class="token operator">=</span>exported/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8</code></pre></div></span>
<p>Here is what the <span><code class="language-text">exported</code></span> folder contains after the export:</p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">exported
 ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8
     checkpoint
        checkpoint
        ckpt-0.data-00000-of-00001
        ckpt-0.index
     pipeline.config
     saved_model
         assets
         saved_model.pb
         variables
             variables.data-00000-of-00001
             variables.index</code></pre></div></span>
<p>At this moment we have a <span><code class="language-text">saved_model</code></span> that may be used for inference.</p>
<h2 id="-using-the-exported-model" style="position:relative"> Using the Exported Model<a href="#-using-the-exported-model" aria-label=" using the exported model permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>Let&#x27;s see how can we use the saved model from the previous step for object detections.</p>
<p>First, we need to create a detection function that will use the saved model. It will accept the image and will output the detected objects:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> time
<span class="token keyword">import</span> math

PATH_TO_SAVED_MODEL <span class="token operator">=</span> <span class="token string">'exported/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model'</span>

<span class="token keyword">def</span> <span class="token function">detection_function_from_saved_model</span><span class="token punctuation">(</span>saved_model_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Loading saved model...'</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>
    start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># Load saved model and build the detection function</span>
    detect_fn <span class="token operator">=</span> tf<span class="token punctuation">.</span>saved_model<span class="token punctuation">.</span>load<span class="token punctuation">(</span>saved_model_path<span class="token punctuation">)</span>

    end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    elapsed_time <span class="token operator">=</span> end_time <span class="token operator">-</span> start_time

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Done! Took {} seconds'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>elapsed_time<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> detect_fn

exported_detect_fn <span class="token operator">=</span> detection_function_from_saved_model<span class="token punctuation">(</span>
    PATH_TO_SAVED_MODEL
<span class="token punctuation">)</span></code></pre></div></span>
<p><em>output </em></p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Loading saved model...Done! Took 9 seconds</code></pre></div></span>
<p>To map the IDs of the detected classes back to the class names we need to load the label map as well:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>utils <span class="token keyword">import</span> label_map_util

category_index <span class="token operator">=</span> label_map_util<span class="token punctuation">.</span>create_category_index_from_labelmap<span class="token punctuation">(</span>
    <span class="token string">'dataset/printed_links/labels/label_map.pbtxt'</span><span class="token punctuation">,</span>
    use_display_name<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>category_index<span class="token punctuation">)</span></code></pre></div></span>
<p><em>output </em></p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">{1: {'id': 1, 'name': 'http'}}</code></pre></div></span>
<p>Testing the model on a test dataset.</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>utils <span class="token keyword">import</span> visualization_utils
<span class="token keyword">from</span> object_detection<span class="token punctuation">.</span>data_decoders<span class="token punctuation">.</span>tf_example_decoder <span class="token keyword">import</span> TfExampleDecoder

<span class="token operator">%</span>matplotlib inline

<span class="token keyword">def</span> <span class="token function">tensors_from_tfrecord</span><span class="token punctuation">(</span>
    tfrecords_filename<span class="token punctuation">,</span>
    tfrecords_num<span class="token punctuation">,</span>
    dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    decoder <span class="token operator">=</span> TfExampleDecoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
    raw_dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TFRecordDataset<span class="token punctuation">(</span>tfrecords_filename<span class="token punctuation">)</span>
    images <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> raw_record <span class="token keyword">in</span> raw_dataset<span class="token punctuation">.</span>take<span class="token punctuation">(</span>tfrecords_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        example <span class="token operator">=</span> decoder<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>raw_record<span class="token punctuation">)</span>
        image <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">'image'</span><span class="token punctuation">]</span>
        image <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>image<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">)</span>
        images<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image<span class="token punctuation">)</span>

    <span class="token keyword">return</span> images

<span class="token keyword">def</span> <span class="token function">test_detection</span><span class="token punctuation">(</span>tfrecords_filename<span class="token punctuation">,</span> tfrecords_num<span class="token punctuation">,</span> detect_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    image_tensors <span class="token operator">=</span> tensors_from_tfrecord<span class="token punctuation">(</span>
        tfrecords_filename<span class="token punctuation">,</span>
        tfrecords_num<span class="token punctuation">,</span>
        dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>uint8
    <span class="token punctuation">)</span>

    <span class="token keyword">for</span> image_tensor <span class="token keyword">in</span> image_tensors<span class="token punctuation">:</span>
        image_np <span class="token operator">=</span> image_tensor<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># The model expects a batch of images, so add an axis with `tf.newaxis`.</span>
        input_tensor <span class="token operator">=</span> tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>image_tensor<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

        detections <span class="token operator">=</span> detect_fn<span class="token punctuation">(</span>input_tensor<span class="token punctuation">)</span>

        <span class="token comment"># All outputs are batches tensors.</span>
        <span class="token comment"># Convert to numpy arrays, and take index [0] to remove the batch dimension.</span>
        <span class="token comment"># We're only interested in the first num_detections.</span>
        num_detections <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>detections<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">'num_detections'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        detections <span class="token operator">=</span> <span class="token punctuation">{</span>key<span class="token punctuation">:</span> value<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>num_detections<span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> detections<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        detections<span class="token punctuation">[</span><span class="token string">'num_detections'</span><span class="token punctuation">]</span> <span class="token operator">=</span> num_detections

        <span class="token comment"># detection_classes should be ints.</span>
        detections<span class="token punctuation">[</span><span class="token string">'detection_classes'</span><span class="token punctuation">]</span> <span class="token operator">=</span> detections<span class="token punctuation">[</span><span class="token string">'detection_classes'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>

        image_np_with_detections <span class="token operator">=</span> image_np<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

        visualization_utils<span class="token punctuation">.</span>visualize_boxes_and_labels_on_image_array<span class="token punctuation">(</span>
            image_np_with_detections<span class="token punctuation">,</span>
            detections<span class="token punctuation">[</span><span class="token string">'detection_boxes'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            detections<span class="token punctuation">[</span><span class="token string">'detection_classes'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            detections<span class="token punctuation">[</span><span class="token string">'detection_scores'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            category_index<span class="token punctuation">,</span>
            use_normalized_coordinates<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            max_boxes_to_draw<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
            min_score_thresh<span class="token operator">=</span><span class="token number">.3</span><span class="token punctuation">,</span>
            agnostic_mode<span class="token operator">=</span><span class="token boolean">False</span>
        <span class="token punctuation">)</span>

        plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image_np_with_detections<span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


test_detection<span class="token punctuation">(</span>
    tfrecords_filename<span class="token operator">=</span><span class="token string">'dataset/printed_links/tfrecords/test.record'</span><span class="token punctuation">,</span>
    tfrecords_num<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    detect_fn<span class="token operator">=</span>exported_detect_fn
<span class="token punctuation">)</span></code></pre></div></span>
<p>As a result, you should see <span><code class="language-text">10</code></span> images from the test dataset and highlighted <span><code class="language-text">https:</code></span> prefixes that were detected by the model:</p>
<span><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 976px; "
    >
      <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 98%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAEDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe+ypUFgAf/EABgQAAIDAAAAAAAAAAAAAAAAAAARAQIQ/9oACAEBAAEFAsrtBCIhH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8BH//EABcQAAMBAAAAAAAAAAAAAAAAAAEQcSD/2gAIAQEABj8CRrNx/8QAGxAAAgMAAwAAAAAAAAAAAAAAAAEQESFRgaH/2gAIAQEAAT8hMgPEjpwqFfDSlzZ//9oADAMBAAIAAwAAABADAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAdEAEBAQACAgMAAAAAAAAAAAABEQAhMUFxYZGx/9oACAEBAAE/ECQs1+GV72LEk5G9+9RL9BnT2/hloK8XMO3yxXVHs3//2Q=='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="Testing the model on a test dataset"
        title=""
        src="/static/61aef315a3caa1f60ef57bf4df5c450f/03073/25.jpg"
        srcset="/static/61aef315a3caa1f60ef57bf4df5c450f/0479a/25.jpg 250w,
/static/61aef315a3caa1f60ef57bf4df5c450f/41099/25.jpg 500w,
/static/61aef315a3caa1f60ef57bf4df5c450f/03073/25.jpg 976w"
        sizes="(max-width: 976px) 100vw, 976px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
    </span></span>
<p>The fact that the model is able to detect custom objects (in our case the <span><code class="language-text">https://</code></span> prefixes) on the images it hasn&#x27;t seen before is a good sign and something that we wanted to achieve.</p>
<h2 id="-converting-the-model-for-web" style="position:relative"> Converting the Model for Web<a href="#-converting-the-model-for-web" aria-label=" converting the model for web permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>As you remember from the beginning of this article, our goal was to use the custom object detection model in the browser. Luckily, there is a <a href="https://www.tensorflow.org/js">TensorFlow.js</a> JavaScript version of the TensorFlow library exists. In JavaScript, we can&#x27;t work with our saved model directly. Instead, we need to convert it to <a href="https://www.tensorflow.org/js/tutorials/conversion/import_saved_model">tfjs_graph_model</a> format.</p>
<p>To do this we need to install the tensorflowjs Python package:</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">pip <span class="token function">install</span> tensorflowjs <span class="token parameter variable">--quiet</span></code></pre></div></span>
<p>The model may be exported like this:</p>
<span><div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">%%bash

tensorflowjs_converter <span class="token punctuation">\</span>
    <span class="token parameter variable">--input_format</span><span class="token operator">=</span>tf_saved_model <span class="token punctuation">\</span>
    <span class="token parameter variable">--output_format</span><span class="token operator">=</span>tfjs_graph_model <span class="token punctuation">\</span>
    exported/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model <span class="token punctuation">\</span>
    exported_web/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8</code></pre></div></span>
<p>The <span><code class="language-text">exported_web</code></span> folder contains the <span><code class="language-text">.json</code></span> file with the model metadata and a bunch of <span><code class="language-text">.bin</code></span> files with trained model parameters:</p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">exported_web
 ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8
     group1-shard1of4.bin
     group1-shard2of4.bin
     group1-shard3of4.bin
     group1-shard4of4.bin
     model.json</code></pre></div></span>
<p>Finally, we have the model that is able to detect <span><code class="language-text">https://</code></span> prefixes for us, and it is saved in JavaScript-understandable format.</p>
<p>Let&#x27;s check the model size to see if it is light enough to be loaded completely to the client-side:</p>
<span><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> pathlib

<span class="token keyword">def</span> <span class="token function">get_folder_size</span><span class="token punctuation">(</span>folder_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    mB <span class="token operator">=</span> <span class="token number">1000000</span>
    root_dir <span class="token operator">=</span> pathlib<span class="token punctuation">.</span>Path<span class="token punctuation">(</span>folder_path<span class="token punctuation">)</span>
    sizeBytes <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>stat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>st_size <span class="token keyword">for</span> f <span class="token keyword">in</span> root_dir<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'**/*'</span><span class="token punctuation">)</span> <span class="token keyword">if</span> f<span class="token punctuation">.</span>is_file<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>sizeBytes<span class="token operator">//</span>mB<span class="token punctuation">}</span></span><span class="token string"> MB'</span></span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Original model size:      </span><span class="token interpolation"><span class="token punctuation">{</span>get_folder_size<span class="token punctuation">(</span><span class="token string">"cache/datasets/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8"</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Exported model size:      </span><span class="token interpolation"><span class="token punctuation">{</span>get_folder_size<span class="token punctuation">(</span><span class="token string">"exported/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8"</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Exported WEB model size:  </span><span class="token interpolation"><span class="token punctuation">{</span>get_folder_size<span class="token punctuation">(</span><span class="token string">"exported_web/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8"</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span></code></pre></div></span>
<p><em>output </em></p>
<span><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Original model size:      31 MB
Exported model size:      28 MB
Exported WEB model size:  13 MB</code></pre></div></span>
<p>As you may see the model that we&#x27;re going to use for the Web has <span><code class="language-text">13MB</code></span> which is quite acceptable in our case.</p>
<p>Later in JavaScript we may start using the model like this:</p>
<span><div class="gatsby-highlight" data-language="javascript"><pre class="language-javascript"><code class="language-javascript"><span class="token keyword">import</span> <span class="token operator">*</span> <span class="token keyword">as</span> tf <span class="token keyword">from</span> <span class="token string">'@tensorflow/tfjs'</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> model <span class="token operator">=</span> <span class="token keyword">await</span> tf<span class="token punctuation">.</span><span class="token function">loadGraphModel</span><span class="token punctuation">(</span>modelURL<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div></span>
<blockquote>
<p> The next step is to implement the Links Detector UI which will use this model, but this is another story for another article. The final source code of the application may be found in <a href="https://github.com/trekhleb/links-detector">links-detector repository</a> on GitHub.</p>
</blockquote>
<h2 id="-conclusions" style="position:relative"> Conclusions<a href="#-conclusions" aria-label=" conclusions permalink" class="gatsby-remark-autolink-header-anchor after"><span><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></span></a></h2>
<p>In this article, we started to solve the issue with printed links detection. We ended up creating the custom object detector to recognize the <span><code class="language-text">https://</code></span> prefixes on text images (i.e. on smartphone camera stream images). We have also converted the model to a <span><code class="language-text">tfjs_graph_model</code></span> to be able to re-use it on the client-side.</p>
<p>You may  <a href="https://trekhleb.dev/links-detector/">launch Links Detector demo</a> from your smartphone to see the final result and to try how the model performs on your books or magazines.</p>
<p>Here is how the final solution looks like:</p>
<img src="/posts-assets/2dc300f4cc152c8b14200c25eba77a02/26.gif" alt="Links Detector Demo"/>
<p>You may also  <a href="https://github.com/trekhleb/links-detector">browse the links-detector repository</a> on GitHub to see the complete source code of the UI part of the application.</p>
<blockquote>
<p> Currently the application is in <em>experimental</em> <em>Alpha</em> stage and has <a href="https://github.com/trekhleb/links-detector/issues?q=is%3Aopen+is%3Aissue+label%3Aenhancement">many issues and limitations</a>. So don&#x27;t raise your expectations level too high until these issues are resolved .</p>
</blockquote>
<p>As the next steps which might improve the model performance we might do the following:</p>
<ul>
<li>Extend the dataset with more link types (<span><code class="language-text">http://</code></span>, <span><code class="language-text">tcp://</code></span>, <span><code class="language-text">ftp://</code></span> etc)</li>
<li>Extended the dataset with images that have dark backgrounds</li>
<li>Extend the dataset with underlined links</li>
<li>Extend the dataset with examples of different fonts and ligatures</li>
<li>etc.</li>
</ul>
<p>Even though the model has a lot to be improved to make it closer to the production-ready state, I still hope that this article was useful for you and gave you some guidelines and inspiration to play around with your custom object detectors.</p>
<p>Happy training, folks!</p></article></div><div class="flex flex-row justify-center items-center mt-16"><div class="max-w-md"><div class="bg-white rounded-md shadow-md p-8"><h1 class="text-grey-darkest uppercase font-bold text-xl mb-3">Subscribe to the Newsletter</h1><p class="text-sm mb-3">Get my latest posts and project updates by email</p><form action="https://dev.us1.list-manage.com/subscribe/post?u=7714f14ff32085c685da2cfaa&amp;amp;id=53ffa81463" method="post" class="flex flex-col"><input placeholder="First Name" type="text" name="FNAME" class="border py-2 px-3 mb-3 rounded border-gray-300 border-solid appearance-none" required=""/><input placeholder="Email" type="email" name="EMAIL" class="border py-2 px-3 mb-3 rounded border-gray-300 border-solid appearance-none" required=""/><div class="hidden" aria-hidden="true"><input type="text" name="b_7714f14ff32085c685da2cfaa_53ffa81463" tabindex="-1"/></div><input type="submit" class="transition duration-200 ease-in-out bg-black text-white py-2 px-3 rounded shadow-sm cursor-pointer hover:bg-gray-800" value="Subscribe"/></form></div></div></div></article><footer class="flex flex-col justify-center items-center px-6 sm:px-12 py-12"><div class="flex flex-row items-center mb-6"><a class="transition duration-200 ease-in-out flex flex-row items-center hover:text-red-600 text-xs mr-5" href="/subscribe/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M928 160H96c-17.7 0-32 14.3-32 32v640c0 17.7 14.3 32 32 32h832c17.7 0 32-14.3 32-32V192c0-17.7-14.3-32-32-32zm-40 110.8V792H136V270.8l-27.6-21.5 39.3-50.5 42.8 33.3h643.1l42.8-33.3 39.3 50.5-27.7 21.5zM833.6 232L512 482 190.4 232l-42.8-33.3-39.3 50.5 27.6 21.5 341.6 265.6a55.99 55.99 0 0 0 68.7 0L888 270.8l27.6-21.5-39.3-50.5-42.7 33.2z"></path></svg><span class="w-2"></span>Subscribe</a><a class="transition duration-200 ease-in-out flex flex-row items-center hover:text-red-600 text-xs" href="/rss.xml"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg><span class="w-2"></span>RSS</a></div><div style="flex:1" class="flex flex-row items-center justify-center"><ul class="flex flex-row flex-wrap "><li class="flex flex-row items-center last:mr-0 mr-2 ml-2"><a href="https://www.linkedin.com/in/trekhleb/" class="transition duration-200 ease-in-out flex flex-row items-center hover:text-red-600 " title="Oleksii Trekhleb on LinkedIn"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="w-5 h-5" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></li><li class="flex flex-row items-center last:mr-0 mr-2 ml-2"><a href="https://github.com/trekhleb" class="transition duration-200 ease-in-out flex flex-row items-center hover:text-red-600 " title="Oleksii Trekhleb on GitHub"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="w-5 h-5" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></li><li class="flex flex-row items-center last:mr-0 mr-2 ml-2"><a href="https://x.com/trekhleb" class="transition duration-200 ease-in-out flex flex-row items-center hover:text-red-600 " title="Oleksii Trekhleb on X"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="w-5 h-5" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a></li></ul><div class="ml-3"><a href="https://war.ukraine.ua/" class="transition duration-200 ease-in-out flex flex-row items-center hover:text-red-600 text-2xl leading-4" title="Help Ukraine to survive the russian invasion"></a></div></div></footer></div></main></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-YJ73BX984Z"></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-YJ73BX984Z', {"send_page_view":false});
      }
      </script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/2020/printed-links-detection/";/*]]>*/</script><!-- slice-start id="_gatsby-scripts-1" -->
          <script
            id="gatsby-chunk-mapping"
          >
            window.___chunkMapping="{\"app\":[\"/app-aa6da1269156bb5ff60b.js\"],\"component---src-pages-404-tsx\":[\"/component---src-pages-404-tsx-56a2b19bbf850be751db.js\"],\"component---src-pages-blog-tsx\":[\"/component---src-pages-blog-tsx-3f595add7c119e841a9a.js\"],\"component---src-pages-index-tsx\":[\"/component---src-pages-index-tsx-77c3e45b553f07c584e0.js\"],\"component---src-pages-projects-tsx\":[\"/component---src-pages-projects-tsx-9fb09990665d5d3e621f.js\"],\"component---src-pages-publications-tsx\":[\"/component---src-pages-publications-tsx-dedf42f1c8ac897ae2c1.js\"],\"component---src-pages-subscribe-confirm-index-tsx\":[\"/component---src-pages-subscribe-confirm-index-tsx-b4570d1c3218650c66af.js\"],\"component---src-pages-subscribe-index-tsx\":[\"/component---src-pages-subscribe-index-tsx-285c35c0d426c1f2b444.js\"],\"component---src-pages-subscribe-thanks-index-tsx\":[\"/component---src-pages-subscribe-thanks-index-tsx-059dd72fbf20e665225f.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2017-dangerous-step-from-agile-to-fragile-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2017-dangerous-step-from-agile-to-fragile-index-md-bd55ab6bbefbe6c02f76.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2017-docker-whale-in-digital-ocean-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2017-docker-whale-in-digital-ocean-index-md-7f79fc2c524b0deb486e.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2017-how-to-create-aot-jit-compatible-angular-4-library-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2017-how-to-create-aot-jit-compatible-angular-4-library-index-md-3523dbfb4c4f86f5aca5.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2017-if-you-ever-used-subway-you-should-know-what-binary-search-tree-is-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2017-if-you-ever-used-subway-you-should-know-what-binary-search-tree-is-index-md-b40b5f76a3332f795c69.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2017-solid-principles-around-you-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2017-solid-principles-around-you-index-md-bb2289bf2e5b939b6d59.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-aggregatus-service-is-live-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-aggregatus-service-is-live-index-md-3363c8fec74c1efa7d38.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-algorithms-and-data-structures-in-javascript-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-algorithms-and-data-structures-in-javascript-index-md-de008122bd0d85775ce5.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-dynamic-programming-vs-divide-and-conquer-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-dynamic-programming-vs-divide-and-conquer-index-md-d9f6caab384c340046d7.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-extend-your-limits-rather-than-your-ambitions-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-extend-your-limits-rather-than-your-ambitions-index-md-f77db01197373cb500df.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-gift-of-24-hours-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-gift-of-24-hours-index-md-f3576b1dadf86bfc6fba.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-homemade-machine-learning-in-python-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-homemade-machine-learning-in-python-index-md-06b5960abe60351da334.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-links-to-promote-your-next-startup-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-links-to-promote-your-next-startup-index-md-a030500c8c73a2437810.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-machine-learning-in-matlaboctave-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-machine-learning-in-matlaboctave-index-md-5057da084adc918e7bc2.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-permutations-combinations-cheat-sheet-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-permutations-combinations-cheat-sheet-index-md-23e01d19f67fb81b858b.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-playground-and-cheatsheet-for-learning-python-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-playground-and-cheatsheet-for-learning-python-index-md-ba546394f2c64441b2fc.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-playing-with-discrete-fourier-transform-algorithm-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-playing-with-discrete-fourier-transform-algorithm-index-md-66897346456aaf799243.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2018-top-33-javascript-projects-on-github-august-2018-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2018-top-33-javascript-projects-on-github-august-2018-index-md-1c41954d842da4b678d5.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2019-most-trending-jupyter-notebooks-of-december-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2019-most-trending-jupyter-notebooks-of-december-index-md-6bbc550285c4556f03b5.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2019-nano-neuron-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2019-nano-neuron-index-md-d6623de28e0952e33af2.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2019-react-useposition-hook-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2019-react-useposition-hook-index-md-e87236ed9d733fed5552.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2019-technical-interview-preparation-checklist-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2019-technical-interview-preparation-checklist-index-md-4304260a8ecba519f9dd.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2020-coronavirus-covid-19-dashboard-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2020-coronavirus-covid-19-dashboard-index-md-7bc62aa4fcb87721eae0.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2020-machine-learning-experiments-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2020-machine-learning-experiments-index-md-35819f4e3c55a9fca22d.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2020-printed-links-detection-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2020-printed-links-detection-index-md-adb3d2b26b2fcdb0f1e3.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2020-recipes-generation-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2020-recipes-generation-index-md-db1a9ddd2a8bc8e0f982.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2020-state-of-the-art-shitcode-principles-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2020-state-of-the-art-shitcode-principles-index-md-e25be1e2971f01978bfa.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2020-this-is-how-social-media-could-ruin-your-happiness-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2020-this-is-how-social-media-could-ruin-your-happiness-index-md-773d21abf6e64c5a117d.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2020-top-33-javascript-projects-on-github-december-index-md\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2020-top-33-javascript-projects-on-github-december-index-md-e5e768b4e183d261c032.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2021-binary-floating-point-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2021-binary-floating-point-index-mdx-b9268f30306799d3e906.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2021-content-aware-image-resizing-in-javascript-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2021-content-aware-image-resizing-in-javascript-index-mdx-ede99b4fcd5371a1a27f.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2021-gyro-web-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2021-gyro-web-index-mdx-ecf87de2e08b965cbcce.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2021-self-parking-car-evolution-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2021-self-parking-car-evolution-index-mdx-fba6c003412eb8062c0b.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2021-top-33-javascript-projects-on-github-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2021-top-33-javascript-projects-on-github-index-mdx-01b110bed2ae167bbd80.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2022-data-structure-sketches-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2022-data-structure-sketches-index-mdx-f192dbe3f9cc16550cd2.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2022-okso-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2022-okso-index-mdx-ba48326a5f5f2458862b.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2022-solid-principles-sketches-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2022-solid-principles-sketches-index-mdx-5741ddac6601ed5a0d78.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2023-micrograd-ts-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2023-micrograd-ts-index-mdx-e46ab45c7885430e4715.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2023-observations-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2023-observations-index-mdx-1bb24883f7231ab2e02b.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2024-api-design-x-home-timeline-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2024-api-design-x-home-timeline-index-mdx-d81440dab07cf00f66d6.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2024-system-design-sketches-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2024-system-design-sketches-index-mdx-1d06c881f4dc7d2c3af5.js\"],\"component---src-templates-post-tsx-content-file-path-src-posts-2025-jobs-radar-index-mdx\":[\"/component---src-templates-post-tsx-content-file-path-src-posts-2025-jobs-radar-index-mdx-4338b68b915873f9e99c.js\"],\"component---src-templates-project-tsx\":[\"/component---src-templates-project-tsx-e4dbdfb0bd90f2d2866a.js\"]}";
          </script>
        <script>window.___webpackCompilationHash="f9b4b2947fc2e96fac59";</script><script src="/webpack-runtime-fe00f109af42c89ea8fe.js" async></script><script src="/framework-dffef80c3dd9823eec87.js" async></script><script src="/app-aa6da1269156bb5ff60b.js" async></script><!-- slice-end id="_gatsby-scripts-1" --></body></html>